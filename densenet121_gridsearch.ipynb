{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30a4fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ðŸ”¬ DenseNet-121 GridSearch - Fair Comparison with Pretrained Weights\n",
    "\n",
    "EXACT SAME PARAMETERS AS RESNET-101 & EEGNET:\n",
    "1. âœ… Optimizer: Adam, AdamW, Adagrad\n",
    "2. âœ… Activation: ReLU, LeakyReLU\n",
    "3. âœ… L1: [0] (same as others)\n",
    "4. âœ… L2: [0, 1e-4, 1e-3]\n",
    "5. âœ… Early Stopping: patience=10\n",
    "6. âœ… LR Scheduler: CosineAnnealingLR\n",
    "7. âœ… Loss: SoftFocalLoss (gamma=3.0)\n",
    "8. âœ… Data: Hybrid loading\n",
    "9. âœ… CV: 3-fold\n",
    "10. âœ… Pretrained: ImageNet weights\n",
    "\n",
    "Total: 18 configs Ã— 3 folds = 54 runs (~10 hours)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64e13fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "===================== DenseNet-121 GridSearch - Pretrained =====================\n",
      "================================================================================\n",
      "\n",
      "Started: 2026-01-25 23:52:28\n",
      "âœ… Seed: 42\n",
      "âœ… Device: cuda:0\n",
      "   GPU: NVIDIA GeForce RTX 5060 Ti\n",
      "\n",
      "âœ… Results: densenet_gridsearch_results\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Setup & Imports\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" DenseNet-121 GridSearch - Pretrained \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nStarted: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)\n",
    "print(\"âœ… Seed: 42\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"âœ… Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "DATA_PKG = Path(\"data_package\")\n",
    "SPEC_DIR = Path(\"spec_hr_out\")\n",
    "RESULTS_DIR = Path(\"densenet_gridsearch_results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\\nâœ… Results: {RESULTS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8fb126b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data loaded\n",
      "   Samples: 17089\n",
      "   Classes: ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n",
      "\n",
      "âœ… Created 3-fold CV\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Load Data\n",
    "\n",
    "meta_use = pd.read_csv(DATA_PKG / \"meta_use.csv\")\n",
    "lbl = np.load(DATA_PKG / \"labels.npz\", allow_pickle=True)\n",
    "y_soft = lbl[\"y_soft\"]\n",
    "w_conf = lbl[\"w_conf\"]\n",
    "classes = [str(c) for c in lbl[\"classes\"]]\n",
    "y_hard = y_soft.argmax(axis=1)\n",
    "\n",
    "print(\"âœ… Data loaded\")\n",
    "print(f\"   Samples: {len(y_hard)}\")\n",
    "print(f\"   Classes: {classes}\")\n",
    "\n",
    "N_FOLDS = 3\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "folds = list(skf.split(meta_use, y_hard))\n",
    "print(f\"\\nâœ… Created {N_FOLDS}-fold CV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a47c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset ready\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Dataset Class\n",
    "\n",
    "class SpecDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, y_soft, w_conf, F_target=81, T_target=600):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root = Path(root_dir)\n",
    "        self.y_soft = y_soft\n",
    "        self.w_conf = w_conf\n",
    "        self.F_target = F_target\n",
    "        self.T_target = T_target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _center_crop_pad(self, x):\n",
    "        C, F, T = x.shape\n",
    "        if F >= self.F_target:\n",
    "            f0 = (F - self.F_target) // 2\n",
    "            x = x[:, f0:f0+self.F_target, :]\n",
    "        else:\n",
    "            pad = self.F_target - F\n",
    "            x = np.pad(x, ((0,0),(pad//2, pad-pad//2),(0,0)), mode=\"constant\")\n",
    "        if T >= self.T_target:\n",
    "            t0 = (T - self.T_target) // 2\n",
    "            x = x[:, :, t0:t0+self.T_target]\n",
    "        else:\n",
    "            pad = self.T_target - T\n",
    "            x = np.pad(x, ((0,0),(0,0),(pad//2, pad-pad//2)), mode=\"constant\")\n",
    "        return x.copy()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        eid = int(row.eeg_id)\n",
    "\n",
    "        npz = np.load(self.root / f\"{eid}_hr.npz\")\n",
    "        x = npz[\"x\"]\n",
    "        x = self._center_crop_pad(x)\n",
    "        x = torch.from_numpy(x).float()\n",
    "\n",
    "        x = F.interpolate(x.unsqueeze(0), size=(224, 224),\n",
    "                          mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "\n",
    "        if x.size(0) == 4:\n",
    "            x = torch.cat([x[:3].mean(0, keepdim=True).repeat(3, 1, 1)], dim=0)\n",
    "\n",
    "        y = torch.from_numpy(self.y_soft[self.df.index[idx]]).float()\n",
    "        w = torch.tensor(self.w_conf[self.df.index[idx]], dtype=torch.float32)\n",
    "\n",
    "        return x, y, w\n",
    "\n",
    "print(\"âœ… Dataset ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb289419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DenseNet-121 model ready\n",
      "   Pretrained: ImageNet weights\n",
      "   Supports: ReLU, LeakyReLU\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: DenseNet-121 Model (Pretrained)\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "class DenseNet121_Pretrained(nn.Module):\n",
    "    \"\"\"DenseNet-121 with pretrained ImageNet weights\"\"\"\n",
    "\n",
    "    def __init__(self, n_classes=6, activation='relu', freeze_backbone=False):\n",
    "        super().__init__()\n",
    "        self.activation_name = activation\n",
    "\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "\n",
    "        if freeze_backbone:\n",
    "            for param in self.backbone.features.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        in_features = self.backbone.classifier.in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, n_classes)\n",
    "        )\n",
    "\n",
    "    def get_activation(self):\n",
    "        if self.activation_name == 'relu':\n",
    "            return F.relu\n",
    "        elif self.activation_name == 'leakyrelu':\n",
    "            return lambda x: F.leaky_relu(x, negative_slope=0.01)\n",
    "        else:\n",
    "            return F.relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        x = self.classifier[0](features)\n",
    "        x = self.classifier[1](x)\n",
    "        x = self.classifier[2](x)\n",
    "        x = self.get_activation()(x)\n",
    "        x = self.classifier[3](x)\n",
    "        x = self.classifier[4](x)\n",
    "        return x\n",
    "\n",
    "print(\"âœ… DenseNet-121 model ready\")\n",
    "print(\"   Pretrained: ImageNet weights\")\n",
    "print(\"   Supports: ReLU, LeakyReLU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f80c538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SoftFocalLoss ready\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: SoftFocalLoss\n",
    "\n",
    "class SoftFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=3.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, soft_targets, sample_weights=None):\n",
    "        hard_targets = soft_targets.argmax(dim=1)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        p_t = probs.gather(1, hard_targets.unsqueeze(1)).squeeze(1)\n",
    "        ce_loss = -(soft_targets * F.log_softmax(logits, dim=1)).sum(dim=1)\n",
    "        focal_weight = ((1 - p_t) ** self.gamma)\n",
    "        loss = focal_weight * ce_loss\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha[hard_targets]\n",
    "            loss = alpha_t * loss\n",
    "\n",
    "        if sample_weights is not None:\n",
    "            loss = loss * sample_weights\n",
    "\n",
    "        return loss.mean()\n",
    "\n",
    "print(\"âœ… SoftFocalLoss ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9c8f6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Hybrid loader ready (batch_size=16 for DenseNet-121)\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Hybrid Data Loader\n",
    "\n",
    "def create_hybrid_loader(fold=0, target_ratio=0.4, weight_power=3.0, batch_size=16):\n",
    "    tr_idx, va_idx = folds[fold]\n",
    "    df_tr = meta_use.iloc[tr_idx]\n",
    "    y_soft_tr, w_conf_tr = y_soft[tr_idx], w_conf[tr_idx]\n",
    "\n",
    "    y_hard_tr = y_soft_tr.argmax(axis=1)\n",
    "    counts = np.bincount(y_hard_tr, minlength=6)\n",
    "    target = int(counts.max() * target_ratio)\n",
    "\n",
    "    indices_add = []\n",
    "    for i in range(6):\n",
    "        mask = y_hard_tr == i\n",
    "        if mask.sum() < target:\n",
    "            idx = np.where(mask)[0]\n",
    "            n_add = target - mask.sum()\n",
    "            indices_add.extend(np.random.choice(idx, n_add, replace=True))\n",
    "\n",
    "    all_idx = np.concatenate([np.arange(len(y_hard_tr)), indices_add])\n",
    "    np.random.shuffle(all_idx)\n",
    "\n",
    "    df_tr_over = df_tr.iloc[all_idx].reset_index(drop=True)\n",
    "    y_soft_over, w_conf_over = y_soft_tr[all_idx], w_conf_tr[all_idx]\n",
    "\n",
    "    y_hard_over = y_soft_over.argmax(axis=1)\n",
    "    counts_over = np.bincount(y_hard_over, minlength=6)\n",
    "\n",
    "    weights = (len(y_hard_over) / (counts_over + 1)) ** weight_power\n",
    "    weights = torch.FloatTensor(weights / weights.sum() * 6)\n",
    "\n",
    "    sample_weights = weights[y_hard_over].numpy()\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "\n",
    "    ds_tr = SpecDataset(df_tr_over, SPEC_DIR, y_soft_over, w_conf_over)\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=batch_size, sampler=sampler, num_workers=0)\n",
    "\n",
    "    ds_va = SpecDataset(meta_use.iloc[va_idx], SPEC_DIR, y_soft[va_idx], w_conf[va_idx])\n",
    "    dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    return dl_tr, dl_va, weights\n",
    "\n",
    "print(\"âœ… Hybrid loader ready (batch_size=16 for DenseNet-121)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2a4a1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Evaluation ready\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: Evaluation\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_full(model, loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "\n",
    "    for x, y, w in loader:\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        preds.append(logits.argmax(1).cpu().numpy())\n",
    "        targets.append(y.argmax(1).cpu().numpy())\n",
    "\n",
    "    y_pred = np.concatenate(preds)\n",
    "    y_true = np.concatenate(targets)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "    }\n",
    "\n",
    "print(\"âœ… Evaluation ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5113c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training function ready\n",
      "   Optimizers: Adam, AdamW, Adagrad\n",
      "   Activations: ReLU, LeakyReLU\n",
      "   Early stopping: patience=10\n"
     ]
    }
   ],
   "source": [
    "# CELL 8: Training Function\n",
    "\n",
    "def train_one_config(fold, optimizer_name, activation, l1_lambda, l2_lambda,\n",
    "                     lr=3e-4, batch_size=16, epochs=30, patience=10):\n",
    "\n",
    "    print(f\"      [1/5] Data...\", end=\" \", flush=True)\n",
    "    t0 = time.time()\n",
    "    dl_tr, dl_va, class_weights = create_hybrid_loader(fold=fold, batch_size=batch_size)\n",
    "    print(f\"âœ“ ({time.time()-t0:.1f}s)\", flush=True)\n",
    "\n",
    "    print(f\"      [2/5] Model (DenseNet-121, {activation})...\", end=\" \", flush=True)\n",
    "    t0 = time.time()\n",
    "    model = DenseNet121_Pretrained(\n",
    "        n_classes=6,\n",
    "        activation=activation,\n",
    "        freeze_backbone=False\n",
    "    ).to(device)\n",
    "    print(f\"âœ“ ({time.time()-t0:.1f}s)\", flush=True)\n",
    "\n",
    "    print(f\"      [3/5] Optimizer ({optimizer_name}, L2={l2_lambda:.0e})...\", end=\" \", flush=True)\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_lambda)\n",
    "    elif optimizer_name == 'adamw':\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=l2_lambda)\n",
    "    elif optimizer_name == 'adagrad':\n",
    "        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=l2_lambda)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
    "    print(\"âœ“\", flush=True)\n",
    "\n",
    "    print(f\"      [4/5] Loss & Scheduler...\", end=\" \", flush=True)\n",
    "    criterion = SoftFocalLoss(alpha=class_weights.to(device), gamma=3.0)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    print(\"âœ“\", flush=True)\n",
    "\n",
    "    print(f\"      [5/5] Training (patience={patience}, L1={l1_lambda:.0e})...\", flush=True)\n",
    "    best_f1, best_state, no_improve = 0.0, None, 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss, n = 0.0, 0\n",
    "\n",
    "        for x, y, w in dl_tr:\n",
    "            x, y, w = x.to(device), y.to(device), w.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y, w)\n",
    "\n",
    "            if l1_lambda > 0:\n",
    "                l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "                loss = loss + l1_lambda * l1_norm\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "            n += x.size(0)\n",
    "\n",
    "        train_loss /= max(n, 1)\n",
    "        val_results = evaluate_full(model, dl_va)\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_results['f1'] > best_f1:\n",
    "            best_f1 = val_results['f1']\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"        Early stop at epoch {epoch}\", flush=True)\n",
    "                break\n",
    "\n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            print(f\"        Epoch {epoch:2d}: F1={val_results['f1']:.4f}, Loss={train_loss:.4f}\", flush=True)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    final_results = evaluate_full(model, dl_va)\n",
    "\n",
    "    del model, optimizer, scheduler, dl_tr, dl_va\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return final_results\n",
    "\n",
    "print(\"âœ… Training function ready\")\n",
    "print(\"   Optimizers: Adam, AdamW, Adagrad\")\n",
    "print(\"   Activations: ReLU, LeakyReLU\")\n",
    "print(\"   Early stopping: patience=10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "547be4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "================= DENSENET-121 GRIDSEARCH - SAME AS RESNET-101 =================\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ HYPERPARAMETER GRID:\n",
      "--------------------------------------------------------------------------------\n",
      "  Optimizer:   ['adam', 'adamw', 'adagrad']\n",
      "  Activation:  ['relu', 'leakyrelu']\n",
      "  L1 lambda:   [0]\n",
      "  L2 lambda:   [0, 0.0001, 0.001]\n",
      "\n",
      "ðŸ“Š GRIDSEARCH STATISTICS:\n",
      "--------------------------------------------------------------------------------\n",
      "  Total combinations: 18\n",
      "  Folds per config:   3\n",
      "  Total trainings:    54\n",
      "\n",
      "ðŸ’¾ AUTO-SAVE:\n",
      "--------------------------------------------------------------------------------\n",
      "  densenet_gridsearch_results/densenet_gridsearch_progress.json\n",
      "  densenet_gridsearch_results/densenet_gridsearch_final.json\n"
     ]
    }
   ],
   "source": [
    "# CELL 9: Grid Configuration (SAME AS RESNET & EEGNET)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" DENSENET-121 GRIDSEARCH - SAME AS RESNET-101 \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'adamw', 'adagrad'],\n",
    "    'activation': ['relu', 'leakyrelu'],\n",
    "    'l1_lambda': [0],\n",
    "    'l2_lambda': [0, 1e-4, 1e-3],\n",
    "}\n",
    "\n",
    "fixed_params = {\n",
    "    'lr': 3e-4,\n",
    "    'batch_size': 16,\n",
    "    'epochs': 30,\n",
    "    'patience': 10,\n",
    "}\n",
    "\n",
    "keys = list(param_grid.keys())\n",
    "values = list(param_grid.values())\n",
    "combinations = list(product(*values))\n",
    "\n",
    "print(\"\\nðŸ“‹ HYPERPARAMETER GRID:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Optimizer:   {param_grid['optimizer']}\")\n",
    "print(f\"  Activation:  {param_grid['activation']}\")\n",
    "print(f\"  L1 lambda:   {param_grid['l1_lambda']}\")\n",
    "print(f\"  L2 lambda:   {param_grid['l2_lambda']}\")\n",
    "\n",
    "print(\"\\nðŸ“Š GRIDSEARCH STATISTICS:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Total combinations: {len(combinations)}\")\n",
    "print(f\"  Folds per config:   {N_FOLDS}\")\n",
    "print(f\"  Total trainings:    {len(combinations) * N_FOLDS}\")\n",
    "\n",
    "print(\"\\nðŸ’¾ AUTO-SAVE:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  {RESULTS_DIR}/densenet_gridsearch_progress.json\")\n",
    "print(f\"  {RESULTS_DIR}/densenet_gridsearch_final.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de9e8b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "============================= STARTING GRIDSEARCH ==============================\n",
      "================================================================================\n",
      "Started: 2026-01-25 23:53:26\n",
      "\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 1/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.5s)\n",
      "      [3/5] Optimizer (adam, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3353, Loss=0.8246\n",
      "        Epoch  5: F1=0.3313, Loss=0.3102\n",
      "        Epoch 10: F1=0.3510, Loss=0.1582\n",
      "        Early stop at epoch 14\n",
      "\n",
      "    âœ“ Fold 1: F1=0.3609 (35.7 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3182, Loss=0.8092\n",
      "        Epoch  5: F1=0.3574, Loss=0.3178\n",
      "        Epoch 10: F1=0.3426, Loss=0.1542\n",
      "        Epoch 15: F1=0.3621, Loss=0.1027\n",
      "        Epoch 20: F1=0.4320, Loss=0.0867\n",
      "        Epoch 25: F1=0.4936, Loss=0.0738\n",
      "        Epoch 30: F1=0.5014, Loss=0.0731\n",
      "\n",
      "    âœ“ Fold 2: F1=0.5054 (58.0 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2750, Loss=0.8048\n",
      "        Epoch  5: F1=0.3435, Loss=0.2925\n",
      "        Epoch 10: F1=0.3319, Loss=0.1519\n",
      "        Epoch 15: F1=0.3616, Loss=0.1110\n",
      "        Epoch 20: F1=0.4339, Loss=0.0884\n",
      "        Epoch 25: F1=0.4878, Loss=0.0787\n",
      "        Epoch 30: F1=0.4915, Loss=0.0793\n",
      "\n",
      "    âœ“ Fold 3: F1=0.4933 (56.5 min)\n",
      "\n",
      "  Mean F1:  0.4532 Â± 0.0655\n",
      "  Mean Acc: 0.4767\n",
      "  Mean Prec:0.4261\n",
      "  Mean Rec: 0.5128\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 2/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3023, Loss=0.8246\n",
      "        Epoch  5: F1=0.3518, Loss=0.3680\n",
      "        Epoch 10: F1=0.3442, Loss=0.1868\n",
      "        Early stop at epoch 15\n",
      "\n",
      "    âœ“ Fold 1: F1=0.3518 (28.3 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3072, Loss=0.8127\n",
      "        Epoch  5: F1=0.3516, Loss=0.3804\n",
      "        Epoch 10: F1=0.3371, Loss=0.1980\n",
      "        Epoch 15: F1=0.3351, Loss=0.1251\n",
      "        Epoch 20: F1=0.3738, Loss=0.0915\n",
      "        Epoch 25: F1=0.4221, Loss=0.0854\n",
      "        Epoch 30: F1=0.4532, Loss=0.0766\n",
      "\n",
      "    âœ“ Fold 2: F1=0.4599 (56.9 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3639, Loss=0.8423\n",
      "        Epoch  5: F1=0.3221, Loss=0.3842\n",
      "        Epoch 10: F1=0.3512, Loss=0.2073\n",
      "        Early stop at epoch 11\n",
      "\n",
      "    âœ“ Fold 3: F1=0.3639 (24.2 min)\n",
      "\n",
      "  Mean F1:  0.3918 Â± 0.0484\n",
      "  Mean Acc: 0.3954\n",
      "  Mean Prec:0.3563\n",
      "  Mean Rec: 0.4801\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 3/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2199, Loss=0.8333\n",
      "        Epoch  5: F1=0.2752, Loss=0.5370\n",
      "        Epoch 10: F1=0.3422, Loss=0.3769\n",
      "        Epoch 15: F1=0.3173, Loss=0.2707\n",
      "        Epoch 20: F1=0.3507, Loss=0.1695\n",
      "        Epoch 25: F1=0.3473, Loss=0.1132\n",
      "        Epoch 30: F1=0.3452, Loss=0.0988\n",
      "\n",
      "    âœ“ Fold 1: F1=0.3523 (56.8 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3100, Loss=0.8447\n",
      "        Epoch  5: F1=0.3221, Loss=0.5438\n",
      "        Epoch 10: F1=0.3437, Loss=0.3859\n",
      "        Epoch 15: F1=0.3358, Loss=0.2814\n",
      "        Epoch 20: F1=0.3385, Loss=0.1834\n",
      "        Epoch 25: F1=0.3396, Loss=0.1169\n",
      "        Early stop at epoch 27\n",
      "\n",
      "    âœ“ Fold 2: F1=0.3570 (51.3 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.1501, Loss=0.8462\n",
      "        Epoch  5: F1=0.3617, Loss=0.5817\n",
      "        Epoch 10: F1=0.3619, Loss=0.4173\n",
      "        Epoch 15: F1=0.2592, Loss=0.2916\n",
      "        Epoch 20: F1=0.3221, Loss=0.1910\n",
      "        Early stop at epoch 23\n",
      "\n",
      "    âœ“ Fold 3: F1=0.3693 (43.8 min)\n",
      "\n",
      "  Mean F1:  0.3595 Â± 0.0072\n",
      "  Mean Acc: 0.3548\n",
      "  Mean Prec:0.2941\n",
      "  Mean Rec: 0.4789\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 4/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2790, Loss=0.8147\n",
      "        Epoch  5: F1=0.2955, Loss=0.2895\n",
      "        Epoch 10: F1=0.3484, Loss=0.1547\n",
      "        Early stop at epoch 14\n",
      "\n",
      "    âœ“ Fold 1: F1=0.3674 (27.0 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2919, Loss=0.8058\n",
      "        Epoch  5: F1=0.3351, Loss=0.3052\n",
      "        Epoch 10: F1=0.3217, Loss=0.1582\n",
      "        Epoch 15: F1=0.3653, Loss=0.1006\n",
      "        Epoch 20: F1=0.4306, Loss=0.0803\n",
      "        Epoch 25: F1=0.4727, Loss=0.0741\n",
      "        Epoch 30: F1=0.4886, Loss=0.0707\n",
      "\n",
      "    âœ“ Fold 2: F1=0.4909 (56.8 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3291, Loss=0.8443\n",
      "        Epoch  5: F1=0.3751, Loss=0.3466\n",
      "        Epoch 10: F1=0.3719, Loss=0.1660\n",
      "        Epoch 15: F1=0.3825, Loss=0.1061\n",
      "        Epoch 20: F1=0.4532, Loss=0.0853\n",
      "        Epoch 25: F1=0.4978, Loss=0.0808\n",
      "        Epoch 30: F1=0.5083, Loss=0.0817\n",
      "\n",
      "    âœ“ Fold 3: F1=0.5140 (56.9 min)\n",
      "\n",
      "  Mean F1:  0.4574 Â± 0.0643\n",
      "  Mean Acc: 0.4770\n",
      "  Mean Prec:0.4346\n",
      "  Mean Rec: 0.5116\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 5/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3305, Loss=0.8080\n",
      "        Epoch  5: F1=0.2716, Loss=0.3703\n",
      "        Epoch 10: F1=0.3404, Loss=0.1931\n",
      "        Early stop at epoch 14\n",
      "\n",
      "    âœ“ Fold 1: F1=0.3568 (26.7 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3342, Loss=0.8158\n",
      "        Epoch  5: F1=0.3485, Loss=0.3655\n",
      "        Epoch 10: F1=0.3439, Loss=0.1886\n",
      "        Epoch 15: F1=0.3504, Loss=0.1227\n",
      "        Epoch 20: F1=0.3657, Loss=0.0914\n",
      "        Epoch 25: F1=0.4389, Loss=0.0770\n",
      "        Epoch 30: F1=0.4524, Loss=0.0766\n",
      "\n",
      "    âœ“ Fold 2: F1=0.4591 (57.1 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3425, Loss=0.8007\n",
      "        Epoch  5: F1=0.2994, Loss=0.3633\n",
      "        Epoch 10: F1=0.3399, Loss=0.1956\n",
      "        Epoch 15: F1=0.3551, Loss=0.1263\n",
      "        Epoch 20: F1=0.3761, Loss=0.1016\n",
      "        Epoch 25: F1=0.4628, Loss=0.0838\n",
      "        Epoch 30: F1=0.4774, Loss=0.0863\n",
      "\n",
      "    âœ“ Fold 3: F1=0.4824 (57.0 min)\n",
      "\n",
      "  Mean F1:  0.4328 Â± 0.0546\n",
      "  Mean Acc: 0.4449\n",
      "  Mean Prec:0.4093\n",
      "  Mean Rec: 0.4960\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 6/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3159, Loss=0.8648\n",
      "        Epoch  5: F1=0.3422, Loss=0.5832\n",
      "        Epoch 10: F1=0.3036, Loss=0.4065\n",
      "        Epoch 15: F1=0.3552, Loss=0.2832\n",
      "        Epoch 20: F1=0.3414, Loss=0.1916\n",
      "        Early stop at epoch 21\n",
      "\n",
      "    âœ“ Fold 1: F1=0.3685 (39.9 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3356, Loss=0.8641\n",
      "        Epoch  5: F1=0.3582, Loss=0.5662\n",
      "        Epoch 10: F1=0.3177, Loss=0.4062\n",
      "        Epoch 15: F1=0.3413, Loss=0.2789\n",
      "        Epoch 20: F1=0.3298, Loss=0.1904\n",
      "        Early stop at epoch 22\n",
      "\n",
      "    âœ“ Fold 2: F1=0.3628 (42.0 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adam, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2910, Loss=0.8651\n",
      "        Epoch  5: F1=0.3294, Loss=0.5925\n",
      "        Epoch 10: F1=0.3220, Loss=0.4033\n",
      "        Epoch 15: F1=0.3655, Loss=0.2860\n",
      "        Epoch 20: F1=0.3561, Loss=0.1867\n",
      "        Early stop at epoch 25\n",
      "\n",
      "    âœ“ Fold 3: F1=0.3655 (47.8 min)\n",
      "\n",
      "  Mean F1:  0.3656 Â± 0.0023\n",
      "  Mean Acc: 0.3571\n",
      "  Mean Prec:0.3062\n",
      "  Mean Rec: 0.4824\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 7/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2811, Loss=0.7946\n",
      "        Epoch  5: F1=0.3162, Loss=0.3056\n",
      "        Epoch 10: F1=0.3597, Loss=0.1543\n",
      "        Epoch 15: F1=0.3478, Loss=0.0996\n",
      "        Epoch 20: F1=0.4450, Loss=0.0838\n",
      "        Epoch 25: F1=0.4888, Loss=0.0722\n",
      "        Epoch 30: F1=0.4987, Loss=0.0722\n",
      "\n",
      "    âœ“ Fold 1: F1=0.5008 (56.9 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2738, Loss=0.7863\n",
      "        Epoch  5: F1=0.3304, Loss=0.3008\n",
      "        Epoch 10: F1=0.3400, Loss=0.1504\n",
      "        Epoch 15: F1=0.3685, Loss=0.1058\n",
      "        Epoch 20: F1=0.4043, Loss=0.0887\n",
      "        Epoch 25: F1=0.4612, Loss=0.0768\n",
      "        Epoch 30: F1=0.4749, Loss=0.0777\n",
      "\n",
      "    âœ“ Fold 2: F1=0.4779 (56.6 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3048, Loss=0.8407\n",
      "        Epoch  5: F1=0.3169, Loss=0.3368\n",
      "        Epoch 10: F1=0.3707, Loss=0.1600\n",
      "        Epoch 15: F1=0.3345, Loss=0.1075\n",
      "        Epoch 20: F1=0.4262, Loss=0.0905\n",
      "        Epoch 25: F1=0.4744, Loss=0.0774\n",
      "        Epoch 30: F1=0.5000, Loss=0.0742\n",
      "\n",
      "    âœ“ Fold 3: F1=0.5000 (59.8 min)\n",
      "\n",
      "  Mean F1:  0.4929 Â± 0.0106\n",
      "  Mean Acc: 0.5257\n",
      "  Mean Prec:0.4843\n",
      "  Mean Rec: 0.5197\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 8/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2974, Loss=0.8069\n",
      "        Epoch  5: F1=0.3480, Loss=0.3021\n",
      "        Epoch 10: F1=0.3244, Loss=0.1469\n",
      "        Epoch 15: F1=0.3397, Loss=0.1011\n",
      "        Epoch 20: F1=0.4225, Loss=0.0837\n",
      "        Epoch 25: F1=0.4744, Loss=0.0698\n",
      "        Epoch 30: F1=0.4831, Loss=0.0752\n",
      "\n",
      "    âœ“ Fold 1: F1=0.4929 (57.6 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3466, Loss=0.7711\n",
      "        Epoch  5: F1=0.3548, Loss=0.3020\n",
      "        Epoch 10: F1=0.3474, Loss=0.1509\n",
      "        Epoch 15: F1=0.3768, Loss=0.1043\n",
      "        Epoch 20: F1=0.4198, Loss=0.0789\n",
      "        Epoch 25: F1=0.4800, Loss=0.0733\n",
      "        Epoch 30: F1=0.4986, Loss=0.0720\n",
      "\n",
      "    âœ“ Fold 2: F1=0.4986 (57.0 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3348, Loss=0.8207\n",
      "        Epoch  5: F1=0.3400, Loss=0.3203\n",
      "        Epoch 10: F1=0.3530, Loss=0.1639\n",
      "        Early stop at epoch 12\n",
      "\n",
      "    âœ“ Fold 3: F1=0.3688 (22.8 min)\n",
      "\n",
      "  Mean F1:  0.4534 Â± 0.0599\n",
      "  Mean Acc: 0.4794\n",
      "  Mean Prec:0.4305\n",
      "  Mean Rec: 0.5103\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 9/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3092, Loss=0.8121\n",
      "        Epoch  5: F1=0.3277, Loss=0.3153\n",
      "        Epoch 10: F1=0.3459, Loss=0.1429\n",
      "        Epoch 15: F1=0.3635, Loss=0.0999\n",
      "        Epoch 20: F1=0.4184, Loss=0.0817\n",
      "        Epoch 25: F1=0.4638, Loss=0.0698\n",
      "        Epoch 30: F1=0.4960, Loss=0.0742\n",
      "\n",
      "    âœ“ Fold 1: F1=0.4965 (57.0 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3083, Loss=0.7938\n",
      "        Epoch  5: F1=0.3568, Loss=0.3021\n",
      "        Epoch 10: F1=0.3573, Loss=0.1496\n",
      "        Epoch 15: F1=0.3715, Loss=0.1065\n",
      "        Epoch 20: F1=0.4555, Loss=0.0829\n",
      "        Epoch 25: F1=0.4797, Loss=0.0777\n",
      "        Epoch 30: F1=0.4870, Loss=0.0814\n",
      "\n",
      "    âœ“ Fold 2: F1=0.4880 (57.1 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3153, Loss=0.8232\n",
      "        Epoch  5: F1=0.3486, Loss=0.3149\n",
      "        Epoch 10: F1=0.3430, Loss=0.1576\n",
      "        Epoch 15: F1=0.3322, Loss=0.1107\n",
      "        Epoch 20: F1=0.4287, Loss=0.0883\n",
      "        Epoch 25: F1=0.4687, Loss=0.0796\n",
      "        Epoch 30: F1=0.4844, Loss=0.0786\n",
      "\n",
      "    âœ“ Fold 3: F1=0.4844 (57.6 min)\n",
      "\n",
      "  Mean F1:  0.4896 Â± 0.0050\n",
      "  Mean Acc: 0.5319\n",
      "  Mean Prec:0.4821\n",
      "  Mean Rec: 0.5154\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 10/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2757, Loss=0.8107\n",
      "        Epoch  5: F1=0.3471, Loss=0.3129\n",
      "        Epoch 10: F1=0.3574, Loss=0.1564\n",
      "        Epoch 15: F1=0.3921, Loss=0.1059\n",
      "        Epoch 20: F1=0.4166, Loss=0.0855\n",
      "        Epoch 25: F1=0.5045, Loss=0.0815\n",
      "        Epoch 30: F1=0.5097, Loss=0.0794\n",
      "\n",
      "    âœ“ Fold 1: F1=0.5097 (63.8 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (1.0s)\n",
      "      [3/5] Optimizer (adamw, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3030, Loss=0.8001\n",
      "        Epoch  5: F1=0.3333, Loss=0.3212\n",
      "        Epoch 10: F1=0.3257, Loss=0.1510\n",
      "        Epoch 15: F1=0.3609, Loss=0.1017\n",
      "        Epoch 20: F1=0.4038, Loss=0.0825\n",
      "        Epoch 25: F1=0.4572, Loss=0.0758\n",
      "        Epoch 30: F1=0.4722, Loss=0.0685\n",
      "\n",
      "    âœ“ Fold 2: F1=0.4722 (59.4 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3300, Loss=0.8160\n",
      "        Epoch  5: F1=0.3386, Loss=0.3171\n",
      "        Epoch 10: F1=0.3563, Loss=0.1602\n",
      "        Epoch 15: F1=0.3603, Loss=0.1092\n",
      "        Epoch 20: F1=0.4354, Loss=0.0851\n",
      "        Epoch 25: F1=0.4794, Loss=0.0798\n",
      "        Epoch 30: F1=0.4973, Loss=0.0821\n",
      "\n",
      "    âœ“ Fold 3: F1=0.4973 (56.7 min)\n",
      "\n",
      "  Mean F1:  0.4931 Â± 0.0156\n",
      "  Mean Acc: 0.5289\n",
      "  Mean Prec:0.4853\n",
      "  Mean Rec: 0.5198\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 11/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3231, Loss=0.8130\n",
      "        Epoch  5: F1=0.3329, Loss=0.3254\n",
      "        Epoch 10: F1=0.3583, Loss=0.1655\n",
      "        Early stop at epoch 12\n",
      "\n",
      "    âœ“ Fold 1: F1=0.3631 (23.3 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3168, Loss=0.7885\n",
      "        Epoch  5: F1=0.3122, Loss=0.2972\n",
      "        Epoch 10: F1=0.3569, Loss=0.1493\n",
      "        Epoch 15: F1=0.3585, Loss=0.1012\n",
      "        Epoch 20: F1=0.4244, Loss=0.0841\n",
      "        Epoch 25: F1=0.4703, Loss=0.0799\n",
      "        Epoch 30: F1=0.4773, Loss=0.0724\n",
      "\n",
      "    âœ“ Fold 2: F1=0.4860 (57.1 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3443, Loss=0.8304\n",
      "        Epoch  5: F1=0.3350, Loss=0.3239\n",
      "        Epoch 10: F1=0.3771, Loss=0.1620\n",
      "        Epoch 15: F1=0.3727, Loss=0.0985\n",
      "        Epoch 20: F1=0.4233, Loss=0.0847\n",
      "        Epoch 25: F1=0.5031, Loss=0.0794\n",
      "        Epoch 30: F1=0.5123, Loss=0.0792\n",
      "\n",
      "    âœ“ Fold 3: F1=0.5127 (56.9 min)\n",
      "\n",
      "  Mean F1:  0.4539 Â± 0.0652\n",
      "  Mean Acc: 0.4777\n",
      "  Mean Prec:0.4340\n",
      "  Mean Rec: 0.5106\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 12/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3088, Loss=0.7946\n",
      "        Epoch  5: F1=0.3508, Loss=0.3093\n",
      "        Epoch 10: F1=0.3612, Loss=0.1554\n",
      "        Epoch 15: F1=0.3605, Loss=0.1058\n",
      "        Epoch 20: F1=0.4327, Loss=0.0865\n",
      "        Epoch 25: F1=0.4729, Loss=0.0770\n",
      "        Epoch 30: F1=0.4897, Loss=0.0760\n",
      "\n",
      "    âœ“ Fold 1: F1=0.4955 (58.3 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3515, Loss=0.8100\n",
      "        Epoch  5: F1=0.3305, Loss=0.3113\n",
      "        Epoch 10: F1=0.3526, Loss=0.1638\n",
      "        Early stop at epoch 13\n",
      "\n",
      "    âœ“ Fold 2: F1=0.3620 (25.0 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2556, Loss=0.8070\n",
      "        Epoch  5: F1=0.3569, Loss=0.3266\n",
      "        Epoch 10: F1=0.3453, Loss=0.1562\n",
      "        Epoch 15: F1=0.3824, Loss=0.1039\n",
      "        Epoch 20: F1=0.4263, Loss=0.0870\n",
      "        Epoch 25: F1=0.4803, Loss=0.0798\n",
      "        Epoch 30: F1=0.4987, Loss=0.0705\n",
      "\n",
      "    âœ“ Fold 3: F1=0.4987 (57.1 min)\n",
      "\n",
      "  Mean F1:  0.4521 Â± 0.0637\n",
      "  Mean Acc: 0.4742\n",
      "  Mean Prec:0.4258\n",
      "  Mean Rec: 0.5068\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 13/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3479, Loss=0.7840\n",
      "        Epoch  5: F1=0.3602, Loss=0.3860\n",
      "        Epoch 10: F1=0.3541, Loss=0.2425\n",
      "        Early stop at epoch 12\n",
      "\n",
      "    âœ“ Fold 1: F1=0.3618 (23.0 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3508, Loss=0.7809\n",
      "        Epoch  5: F1=0.3621, Loss=0.3972\n",
      "        Epoch 10: F1=0.3638, Loss=0.2377\n",
      "        Epoch 15: F1=0.3613, Loss=0.1790\n",
      "        Early stop at epoch 16\n",
      "\n",
      "    âœ“ Fold 2: F1=0.3682 (30.5 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3518, Loss=0.7844\n",
      "        Epoch  5: F1=0.3655, Loss=0.3829\n",
      "        Epoch 10: F1=0.3705, Loss=0.2407\n",
      "        Epoch 15: F1=0.3652, Loss=0.1786\n",
      "        Early stop at epoch 16\n",
      "\n",
      "    âœ“ Fold 3: F1=0.3748 (30.4 min)\n",
      "\n",
      "  Mean F1:  0.3682 Â± 0.0053\n",
      "  Mean Acc: 0.3550\n",
      "  Mean Prec:0.3015\n",
      "  Mean Rec: 0.4996\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 14/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3384, Loss=0.8040\n",
      "        Epoch  5: F1=0.3629, Loss=0.3818\n",
      "        Epoch 10: F1=0.3493, Loss=0.2254\n",
      "        Early stop at epoch 15\n",
      "\n",
      "    âœ“ Fold 1: F1=0.3629 (28.7 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3440, Loss=0.8205\n",
      "        Epoch  5: F1=0.3630, Loss=0.4002\n",
      "        Epoch 10: F1=0.3619, Loss=0.2353\n",
      "        Early stop at epoch 14\n",
      "\n",
      "    âœ“ Fold 2: F1=0.3693 (26.9 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3458, Loss=0.8091\n",
      "        Epoch  5: F1=0.3793, Loss=0.4019\n",
      "        Epoch 10: F1=0.3712, Loss=0.2387\n",
      "        Early stop at epoch 15\n",
      "\n",
      "    âœ“ Fold 3: F1=0.3793 (28.5 min)\n",
      "\n",
      "  Mean F1:  0.3705 Â± 0.0068\n",
      "  Mean Acc: 0.3563\n",
      "  Mean Prec:0.3047\n",
      "  Mean Rec: 0.5022\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 15/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3437, Loss=0.7814\n",
      "        Epoch  5: F1=0.3603, Loss=0.3510\n",
      "        Epoch 10: F1=0.3549, Loss=0.1916\n",
      "        Early stop at epoch 13\n",
      "\n",
      "    âœ“ Fold 1: F1=0.3617 (24.6 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3392, Loss=0.7859\n",
      "        Epoch  5: F1=0.3572, Loss=0.3661\n",
      "        Epoch 10: F1=0.3558, Loss=0.2044\n",
      "        Epoch 15: F1=0.3563, Loss=0.1575\n",
      "        Early stop at epoch 17\n",
      "\n",
      "    âœ“ Fold 2: F1=0.3640 (32.7 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, relu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3536, Loss=0.8198\n",
      "        Epoch  5: F1=0.3684, Loss=0.3889\n",
      "        Epoch 10: F1=0.3687, Loss=0.2127\n",
      "        Early stop at epoch 14\n",
      "\n",
      "    âœ“ Fold 3: F1=0.3773 (27.5 min)\n",
      "\n",
      "  Mean F1:  0.3677 Â± 0.0069\n",
      "  Mean Acc: 0.3543\n",
      "  Mean Prec:0.3036\n",
      "  Mean Rec: 0.4942\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 16/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3412, Loss=0.7947\n",
      "        Epoch  5: F1=0.3577, Loss=0.3878\n",
      "        Epoch 10: F1=0.3507, Loss=0.2356\n",
      "        Epoch 15: F1=0.3542, Loss=0.1832\n",
      "        Early stop at epoch 18\n",
      "\n",
      "    âœ“ Fold 1: F1=0.3578 (35.3 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3389, Loss=0.7905\n",
      "        Epoch  5: F1=0.3630, Loss=0.3774\n",
      "        Epoch 10: F1=0.3593, Loss=0.2286\n",
      "        Epoch 15: F1=0.3612, Loss=0.1780\n",
      "        Epoch 20: F1=0.3550, Loss=0.1520\n",
      "        Epoch 25: F1=0.3559, Loss=0.1518\n",
      "        Early stop at epoch 26\n",
      "\n",
      "    âœ“ Fold 2: F1=0.3668 (50.4 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=0e+00)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3596, Loss=0.7805\n",
      "        Epoch  5: F1=0.3664, Loss=0.3763\n",
      "        Epoch 10: F1=0.3630, Loss=0.2414\n",
      "        Epoch 15: F1=0.3703, Loss=0.1836\n",
      "        Epoch 20: F1=0.3637, Loss=0.1614\n",
      "        Early stop at epoch 25\n",
      "\n",
      "    âœ“ Fold 3: F1=0.3703 (48.3 min)\n",
      "\n",
      "  Mean F1:  0.3649 Â± 0.0052\n",
      "  Mean Acc: 0.3585\n",
      "  Mean Prec:0.2962\n",
      "  Mean Rec: 0.4923\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 17/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3482, Loss=0.8164\n",
      "        Epoch  5: F1=0.3586, Loss=0.3636\n",
      "        Epoch 10: F1=0.3499, Loss=0.2302\n",
      "        Early stop at epoch 13\n",
      "\n",
      "    âœ“ Fold 1: F1=0.3593 (25.4 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3477, Loss=0.8134\n",
      "        Epoch  5: F1=0.3700, Loss=0.4137\n",
      "        Epoch 10: F1=0.3663, Loss=0.2518\n",
      "        Epoch 15: F1=0.3670, Loss=0.1842\n",
      "        Early stop at epoch 18\n",
      "\n",
      "    âœ“ Fold 2: F1=0.3713 (35.1 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-04)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3426, Loss=0.8105\n",
      "        Epoch  5: F1=0.3564, Loss=0.3854\n",
      "        Epoch 10: F1=0.3590, Loss=0.2333\n",
      "        Early stop at epoch 13\n",
      "\n",
      "    âœ“ Fold 3: F1=0.3664 (25.4 min)\n",
      "\n",
      "  Mean F1:  0.3657 Â± 0.0049\n",
      "  Mean Acc: 0.3544\n",
      "  Mean Prec:0.2992\n",
      "  Mean Rec: 0.4946\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 18/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3489, Loss=0.7891\n",
      "        Epoch  5: F1=0.3632, Loss=0.3373\n",
      "        Epoch 10: F1=0.3578, Loss=0.2095\n",
      "        Epoch 15: F1=0.3559, Loss=0.1548\n",
      "        Early stop at epoch 17\n",
      "\n",
      "    âœ“ Fold 1: F1=0.3662 (32.9 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (0.2s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3398, Loss=0.8221\n",
      "        Epoch  5: F1=0.3623, Loss=0.3577\n",
      "        Epoch 10: F1=0.3563, Loss=0.2014\n",
      "        Epoch 15: F1=0.3464, Loss=0.1443\n",
      "        Early stop at epoch 16\n",
      "\n",
      "    âœ“ Fold 2: F1=0.3658 (31.7 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... âœ“ (0.0s)\n",
      "      [2/5] Model (DenseNet-121, leakyrelu)... âœ“ (1.5s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-03)... âœ“\n",
      "      [4/5] Loss & Scheduler... âœ“\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3404, Loss=0.7765\n",
      "        Epoch  5: F1=0.3611, Loss=0.3692\n",
      "        Epoch 10: F1=0.3541, Loss=0.2078\n",
      "        Early stop at epoch 13\n",
      "\n",
      "    âœ“ Fold 3: F1=0.3648 (27.3 min)\n",
      "\n",
      "  Mean F1:  0.3656 Â± 0.0006\n",
      "  Mean Acc: 0.3620\n",
      "  Mean Prec:0.2945\n",
      "  Mean Rec: 0.4953\n",
      "  ðŸ’¾ Saved\n",
      "\n",
      "================================================================================\n",
      "============================= GRIDSEARCH COMPLETE ==============================\n",
      "================================================================================\n",
      "Total time: 38.78 hours\n"
     ]
    }
   ],
   "source": [
    "# CELL 10: Run GridSearch\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" STARTING GRIDSEARCH \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "all_results = []\n",
    "start_time = time.time()\n",
    "\n",
    "for combo_idx, combo in enumerate(combinations, 1):\n",
    "    params = dict(zip(keys, combo))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\" CONFIG {combo_idx}/{len(combinations)} \".center(80, \"=\"))\n",
    "    print(\"=\"*80)\n",
    "    print(f\"  Optimizer: {params['optimizer']}\")\n",
    "    print(f\"  Activation: {params['activation']}\")\n",
    "    print(f\"  L1: {params['l1_lambda']:.0e}\")\n",
    "    print(f\"  L2: {params['l2_lambda']:.0e}\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "    fold_results = []\n",
    "\n",
    "    for fold in range(N_FOLDS):\n",
    "        print(f\"\\n    Fold {fold+1}/{N_FOLDS}...\", flush=True)\n",
    "        fold_start = time.time()\n",
    "\n",
    "        try:\n",
    "            result = train_one_config(\n",
    "                fold=fold,\n",
    "                optimizer_name=params['optimizer'],\n",
    "                activation=params['activation'],\n",
    "                l1_lambda=params['l1_lambda'],\n",
    "                l2_lambda=params['l2_lambda'],\n",
    "                **fixed_params\n",
    "            )\n",
    "            fold_results.append(result)\n",
    "            print(f\"\\n    âœ“ Fold {fold+1}: F1={result['f1']:.4f} ({(time.time()-fold_start)/60:.1f} min)\", flush=True)\n",
    "        except Exception as e:\n",
    "            print(f\"\\n    âœ— Error: {e}\", flush=True)\n",
    "            fold_results.append({'f1': 0.0, 'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0})\n",
    "\n",
    "    mean_metrics = {\n",
    "        'f1': float(np.mean([r['f1'] for r in fold_results])),\n",
    "        'accuracy': float(np.mean([r['accuracy'] for r in fold_results])),\n",
    "        'precision': float(np.mean([r['precision'] for r in fold_results])),\n",
    "        'recall': float(np.mean([r['recall'] for r in fold_results])),\n",
    "        'f1_std': float(np.std([r['f1'] for r in fold_results])),\n",
    "    }\n",
    "\n",
    "    result_entry = {\n",
    "        'config_id': combo_idx,\n",
    "        'params': params,\n",
    "        'mean_metrics': mean_metrics,\n",
    "        'fold_results': fold_results,\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    }\n",
    "    all_results.append(result_entry)\n",
    "\n",
    "    print(f\"\\n  Mean F1:  {mean_metrics['f1']:.4f} Â± {mean_metrics['f1_std']:.4f}\")\n",
    "    print(f\"  Mean Acc: {mean_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Mean Prec:{mean_metrics['precision']:.4f}\")\n",
    "    print(f\"  Mean Rec: {mean_metrics['recall']:.4f}\")\n",
    "\n",
    "    with open(RESULTS_DIR / 'densenet_gridsearch_progress.json', 'w') as f:\n",
    "        json.dump(all_results, f, indent=2, default=str)\n",
    "    print(\"  ðŸ’¾ Saved\", flush=True)\n",
    "\n",
    "with open(RESULTS_DIR / 'densenet_gridsearch_final.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'all_results': all_results,\n",
    "        'param_grid': param_grid,\n",
    "        'fixed_params': fixed_params,\n",
    "        'total_time_hours': (time.time() - start_time) / 3600,\n",
    "    }, f, indent=2, default=str)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" GRIDSEARCH COMPLETE \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"Total time: {(time.time()-start_time)/3600:.2f} hours\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71875e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "======================= DENSENET-121 GRIDSEARCH RESULTS ========================\n",
      "================================================================================\n",
      "\n",
      "ðŸ† TOP 10 CONFIGURATIONS:\n",
      "================================================================================\n",
      "Rank    Optimizer   Activation       L1       L2         F1      Acc     Prec      Rec\n",
      "--------------------------------------------------------------------------------\n",
      "1           adamw    leakyrelu    0e+00    0e+00     0.4931   0.5289   0.4853   0.5198\n",
      "2           adamw         relu    0e+00    0e+00     0.4929   0.5257   0.4843   0.5197\n",
      "3           adamw         relu    0e+00    1e-03     0.4896   0.5319   0.4821   0.5154\n",
      "4            adam    leakyrelu    0e+00    0e+00     0.4574   0.4770   0.4346   0.5116\n",
      "5           adamw    leakyrelu    0e+00    1e-04     0.4539   0.4777   0.4340   0.5106\n",
      "6           adamw         relu    0e+00    1e-04     0.4534   0.4794   0.4305   0.5103\n",
      "7            adam         relu    0e+00    0e+00     0.4532   0.4767   0.4261   0.5128\n",
      "8           adamw    leakyrelu    0e+00    1e-03     0.4521   0.4742   0.4258   0.5068\n",
      "9            adam    leakyrelu    0e+00    1e-04     0.4328   0.4449   0.4093   0.4960\n",
      "10           adam         relu    0e+00    1e-04     0.3918   0.3954   0.3563   0.4801\n",
      "\n",
      "================================================================================\n",
      "======================= BEST DENSENET-121 CONFIGURATION ========================\n",
      "================================================================================\n",
      "  Optimizer:  adamw\n",
      "  Activation: leakyrelu\n",
      "  L1:         0e+00\n",
      "  L2:         0e+00\n",
      "\n",
      "  F1:        0.4931 Â± 0.0156\n",
      "  Accuracy:  0.5289\n",
      "  Precision: 0.4853\n",
      "  Recall:    0.5198\n",
      "\n",
      "ðŸ’¾ Results saved to:\n",
      "   densenet_gridsearch_results/densenet_gridsearch_final.json\n"
     ]
    }
   ],
   "source": [
    "# CELL 11: Analyze Results (F1 + Acc + Precision + Recall)\n",
    "\n",
    "sorted_results = sorted(all_results, key=lambda x: x['mean_metrics']['f1'], reverse=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" DENSENET-121 GRIDSEARCH RESULTS \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ† TOP 10 CONFIGURATIONS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Rank':<6} {'Optimizer':>10} {'Activation':>12} {'L1':>8} {'L2':>8} \"\n",
    "      f\"{'F1':>10} {'Acc':>8} {'Prec':>8} {'Rec':>8}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for i, result in enumerate(sorted_results[:10], 1):\n",
    "    p = result['params']\n",
    "    m = result['mean_metrics']\n",
    "    print(f\"{i:<6} {p['optimizer']:>10} {p['activation']:>12} {p['l1_lambda']:>8.0e} \"\n",
    "          f\"{p['l2_lambda']:>8.0e} {m['f1']:>10.4f} {m['accuracy']:>8.4f} \"\n",
    "          f\"{m['precision']:>8.4f} {m['recall']:>8.4f}\")\n",
    "\n",
    "best = sorted_results[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" BEST DENSENET-121 CONFIGURATION \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"  Optimizer:  {best['params']['optimizer']}\")\n",
    "print(f\"  Activation: {best['params']['activation']}\")\n",
    "print(f\"  L1:         {best['params']['l1_lambda']:.0e}\")\n",
    "print(f\"  L2:         {best['params']['l2_lambda']:.0e}\")\n",
    "\n",
    "print(f\"\\n  F1:        {best['mean_metrics']['f1']:.4f} Â± {best['mean_metrics']['f1_std']:.4f}\")\n",
    "print(f\"  Accuracy:  {best['mean_metrics']['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {best['mean_metrics']['precision']:.4f}\")\n",
    "print(f\"  Recall:    {best['mean_metrics']['recall']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ’¾ Results saved to:\")\n",
    "print(f\"   {RESULTS_DIR}/densenet_gridsearch_final.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad5b708-bd78-4741-9481-39c3a98e6713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jkl)",
   "language": "python",
   "name": "jkl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
