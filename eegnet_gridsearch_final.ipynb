{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ EEGNet GridSearch - Fair Comparison\n",
    "\n",
    "**Same Parameters as ResNet-101:**\n",
    "1. ‚úÖ **Optimizer**: Adam, AdamW, Adagrad\n",
    "2. ‚úÖ **Activation**: ReLU, LeakyReLU\n",
    "3. ‚úÖ **L1**: [0] (same as ResNet)\n",
    "4. ‚úÖ **L2**: [0, 1e-4, 1e-3]\n",
    "5. ‚úÖ **Early Stopping**: patience=10\n",
    "6. ‚úÖ **LR Scheduler**: CosineAnnealingLR\n",
    "7. ‚úÖ **Loss**: SoftFocalLoss (gamma=3.0)\n",
    "8. ‚úÖ **Data**: Hybrid loading\n",
    "9. ‚úÖ **CV**: 3-fold\n",
    "\n",
    "**Total: 18 configs √ó 3 folds = 54 runs (~9 hours)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ CELL 1: Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "===================== EEGNet GridSearch - Fair Comparison ======================\n",
      "================================================================================\n",
      "\n",
      "Started: 2026-01-14 15:25:31\n",
      "‚úÖ Seed: 42\n",
      "‚úÖ Device: cuda:0\n",
      "   GPU: NVIDIA GeForce RTX 5060 Ti\n",
      "\n",
      "‚úÖ Results: eegnet_gridsearch_results\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" EEGNet GridSearch - Fair Comparison \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nStarted: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Reproducibility\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)\n",
    "print(\"‚úÖ Seed: 42\")\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Paths\n",
    "DATA_PKG = Path(\"data_package\")\n",
    "SPEC_DIR = Path(\"spec_hr_out\")\n",
    "RESULTS_DIR = Path(\"eegnet_gridsearch_results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Results: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä CELL 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded\n",
      "   Samples: 17089\n",
      "   Classes: ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n",
      "\n",
      "‚úÖ Created 3-fold CV\n"
     ]
    }
   ],
   "source": [
    "meta_use = pd.read_csv(DATA_PKG / \"meta_use.csv\")\n",
    "lbl = np.load(DATA_PKG / \"labels.npz\", allow_pickle=True)\n",
    "y_soft = lbl[\"y_soft\"]\n",
    "w_conf = lbl[\"w_conf\"]\n",
    "classes = [str(c) for c in lbl[\"classes\"]]\n",
    "y_hard = y_soft.argmax(axis=1)\n",
    "\n",
    "print(\"‚úÖ Data loaded\")\n",
    "print(f\"   Samples: {len(y_hard)}\")\n",
    "print(f\"   Classes: {classes}\")\n",
    "\n",
    "# 3-fold CV (SAME AS RESNET & KAN)\n",
    "N_FOLDS = 3\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "folds = list(skf.split(meta_use, y_hard))\n",
    "print(f\"\\n‚úÖ Created {N_FOLDS}-fold CV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ CELL 3: Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset ready\n"
     ]
    }
   ],
   "source": [
    "class SpecDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, y_soft, w_conf, F_target=81, T_target=600):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root = Path(root_dir)\n",
    "        self.y_soft = y_soft\n",
    "        self.w_conf = w_conf\n",
    "        self.F_target = F_target\n",
    "        self.T_target = T_target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _center_crop_pad(self, x):\n",
    "        C, F, T = x.shape\n",
    "        if F >= self.F_target:\n",
    "            f0 = (F - self.F_target) // 2\n",
    "            x = x[:, f0:f0+self.F_target, :]\n",
    "        else:\n",
    "            pad = self.F_target - F\n",
    "            x = np.pad(x, ((0,0),(pad//2, pad-pad//2),(0,0)), mode=\"constant\")\n",
    "        if T >= self.T_target:\n",
    "            t0 = (T - self.T_target) // 2\n",
    "            x = x[:, :, t0:t0+self.T_target]\n",
    "        else:\n",
    "            pad = self.T_target - T\n",
    "            x = np.pad(x, ((0,0),(0,0),(pad//2, pad-pad//2)), mode=\"constant\")\n",
    "        return x.copy()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        eid = int(row.eeg_id)\n",
    "        \n",
    "        npz = np.load(self.root / f\"{eid}_hr.npz\")\n",
    "        x = npz[\"x\"]\n",
    "        x = self._center_crop_pad(x)\n",
    "        x = torch.from_numpy(x).float()\n",
    "        x = F.interpolate(x.unsqueeze(0), size=(224, 224),\n",
    "                          mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "        \n",
    "        y = torch.from_numpy(self.y_soft[self.df.index[idx]]).float()\n",
    "        w = torch.tensor(self.w_conf[self.df.index[idx]], dtype=torch.float32)\n",
    "        \n",
    "        return x, y, w\n",
    "\n",
    "print(\"‚úÖ Dataset ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è CELL 4: EEGNet Model (Configurable Activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ EEGNet model ready\n",
      "   Supports: ReLU, LeakyReLU\n"
     ]
    }
   ],
   "source": [
    "class EEGNet_Configurable(nn.Module):\n",
    "    \"\"\"EEGNet with configurable activation function\"\"\"\n",
    "    \n",
    "    def __init__(self, n_classes=6, n_channels=4, activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store activation type\n",
    "        self.activation_name = activation\n",
    "        \n",
    "        # Block 1: Temporal convolution\n",
    "        self.conv1 = nn.Conv2d(n_channels, 8, kernel_size=(1, 64), \n",
    "                              padding=(0, 32), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        \n",
    "        # Block 2: Depthwise spatial convolution\n",
    "        self.dw_conv = nn.Conv2d(8, 16, kernel_size=(224, 1), \n",
    "                                groups=8, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=(1, 4))\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        \n",
    "        # Block 3: Separable convolution\n",
    "        self.sep_conv = nn.Conv2d(16, 16, kernel_size=(1, 16), \n",
    "                                 padding=(0, 8), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(16)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=(1, 8))\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        \n",
    "        # Calculate flattened size\n",
    "        self.flat_size = 16 * 7\n",
    "        \n",
    "        # Classifier\n",
    "        self.fc1 = nn.Linear(self.flat_size, 64)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, n_classes)\n",
    "    \n",
    "    def get_activation(self):\n",
    "        \"\"\"Return activation function based on config\"\"\"\n",
    "        if self.activation_name == 'relu':\n",
    "            return F.relu\n",
    "        elif self.activation_name == 'leakyrelu':\n",
    "            return lambda x: F.leaky_relu(x, negative_slope=0.01)\n",
    "        else:\n",
    "            return F.relu  # default\n",
    "    \n",
    "    def forward(self, x):\n",
    "        act = self.get_activation()\n",
    "        \n",
    "        # Block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = act(x)\n",
    "        \n",
    "        # Block 2\n",
    "        x = self.dw_conv(x)\n",
    "        x = self.bn2(x)\n",
    "        x = act(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Block 3\n",
    "        x = self.sep_conv(x)\n",
    "        x = self.bn3(x)\n",
    "        x = act(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Classifier\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = act(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "print(\"‚úÖ EEGNet model ready\")\n",
    "print(\"   Supports: ReLU, LeakyReLU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ CELL 5: SoftFocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SoftFocalLoss ready\n"
     ]
    }
   ],
   "source": [
    "class SoftFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=3.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, logits, soft_targets, sample_weights=None):\n",
    "        hard_targets = soft_targets.argmax(dim=1)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        p_t = probs.gather(1, hard_targets.unsqueeze(1)).squeeze(1)\n",
    "        ce_loss = -(soft_targets * F.log_softmax(logits, dim=1)).sum(dim=1)\n",
    "        focal_weight = ((1 - p_t) ** self.gamma)\n",
    "        loss = focal_weight * ce_loss\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha[hard_targets]\n",
    "            loss = alpha_t * loss\n",
    "        \n",
    "        if sample_weights is not None:\n",
    "            loss = loss * sample_weights\n",
    "        \n",
    "        return loss.mean()\n",
    "\n",
    "print(\"‚úÖ SoftFocalLoss ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ CELL 6: Hybrid Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Hybrid loader ready\n"
     ]
    }
   ],
   "source": [
    "def create_hybrid_loader(fold=0, target_ratio=0.4, weight_power=3.0, batch_size=16):\n",
    "    tr_idx, va_idx = folds[fold]\n",
    "    df_tr = meta_use.iloc[tr_idx]\n",
    "    y_soft_tr, w_conf_tr = y_soft[tr_idx], w_conf[tr_idx]\n",
    "    \n",
    "    y_hard = y_soft_tr.argmax(axis=1)\n",
    "    counts = np.bincount(y_hard, minlength=6)\n",
    "    target = int(counts.max() * target_ratio)\n",
    "    \n",
    "    indices_add = []\n",
    "    for i in range(6):\n",
    "        mask = y_hard == i\n",
    "        if mask.sum() < target:\n",
    "            idx = np.where(mask)[0]\n",
    "            n_add = target - mask.sum()\n",
    "            indices_add.extend(np.random.choice(idx, n_add, replace=True))\n",
    "    \n",
    "    all_idx = np.concatenate([np.arange(len(y_hard)), indices_add])\n",
    "    np.random.shuffle(all_idx)\n",
    "    \n",
    "    df_tr_over = df_tr.iloc[all_idx].reset_index(drop=True)\n",
    "    y_soft_over, w_conf_over = y_soft_tr[all_idx], w_conf_tr[all_idx]\n",
    "    \n",
    "    y_hard_over = y_soft_over.argmax(axis=1)\n",
    "    counts_over = np.bincount(y_hard_over, minlength=6)\n",
    "    \n",
    "    weights = (len(y_hard_over) / (counts_over + 1)) ** weight_power\n",
    "    weights = torch.FloatTensor(weights / weights.sum() * 6)\n",
    "    \n",
    "    sample_weights = weights[y_hard_over].numpy()\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    ds_tr = SpecDataset(df_tr_over, SPEC_DIR, y_soft_over, w_conf_over)\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=batch_size, sampler=sampler, num_workers=0)\n",
    "    \n",
    "    ds_va = SpecDataset(meta_use.iloc[va_idx], SPEC_DIR, y_soft[va_idx], w_conf[va_idx])\n",
    "    dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    return dl_tr, dl_va, weights\n",
    "\n",
    "print(\"‚úÖ Hybrid loader ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà CELL 7: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Evaluation ready\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_full(model, loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    \n",
    "    for x, y, w in loader:\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        preds.append(logits.argmax(1).cpu().numpy())\n",
    "        targets.append(y.argmax(1).cpu().numpy())\n",
    "    \n",
    "    y_pred = np.concatenate(preds)\n",
    "    y_true = np.concatenate(targets)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Evaluation ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è CELL 8: Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training function ready\n",
      "   Optimizers: Adam, AdamW, Adagrad\n",
      "   Activations: ReLU, LeakyReLU\n",
      "   L1/L2 regularization supported\n",
      "   Early stopping: patience=10\n"
     ]
    }
   ],
   "source": [
    "def train_one_config(fold, optimizer_name, activation, l1_lambda, l2_lambda,\n",
    "                     lr=3e-4, batch_size=16, epochs=30, patience=10):\n",
    "    import sys\n",
    "    \n",
    "    # Data\n",
    "    print(f\"      [1/5] Data...\", end=\" \", flush=True)\n",
    "    t0 = time.time()\n",
    "    dl_tr, dl_va, class_weights = create_hybrid_loader(fold=fold, batch_size=batch_size)\n",
    "    print(f\"‚úì ({time.time()-t0:.1f}s)\", flush=True)\n",
    "    \n",
    "    # Model\n",
    "    print(f\"      [2/5] Model ({activation})...\", end=\" \", flush=True)\n",
    "    t0 = time.time()\n",
    "    model = EEGNet_Configurable(\n",
    "        n_classes=6, \n",
    "        n_channels=4,\n",
    "        activation=activation\n",
    "    ).to(device)\n",
    "    print(f\"‚úì ({time.time()-t0:.1f}s)\", flush=True)\n",
    "    \n",
    "    # Optimizer\n",
    "    print(f\"      [3/5] Optimizer ({optimizer_name}, L2={l2_lambda:.0e})...\", end=\" \", flush=True)\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_lambda)\n",
    "    elif optimizer_name == 'adamw':\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=l2_lambda)\n",
    "    elif optimizer_name == 'adagrad':\n",
    "        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=l2_lambda)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
    "    print(f\"‚úì\", flush=True)\n",
    "    \n",
    "    # Loss & Scheduler\n",
    "    print(f\"      [4/5] Loss & Scheduler...\", end=\" \", flush=True)\n",
    "    criterion = SoftFocalLoss(alpha=class_weights.to(device), gamma=3.0)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    print(f\"‚úì\", flush=True)\n",
    "    \n",
    "    # Training\n",
    "    print(f\"      [5/5] Training (patience={patience}, L1={l1_lambda:.0e})...\", flush=True)\n",
    "    best_f1, best_state, no_improve = 0.0, None, 0\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss, n = 0.0, 0\n",
    "        \n",
    "        for x, y, w in dl_tr:\n",
    "            x, y, w = x.to(device), y.to(device), w.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y, w)\n",
    "            \n",
    "            # L1 Regularization (SAME AS RESNET)\n",
    "            if l1_lambda > 0:\n",
    "                l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "                loss = loss + l1_lambda * l1_norm\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * x.size(0)\n",
    "            n += x.size(0)\n",
    "        \n",
    "        train_loss /= n\n",
    "        val_results = evaluate_full(model, dl_va)\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_results['f1'] > best_f1:\n",
    "            best_f1 = val_results['f1']\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"        Early stop at epoch {epoch}\", flush=True)\n",
    "                break\n",
    "        \n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            print(f\"        Epoch {epoch:2d}: F1={val_results['f1']:.4f}, Loss={train_loss:.4f}\", flush=True)\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    final_results = evaluate_full(model, dl_va)\n",
    "    \n",
    "    del model, optimizer, scheduler, dl_tr, dl_va\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "print(\"‚úÖ Training function ready\")\n",
    "print(\"   Optimizers: Adam, AdamW, Adagrad\")\n",
    "print(\"   Activations: ReLU, LeakyReLU\")\n",
    "print(\"   L1/L2 regularization supported\")\n",
    "print(\"   Early stopping: patience=10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç CELL 9: Grid Configuration (SAME AS RESNET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "==================== EEGNET GRIDSEARCH - SAME AS RESNET-101 ====================\n",
      "================================================================================\n",
      "\n",
      "üìã HYPERPARAMETER GRID:\n",
      "--------------------------------------------------------------------------------\n",
      "  Optimizer:   ['adam', 'adamw', 'adagrad']\n",
      "  Activation:  ['relu', 'leakyrelu']\n",
      "  L1 lambda:   [0]\n",
      "  L2 lambda:   [0, 0.0001, 0.001]\n",
      "\n",
      "üìä GRIDSEARCH STATISTICS:\n",
      "--------------------------------------------------------------------------------\n",
      "  Total combinations: 18\n",
      "  Folds per config:   3\n",
      "  Total trainings:    54\n",
      "  Est. time per run:  ~10 min (EEGNet is smaller)\n",
      "  Est. total time:    ~9.0 hours\n",
      "\n",
      "üìù ALL COMBINATIONS:\n",
      "--------------------------------------------------------------------------------\n",
      "   1. adam    + relu       + L1=0e+00 + L2=0e+00\n",
      "   2. adam    + relu       + L1=0e+00 + L2=1e-04\n",
      "   3. adam    + relu       + L1=0e+00 + L2=1e-03\n",
      "   4. adam    + leakyrelu  + L1=0e+00 + L2=0e+00\n",
      "   5. adam    + leakyrelu  + L1=0e+00 + L2=1e-04\n",
      "   6. adam    + leakyrelu  + L1=0e+00 + L2=1e-03\n",
      "   7. adamw   + relu       + L1=0e+00 + L2=0e+00\n",
      "   8. adamw   + relu       + L1=0e+00 + L2=1e-04\n",
      "   9. adamw   + relu       + L1=0e+00 + L2=1e-03\n",
      "  10. adamw   + leakyrelu  + L1=0e+00 + L2=0e+00\n",
      "  11. adamw   + leakyrelu  + L1=0e+00 + L2=1e-04\n",
      "  12. adamw   + leakyrelu  + L1=0e+00 + L2=1e-03\n",
      "  13. adagrad + relu       + L1=0e+00 + L2=0e+00\n",
      "  14. adagrad + relu       + L1=0e+00 + L2=1e-04\n",
      "  15. adagrad + relu       + L1=0e+00 + L2=1e-03\n",
      "  16. adagrad + leakyrelu  + L1=0e+00 + L2=0e+00\n",
      "  17. adagrad + leakyrelu  + L1=0e+00 + L2=1e-04\n",
      "  18. adagrad + leakyrelu  + L1=0e+00 + L2=1e-03\n",
      "\n",
      "üéØ TARGETS TO BEAT:\n",
      "--------------------------------------------------------------------------------\n",
      "  EEGNet (baseline, no tuning): F1 = 0.3281\n",
      "  ResNet-101 (tuned):           F1 = 0.5585\n",
      "  KAN (tuned):                  F1 = ??? (running)\n",
      "\n",
      "‚è±Ô∏è  TIMELINE:\n",
      "--------------------------------------------------------------------------------\n",
      "  Start:  2026-01-14 15:26\n",
      "  Finish: 2026-01-15 00:26 (approx)\n",
      "\n",
      "üíæ AUTO-SAVE:\n",
      "--------------------------------------------------------------------------------\n",
      "  eegnet_gridsearch_results/eegnet_gridsearch_progress.json\n",
      "  eegnet_gridsearch_results/eegnet_gridsearch_final.json\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" EEGNET GRIDSEARCH - SAME AS RESNET-101 \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# EXACT SAME PARAMS AS RESNET-101\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'adamw', 'adagrad'],  # 3 - SAME\n",
    "    'activation': ['relu', 'leakyrelu'],        # 2 - SAME\n",
    "    'l1_lambda': [0],                           # 1 - SAME (no L1)\n",
    "    'l2_lambda': [0, 1e-4, 1e-3],              # 3 - SAME\n",
    "}\n",
    "\n",
    "fixed_params = {\n",
    "    'lr': 3e-4,\n",
    "    'batch_size': 16,\n",
    "    'epochs': 30,\n",
    "    'patience': 10,\n",
    "}\n",
    "\n",
    "keys = list(param_grid.keys())\n",
    "values = list(param_grid.values())\n",
    "combinations = list(product(*values))\n",
    "\n",
    "print(\"\\nüìã HYPERPARAMETER GRID:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Optimizer:   {param_grid['optimizer']}\")\n",
    "print(f\"  Activation:  {param_grid['activation']}\")\n",
    "print(f\"  L1 lambda:   {param_grid['l1_lambda']}\")\n",
    "print(f\"  L2 lambda:   {param_grid['l2_lambda']}\")\n",
    "\n",
    "print(\"\\nüìä GRIDSEARCH STATISTICS:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Total combinations: {len(combinations)}\")\n",
    "print(f\"  Folds per config:   {N_FOLDS}\")\n",
    "print(f\"  Total trainings:    {len(combinations) * N_FOLDS}\")\n",
    "print(f\"  Est. time per run:  ~10 min (EEGNet is smaller)\")\n",
    "print(f\"  Est. total time:    ~{len(combinations) * N_FOLDS * 10 / 60:.1f} hours\")\n",
    "\n",
    "print(\"\\nüìù ALL COMBINATIONS:\")\n",
    "print(\"-\"*80)\n",
    "for i, combo in enumerate(combinations, 1):\n",
    "    params = dict(zip(keys, combo))\n",
    "    print(f\"  {i:2d}. {params['optimizer']:7s} + {params['activation']:10s} + \"\n",
    "          f\"L1={params['l1_lambda']:.0e} + L2={params['l2_lambda']:.0e}\")\n",
    "\n",
    "print(\"\\nüéØ TARGETS TO BEAT:\")\n",
    "print(\"-\"*80)\n",
    "print(\"  EEGNet (baseline, no tuning): F1 = 0.3281\")\n",
    "print(\"  ResNet-101 (tuned):           F1 = 0.5585\")\n",
    "print(\"  KAN (tuned):                  F1 = ??? (running)\")\n",
    "\n",
    "print(\"\\n‚è±Ô∏è  TIMELINE:\")\n",
    "print(\"-\"*80)\n",
    "current_time = datetime.now()\n",
    "finish_time = current_time + pd.Timedelta(hours=len(combinations) * N_FOLDS * 10 / 60)\n",
    "print(f\"  Start:  {current_time.strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(f\"  Finish: {finish_time.strftime('%Y-%m-%d %H:%M')} (approx)\")\n",
    "\n",
    "print(\"\\nüíæ AUTO-SAVE:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  {RESULTS_DIR}/eegnet_gridsearch_progress.json\")\n",
    "print(f\"  {RESULTS_DIR}/eegnet_gridsearch_final.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ CELL 10: Run GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "============================= STARTING GRIDSEARCH ==============================\n",
      "================================================================================\n",
      "Started: 2026-01-14 15:26:57\n",
      "\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 1/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.1s)\n",
      "      [3/5] Optimizer (adam, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2419, Loss=0.9869\n",
      "        Epoch  5: F1=0.3200, Loss=0.7310\n",
      "        Epoch 10: F1=0.3528, Loss=0.6470\n",
      "        Epoch 15: F1=0.3753, Loss=0.5995\n",
      "        Epoch 20: F1=0.3728, Loss=0.5817\n",
      "        Epoch 25: F1=0.3827, Loss=0.5663\n",
      "        Epoch 30: F1=0.3815, Loss=0.5555\n",
      "\n",
      "    ‚úì Fold 1: F1=0.3838 (37.8 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2551, Loss=0.9758\n",
      "        Epoch  5: F1=0.3529, Loss=0.7238\n",
      "        Epoch 10: F1=0.3517, Loss=0.6400\n",
      "        Epoch 15: F1=0.3684, Loss=0.6085\n",
      "        Epoch 20: F1=0.3701, Loss=0.5984\n",
      "        Epoch 25: F1=0.3771, Loss=0.5729\n",
      "        Epoch 30: F1=0.3723, Loss=0.5805\n",
      "\n",
      "    ‚úì Fold 2: F1=0.3797 (23.6 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2956, Loss=0.9822\n",
      "        Epoch  5: F1=0.3464, Loss=0.7620\n",
      "        Epoch 10: F1=0.3431, Loss=0.6935\n",
      "        Epoch 15: F1=0.3572, Loss=0.6588\n",
      "        Epoch 20: F1=0.3666, Loss=0.6460\n",
      "        Epoch 25: F1=0.3744, Loss=0.6211\n",
      "        Epoch 30: F1=0.3744, Loss=0.6353\n",
      "\n",
      "    ‚úì Fold 3: F1=0.3797 (23.4 min)\n",
      "\n",
      "  Mean F1: 0.3811 ¬± 0.0019\n",
      "  Mean Acc: 0.3644\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 2/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2914, Loss=0.9843\n",
      "        Epoch  5: F1=0.3310, Loss=0.7481\n",
      "        Epoch 10: F1=0.3506, Loss=0.6950\n",
      "        Epoch 15: F1=0.3542, Loss=0.6582\n",
      "        Epoch 20: F1=0.3537, Loss=0.6298\n",
      "        Epoch 25: F1=0.3567, Loss=0.6137\n",
      "        Epoch 30: F1=0.3580, Loss=0.6140\n",
      "\n",
      "    ‚úì Fold 1: F1=0.3595 (23.3 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2833, Loss=0.9777\n",
      "        Epoch  5: F1=0.3432, Loss=0.7255\n",
      "        Epoch 10: F1=0.3643, Loss=0.6548\n",
      "        Epoch 15: F1=0.3766, Loss=0.6253\n",
      "        Epoch 20: F1=0.3649, Loss=0.5885\n",
      "        Early stop at epoch 25\n",
      "\n",
      "    ‚úì Fold 2: F1=0.3766 (19.6 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2855, Loss=0.9832\n",
      "        Epoch  5: F1=0.3721, Loss=0.7277\n",
      "        Epoch 10: F1=0.3713, Loss=0.6457\n",
      "        Epoch 15: F1=0.3736, Loss=0.5908\n",
      "        Epoch 20: F1=0.3947, Loss=0.6018\n",
      "        Epoch 25: F1=0.3858, Loss=0.5849\n",
      "        Epoch 30: F1=0.3907, Loss=0.5787\n",
      "\n",
      "    ‚úì Fold 3: F1=0.3963 (23.4 min)\n",
      "\n",
      "  Mean F1: 0.3775 ¬± 0.0150\n",
      "  Mean Acc: 0.3582\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 3/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2840, Loss=0.9746\n",
      "        Epoch  5: F1=0.3587, Loss=0.7029\n",
      "        Epoch 10: F1=0.3645, Loss=0.6243\n",
      "        Epoch 15: F1=0.3859, Loss=0.6062\n",
      "        Epoch 20: F1=0.3818, Loss=0.5924\n",
      "        Early stop at epoch 25\n",
      "\n",
      "    ‚úì Fold 1: F1=0.3859 (19.5 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2684, Loss=0.9805\n",
      "        Epoch  5: F1=0.3393, Loss=0.7256\n",
      "        Epoch 10: F1=0.3806, Loss=0.6394\n",
      "        Epoch 15: F1=0.3759, Loss=0.6098\n",
      "        Epoch 20: F1=0.3803, Loss=0.6042\n",
      "        Epoch 25: F1=0.3767, Loss=0.5806\n",
      "        Epoch 30: F1=0.3820, Loss=0.5635\n",
      "\n",
      "    ‚úì Fold 2: F1=0.3841 (23.3 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3261, Loss=0.9438\n",
      "        Epoch  5: F1=0.3581, Loss=0.7108\n",
      "        Epoch 10: F1=0.3755, Loss=0.6539\n",
      "        Epoch 15: F1=0.3823, Loss=0.6310\n",
      "        Epoch 20: F1=0.3851, Loss=0.6132\n",
      "        Epoch 25: F1=0.3861, Loss=0.6049\n",
      "        Epoch 30: F1=0.3919, Loss=0.5824\n",
      "\n",
      "    ‚úì Fold 3: F1=0.3976 (23.1 min)\n",
      "\n",
      "  Mean F1: 0.3892 ¬± 0.0060\n",
      "  Mean Acc: 0.3731\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 4/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2968, Loss=0.9846\n",
      "        Epoch  5: F1=0.3224, Loss=0.7379\n",
      "        Epoch 10: F1=0.3469, Loss=0.6599\n",
      "        Epoch 15: F1=0.3538, Loss=0.6298\n",
      "        Epoch 20: F1=0.3737, Loss=0.6061\n",
      "        Epoch 25: F1=0.3720, Loss=0.5614\n",
      "        Epoch 30: F1=0.3735, Loss=0.5753\n",
      "\n",
      "    ‚úì Fold 1: F1=0.3768 (23.1 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2934, Loss=0.9588\n",
      "        Epoch  5: F1=0.3141, Loss=0.7057\n",
      "        Epoch 10: F1=0.3660, Loss=0.6240\n",
      "        Epoch 15: F1=0.3758, Loss=0.6031\n",
      "        Epoch 20: F1=0.3759, Loss=0.5850\n",
      "        Early stop at epoch 24\n",
      "\n",
      "    ‚úì Fold 2: F1=0.3802 (18.9 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3162, Loss=0.9427\n",
      "        Epoch  5: F1=0.3541, Loss=0.7192\n",
      "        Epoch 10: F1=0.3566, Loss=0.6437\n",
      "        Epoch 15: F1=0.3774, Loss=0.6139\n",
      "        Epoch 20: F1=0.3864, Loss=0.5947\n",
      "        Epoch 25: F1=0.3794, Loss=0.5857\n",
      "        Epoch 30: F1=0.3775, Loss=0.5626\n",
      "\n",
      "    ‚úì Fold 3: F1=0.3868 (24.0 min)\n",
      "\n",
      "  Mean F1: 0.3813 ¬± 0.0041\n",
      "  Mean Acc: 0.3632\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 5/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3006, Loss=0.9942\n",
      "        Epoch  5: F1=0.3617, Loss=0.7005\n",
      "        Epoch 10: F1=0.3648, Loss=0.6441\n",
      "        Epoch 15: F1=0.3795, Loss=0.6059\n",
      "        Early stop at epoch 18\n",
      "\n",
      "    ‚úì Fold 1: F1=0.3818 (14.1 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2975, Loss=0.9662\n",
      "        Epoch  5: F1=0.3600, Loss=0.7202\n",
      "        Epoch 10: F1=0.3616, Loss=0.6380\n",
      "        Epoch 15: F1=0.3736, Loss=0.6207\n",
      "        Epoch 20: F1=0.3760, Loss=0.5802\n",
      "        Epoch 25: F1=0.3757, Loss=0.5673\n",
      "        Early stop at epoch 26\n",
      "\n",
      "    ‚úì Fold 2: F1=0.3796 (21.6 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2720, Loss=0.9904\n",
      "        Epoch  5: F1=0.3563, Loss=0.7362\n",
      "        Epoch 10: F1=0.3852, Loss=0.6740\n",
      "        Epoch 15: F1=0.3739, Loss=0.6290\n",
      "        Epoch 20: F1=0.3874, Loss=0.5953\n",
      "        Epoch 25: F1=0.3936, Loss=0.5859\n",
      "        Epoch 30: F1=0.3954, Loss=0.5868\n",
      "\n",
      "    ‚úì Fold 3: F1=0.3979 (23.8 min)\n",
      "\n",
      "  Mean F1: 0.3864 ¬± 0.0081\n",
      "  Mean Acc: 0.3657\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 6/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3035, Loss=1.0025\n",
      "        Epoch  5: F1=0.3652, Loss=0.6900\n",
      "        Epoch 10: F1=0.3696, Loss=0.6377\n",
      "        Epoch 15: F1=0.3735, Loss=0.6372\n",
      "        Epoch 20: F1=0.3772, Loss=0.5840\n",
      "        Epoch 25: F1=0.3800, Loss=0.5604\n",
      "        Epoch 30: F1=0.3809, Loss=0.5723\n",
      "\n",
      "    ‚úì Fold 1: F1=0.3818 (24.6 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3053, Loss=0.9550\n",
      "        Epoch  5: F1=0.3513, Loss=0.7038\n",
      "        Epoch 10: F1=0.3666, Loss=0.6440\n",
      "        Epoch 15: F1=0.3758, Loss=0.6092\n",
      "        Epoch 20: F1=0.3750, Loss=0.5954\n",
      "        Epoch 25: F1=0.3756, Loss=0.5776\n",
      "        Epoch 30: F1=0.3814, Loss=0.5686\n",
      "\n",
      "    ‚úì Fold 2: F1=0.3846 (25.9 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adam, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3086, Loss=0.9449\n",
      "        Epoch  5: F1=0.3655, Loss=0.7207\n",
      "        Epoch 10: F1=0.3525, Loss=0.6627\n",
      "        Epoch 15: F1=0.3896, Loss=0.6446\n",
      "        Epoch 20: F1=0.3923, Loss=0.6211\n",
      "        Epoch 25: F1=0.3872, Loss=0.6003\n",
      "        Epoch 30: F1=0.3870, Loss=0.5931\n",
      "\n",
      "    ‚úì Fold 3: F1=0.3927 (26.4 min)\n",
      "\n",
      "  Mean F1: 0.3864 ¬± 0.0046\n",
      "  Mean Acc: 0.3692\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 7/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2900, Loss=0.9627\n",
      "        Epoch  5: F1=0.3516, Loss=0.7298\n",
      "        Epoch 10: F1=0.3424, Loss=0.6756\n",
      "        Epoch 15: F1=0.3566, Loss=0.6321\n",
      "        Epoch 20: F1=0.3603, Loss=0.6237\n",
      "        Epoch 25: F1=0.3574, Loss=0.5963\n",
      "        Epoch 30: F1=0.3674, Loss=0.6025\n",
      "\n",
      "    ‚úì Fold 1: F1=0.3719 (28.9 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2929, Loss=1.0014\n",
      "        Epoch  5: F1=0.3403, Loss=0.7463\n",
      "        Epoch 10: F1=0.3638, Loss=0.6827\n",
      "        Epoch 15: F1=0.3648, Loss=0.6279\n",
      "        Epoch 20: F1=0.3672, Loss=0.6120\n",
      "        Epoch 25: F1=0.3712, Loss=0.6081\n",
      "        Epoch 30: F1=0.3724, Loss=0.5963\n",
      "\n",
      "    ‚úì Fold 2: F1=0.3725 (26.3 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2837, Loss=0.9849\n",
      "        Epoch  5: F1=0.3248, Loss=0.7484\n",
      "        Epoch 10: F1=0.3629, Loss=0.6822\n",
      "        Epoch 15: F1=0.3594, Loss=0.6440\n",
      "        Epoch 20: F1=0.3883, Loss=0.6072\n",
      "        Epoch 25: F1=0.3934, Loss=0.5934\n",
      "        Epoch 30: F1=0.3934, Loss=0.5870\n",
      "\n",
      "    ‚úì Fold 3: F1=0.3962 (27.8 min)\n",
      "\n",
      "  Mean F1: 0.3802 ¬± 0.0113\n",
      "  Mean Acc: 0.3577\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 8/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3057, Loss=0.9716\n",
      "        Epoch  5: F1=0.3491, Loss=0.7392\n",
      "        Epoch 10: F1=0.3343, Loss=0.6891\n",
      "        Epoch 15: F1=0.3618, Loss=0.6487\n",
      "        Epoch 20: F1=0.3656, Loss=0.6151\n",
      "        Epoch 25: F1=0.3661, Loss=0.6024\n",
      "        Epoch 30: F1=0.3620, Loss=0.6009\n",
      "\n",
      "    ‚úì Fold 1: F1=0.3685 (26.9 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3007, Loss=1.0004\n",
      "        Epoch  5: F1=0.3554, Loss=0.7093\n",
      "        Epoch 10: F1=0.3681, Loss=0.6450\n",
      "        Epoch 15: F1=0.3704, Loss=0.6167\n",
      "        Epoch 20: F1=0.3771, Loss=0.5826\n",
      "        Epoch 25: F1=0.3803, Loss=0.5719\n",
      "        Epoch 30: F1=0.3824, Loss=0.5621\n",
      "\n",
      "    ‚úì Fold 2: F1=0.3865 (28.0 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2896, Loss=0.9593\n",
      "        Epoch  5: F1=0.3284, Loss=0.7567\n",
      "        Epoch 10: F1=0.3646, Loss=0.7059\n",
      "        Epoch 15: F1=0.3705, Loss=0.6591\n",
      "        Epoch 20: F1=0.3574, Loss=0.6495\n",
      "        Epoch 25: F1=0.3727, Loss=0.6384\n",
      "        Epoch 30: F1=0.3745, Loss=0.6246\n",
      "\n",
      "    ‚úì Fold 3: F1=0.3761 (27.7 min)\n",
      "\n",
      "  Mean F1: 0.3770 ¬± 0.0074\n",
      "  Mean Acc: 0.3534\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 9/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3175, Loss=0.9603\n",
      "        Epoch  5: F1=0.3602, Loss=0.7198\n",
      "        Epoch 10: F1=0.3788, Loss=0.6509\n",
      "        Epoch 15: F1=0.3679, Loss=0.6125\n",
      "        Epoch 20: F1=0.3746, Loss=0.5810\n",
      "        Early stop at epoch 21\n",
      "\n",
      "    ‚úì Fold 1: F1=0.3806 (20.3 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3055, Loss=0.9621\n",
      "        Epoch  5: F1=0.3524, Loss=0.7362\n",
      "        Epoch 10: F1=0.3509, Loss=0.6892\n",
      "        Epoch 15: F1=0.3688, Loss=0.6363\n",
      "        Epoch 20: F1=0.3682, Loss=0.6168\n",
      "        Epoch 25: F1=0.3700, Loss=0.5984\n",
      "        Epoch 30: F1=0.3721, Loss=0.6135\n",
      "\n",
      "    ‚úì Fold 2: F1=0.3735 (28.4 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2849, Loss=0.9808\n",
      "        Epoch  5: F1=0.3646, Loss=0.7145\n",
      "        Epoch 10: F1=0.3867, Loss=0.6591\n",
      "        Epoch 15: F1=0.3803, Loss=0.6169\n",
      "        Epoch 20: F1=0.3833, Loss=0.5912\n",
      "        Epoch 25: F1=0.3928, Loss=0.5827\n",
      "        Epoch 30: F1=0.3970, Loss=0.5725\n",
      "\n",
      "    ‚úì Fold 3: F1=0.3970 (27.7 min)\n",
      "\n",
      "  Mean F1: 0.3837 ¬± 0.0099\n",
      "  Mean Acc: 0.3613\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 10/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2974, Loss=0.9528\n",
      "        Epoch  5: F1=0.3486, Loss=0.6945\n",
      "        Epoch 10: F1=0.3549, Loss=0.6229\n",
      "        Epoch 15: F1=0.3751, Loss=0.5916\n",
      "        Epoch 20: F1=0.3874, Loss=0.5802\n",
      "        Epoch 25: F1=0.3813, Loss=0.5568\n",
      "        Epoch 30: F1=0.3850, Loss=0.5567\n",
      "\n",
      "    ‚úì Fold 1: F1=0.3889 (30.3 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3019, Loss=0.9594\n",
      "        Epoch  5: F1=0.3381, Loss=0.7154\n",
      "        Epoch 10: F1=0.3557, Loss=0.6597\n",
      "        Epoch 15: F1=0.3749, Loss=0.6201\n",
      "        Epoch 20: F1=0.3758, Loss=0.5927\n",
      "        Epoch 25: F1=0.3823, Loss=0.5820\n",
      "        Epoch 30: F1=0.3789, Loss=0.5725\n",
      "\n",
      "    ‚úì Fold 2: F1=0.3823 (28.7 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3211, Loss=0.9742\n",
      "        Epoch  5: F1=0.3446, Loss=0.7158\n",
      "        Epoch 10: F1=0.3864, Loss=0.6413\n",
      "        Epoch 15: F1=0.3850, Loss=0.6228\n",
      "        Epoch 20: F1=0.3906, Loss=0.6021\n",
      "        Epoch 25: F1=0.3938, Loss=0.5751\n",
      "        Epoch 30: F1=0.3927, Loss=0.5839\n",
      "\n",
      "    ‚úì Fold 3: F1=0.3947 (32.0 min)\n",
      "\n",
      "  Mean F1: 0.3887 ¬± 0.0051\n",
      "  Mean Acc: 0.3684\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 11/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2963, Loss=0.9722\n",
      "        Epoch  5: F1=0.3518, Loss=0.7490\n",
      "        Epoch 10: F1=0.3440, Loss=0.6581\n",
      "        Epoch 15: F1=0.3604, Loss=0.6419\n",
      "        Epoch 20: F1=0.3698, Loss=0.6140\n",
      "        Epoch 25: F1=0.3741, Loss=0.5826\n",
      "        Early stop at epoch 29\n",
      "\n",
      "    ‚úì Fold 1: F1=0.3750 (35.9 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3205, Loss=0.9634\n",
      "        Epoch  5: F1=0.3487, Loss=0.7190\n",
      "        Epoch 10: F1=0.3463, Loss=0.6821\n",
      "        Epoch 15: F1=0.3582, Loss=0.6379\n",
      "        Epoch 20: F1=0.3566, Loss=0.6291\n",
      "        Epoch 25: F1=0.3596, Loss=0.6072\n",
      "        Epoch 30: F1=0.3592, Loss=0.6035\n",
      "\n",
      "    ‚úì Fold 2: F1=0.3636 (33.4 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3211, Loss=0.9707\n",
      "        Epoch  5: F1=0.3556, Loss=0.7371\n",
      "        Epoch 10: F1=0.3664, Loss=0.6915\n",
      "        Epoch 15: F1=0.3731, Loss=0.6529\n",
      "        Epoch 20: F1=0.3723, Loss=0.6206\n",
      "        Epoch 25: F1=0.3773, Loss=0.5986\n",
      "        Epoch 30: F1=0.3807, Loss=0.6112\n",
      "\n",
      "    ‚úì Fold 3: F1=0.3815 (31.7 min)\n",
      "\n",
      "  Mean F1: 0.3734 ¬± 0.0074\n",
      "  Mean Acc: 0.3484\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 12/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2732, Loss=0.9755\n",
      "        Epoch  5: F1=0.3523, Loss=0.7099\n",
      "        Epoch 10: F1=0.3779, Loss=0.6435\n",
      "        Epoch 15: F1=0.3713, Loss=0.5953\n",
      "        Epoch 20: F1=0.3755, Loss=0.5780\n",
      "        Epoch 25: F1=0.3800, Loss=0.5669\n",
      "        Epoch 30: F1=0.3812, Loss=0.5619\n",
      "\n",
      "    ‚úì Fold 1: F1=0.3839 (32.1 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3166, Loss=0.9734\n",
      "        Epoch  5: F1=0.3357, Loss=0.7201\n",
      "        Epoch 10: F1=0.3730, Loss=0.6598\n",
      "        Epoch 15: F1=0.3647, Loss=0.6249\n",
      "        Epoch 20: F1=0.3738, Loss=0.6037\n",
      "        Epoch 25: F1=0.3770, Loss=0.5858\n",
      "        Epoch 30: F1=0.3767, Loss=0.5753\n",
      "\n",
      "    ‚úì Fold 2: F1=0.3770 (38.9 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adamw, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2888, Loss=0.9808\n",
      "        Epoch  5: F1=0.3641, Loss=0.7181\n",
      "        Epoch 10: F1=0.3779, Loss=0.6244\n",
      "        Epoch 15: F1=0.3863, Loss=0.5959\n",
      "        Epoch 20: F1=0.3834, Loss=0.5851\n",
      "        Early stop at epoch 23\n",
      "\n",
      "    ‚úì Fold 3: F1=0.3894 (29.8 min)\n",
      "\n",
      "  Mean F1: 0.3834 ¬± 0.0051\n",
      "  Mean Acc: 0.3631\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 13/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2100, Loss=1.1888\n",
      "        Epoch  5: F1=0.2509, Loss=1.0315\n",
      "        Epoch 10: F1=0.2617, Loss=0.9917\n",
      "        Epoch 15: F1=0.2582, Loss=0.9680\n",
      "        Early stop at epoch 17\n",
      "\n",
      "    ‚úì Fold 1: F1=0.2641 (56.5 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2476, Loss=1.1840\n",
      "        Epoch  5: F1=0.2416, Loss=1.0197\n",
      "        Epoch 10: F1=0.2522, Loss=0.9895\n",
      "        Epoch 15: F1=0.2552, Loss=0.9658\n",
      "        Epoch 20: F1=0.2541, Loss=0.9601\n",
      "        Early stop at epoch 24\n",
      "\n",
      "    ‚úì Fold 2: F1=0.2576 (44.9 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.1168, Loss=1.2311\n",
      "        Epoch  5: F1=0.1418, Loss=1.0795\n",
      "        Epoch 10: F1=0.2111, Loss=1.0238\n",
      "        Epoch 15: F1=0.2339, Loss=0.9925\n",
      "        Epoch 20: F1=0.2419, Loss=0.9849\n",
      "        Epoch 25: F1=0.2445, Loss=0.9764\n",
      "        Epoch 30: F1=0.2429, Loss=0.9897\n",
      "\n",
      "    ‚úì Fold 3: F1=0.2461 (52.2 min)\n",
      "\n",
      "  Mean F1: 0.2560 ¬± 0.0074\n",
      "  Mean Acc: 0.2524\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 14/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2129, Loss=1.2162\n",
      "        Epoch  5: F1=0.2698, Loss=1.0820\n",
      "        Epoch 10: F1=0.2831, Loss=1.0108\n",
      "        Epoch 15: F1=0.2876, Loss=0.9873\n",
      "        Epoch 20: F1=0.2837, Loss=0.9862\n",
      "        Epoch 25: F1=0.2910, Loss=0.9872\n",
      "        Epoch 30: F1=0.2828, Loss=0.9724\n",
      "\n",
      "    ‚úì Fold 1: F1=0.2910 (56.7 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2245, Loss=1.1989\n",
      "        Epoch  5: F1=0.2506, Loss=1.0368\n",
      "        Epoch 10: F1=0.2628, Loss=0.9952\n",
      "        Epoch 15: F1=0.2533, Loss=0.9834\n",
      "        Epoch 20: F1=0.2738, Loss=0.9919\n",
      "        Epoch 25: F1=0.2705, Loss=0.9684\n",
      "        Early stop at epoch 30\n",
      "\n",
      "    ‚úì Fold 2: F1=0.2738 (80.4 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.1750, Loss=1.2013\n",
      "        Epoch  5: F1=0.2069, Loss=1.0510\n",
      "        Epoch 10: F1=0.2246, Loss=1.0076\n",
      "        Epoch 15: F1=0.2269, Loss=0.9804\n",
      "        Epoch 20: F1=0.2334, Loss=0.9884\n",
      "        Epoch 25: F1=0.2369, Loss=0.9772\n",
      "        Epoch 30: F1=0.2343, Loss=0.9704\n",
      "\n",
      "    ‚úì Fold 3: F1=0.2369 (95.4 min)\n",
      "\n",
      "  Mean F1: 0.2672 ¬± 0.0226\n",
      "  Mean Acc: 0.2545\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 15/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: relu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.1776, Loss=1.1905\n",
      "        Epoch  5: F1=0.1984, Loss=1.0302\n",
      "        Epoch 10: F1=0.2084, Loss=0.9824\n",
      "        Epoch 15: F1=0.2189, Loss=0.9664\n",
      "        Epoch 20: F1=0.2276, Loss=0.9475\n",
      "        Epoch 25: F1=0.2202, Loss=0.9569\n",
      "        Epoch 30: F1=0.2245, Loss=0.9512\n",
      "\n",
      "    ‚úì Fold 1: F1=0.2290 (152.8 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.1942, Loss=1.2217\n",
      "        Epoch  5: F1=0.2538, Loss=1.0303\n",
      "        Epoch 10: F1=0.2612, Loss=1.0008\n",
      "        Epoch 15: F1=0.2674, Loss=0.9732\n",
      "        Epoch 20: F1=0.2701, Loss=0.9677\n",
      "        Epoch 25: F1=0.2703, Loss=0.9762\n",
      "        Early stop at epoch 29\n",
      "\n",
      "    ‚úì Fold 2: F1=0.2756 (155.4 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (relu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.1915, Loss=1.2241\n",
      "        Epoch  5: F1=0.2672, Loss=1.0356\n",
      "        Epoch 10: F1=0.2807, Loss=1.0042\n",
      "        Epoch 15: F1=0.2769, Loss=0.9766\n",
      "        Epoch 20: F1=0.2786, Loss=0.9706\n",
      "        Epoch 25: F1=0.2825, Loss=0.9750\n",
      "        Epoch 30: F1=0.2798, Loss=0.9629\n",
      "\n",
      "    ‚úì Fold 3: F1=0.2876 (174.0 min)\n",
      "\n",
      "  Mean F1: 0.2641 ¬± 0.0253\n",
      "  Mean Acc: 0.2560\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 16/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.1511, Loss=1.2177\n",
      "        Epoch  5: F1=0.1779, Loss=1.0520\n",
      "        Epoch 10: F1=0.2349, Loss=0.9997\n",
      "        Epoch 15: F1=0.2481, Loss=0.9846\n",
      "        Epoch 20: F1=0.2536, Loss=0.9820\n",
      "        Epoch 25: F1=0.2524, Loss=0.9723\n",
      "        Epoch 30: F1=0.2552, Loss=0.9693\n",
      "\n",
      "    ‚úì Fold 1: F1=0.2575 (165.3 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.1542, Loss=1.1795\n",
      "        Epoch  5: F1=0.2177, Loss=1.0491\n",
      "        Epoch 10: F1=0.2182, Loss=0.9993\n",
      "        Epoch 15: F1=0.2187, Loss=0.9836\n",
      "        Early stop at epoch 16\n",
      "\n",
      "    ‚úì Fold 2: F1=0.2227 (90.6 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=0e+00)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.1751, Loss=1.2560\n",
      "        Epoch  5: F1=0.2344, Loss=1.1377\n",
      "        Epoch 10: F1=0.2464, Loss=1.0525\n",
      "        Epoch 15: F1=0.2528, Loss=1.0208\n",
      "        Epoch 20: F1=0.2539, Loss=1.0051\n",
      "        Epoch 25: F1=0.2549, Loss=0.9991\n",
      "        Early stop at epoch 27\n",
      "\n",
      "    ‚úì Fold 3: F1=0.2569 (168.6 min)\n",
      "\n",
      "  Mean F1: 0.2457 ¬± 0.0163\n",
      "  Mean Acc: 0.2427\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 17/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2256, Loss=1.2114\n",
      "        Epoch  5: F1=0.2365, Loss=1.0524\n",
      "        Epoch 10: F1=0.2463, Loss=0.9973\n",
      "        Epoch 15: F1=0.2492, Loss=0.9644\n",
      "        Epoch 20: F1=0.2566, Loss=0.9617\n",
      "        Epoch 25: F1=0.2609, Loss=0.9482\n",
      "        Epoch 30: F1=0.2582, Loss=0.9634\n",
      "\n",
      "    ‚úì Fold 1: F1=0.2609 (208.6 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2118, Loss=1.2090\n",
      "        Epoch  5: F1=0.2372, Loss=1.0302\n",
      "        Epoch 10: F1=0.2576, Loss=0.9783\n",
      "        Epoch 15: F1=0.2601, Loss=0.9712\n",
      "        Epoch 20: F1=0.2591, Loss=0.9568\n",
      "        Epoch 25: F1=0.2663, Loss=0.9572\n",
      "        Epoch 30: F1=0.2650, Loss=0.9536\n",
      "\n",
      "    ‚úì Fold 2: F1=0.2667 (180.4 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-04)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2352, Loss=1.1739\n",
      "        Epoch  5: F1=0.2523, Loss=1.0215\n",
      "        Epoch 10: F1=0.2681, Loss=0.9737\n",
      "        Epoch 15: F1=0.2739, Loss=0.9781\n",
      "        Epoch 20: F1=0.2739, Loss=0.9578\n",
      "        Epoch 25: F1=0.2791, Loss=0.9703\n",
      "        Early stop at epoch 29\n",
      "\n",
      "    ‚úì Fold 3: F1=0.2814 (164.0 min)\n",
      "\n",
      "  Mean F1: 0.2697 ¬± 0.0087\n",
      "  Mean Acc: 0.2703\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 18/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: leakyrelu\n",
      "  L1: 0e+00\n",
      "  L2: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.1933, Loss=1.1990\n",
      "        Epoch  5: F1=0.2157, Loss=1.0535\n",
      "        Epoch 10: F1=0.2483, Loss=1.0027\n",
      "        Epoch 15: F1=0.2510, Loss=0.9767\n",
      "        Epoch 20: F1=0.2563, Loss=0.9659\n",
      "        Epoch 25: F1=0.2569, Loss=0.9729\n",
      "        Early stop at epoch 29\n",
      "\n",
      "    ‚úì Fold 1: F1=0.2626 (171.6 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.0697, Loss=1.2211\n",
      "        Epoch  5: F1=0.2353, Loss=1.0905\n",
      "        Epoch 10: F1=0.2553, Loss=1.0349\n",
      "        Epoch 15: F1=0.2634, Loss=1.0113\n",
      "        Epoch 20: F1=0.2617, Loss=0.9890\n",
      "        Epoch 25: F1=0.2698, Loss=0.9949\n",
      "        Epoch 30: F1=0.2602, Loss=0.9962\n",
      "\n",
      "    ‚úì Fold 2: F1=0.2698 (177.5 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/5] Data... ‚úì (0.0s)\n",
      "      [2/5] Model (leakyrelu)... ‚úì (0.0s)\n",
      "      [3/5] Optimizer (adagrad, L2=1e-03)... ‚úì\n",
      "      [4/5] Loss & Scheduler... ‚úì\n",
      "      [5/5] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2572, Loss=1.2118\n",
      "        Epoch  5: F1=0.2524, Loss=1.0392\n",
      "        Epoch 10: F1=0.2636, Loss=0.9914\n",
      "        Epoch 15: F1=0.2715, Loss=0.9747\n",
      "        Epoch 20: F1=0.2737, Loss=0.9671\n",
      "        Epoch 25: F1=0.2706, Loss=0.9658\n",
      "        Epoch 30: F1=0.2676, Loss=0.9637\n",
      "\n",
      "    ‚úì Fold 3: F1=0.2775 (182.0 min)\n",
      "\n",
      "  Mean F1: 0.2700 ¬± 0.0061\n",
      "  Mean Acc: 0.2626\n",
      "  üíæ Saved\n",
      "\n",
      "================================================================================\n",
      "============================= GRIDSEARCH COMPLETE ==============================\n",
      "================================================================================\n",
      "Total time: 55.52 hours\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" STARTING GRIDSEARCH \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "for combo_idx, combo in enumerate(combinations, 1):\n",
    "    params = dict(zip(keys, combo))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\" CONFIG {combo_idx}/{len(combinations)} \".center(80, \"=\"))\n",
    "    print(\"=\"*80)\n",
    "    print(f\"  Optimizer: {params['optimizer']}\")\n",
    "    print(f\"  Activation: {params['activation']}\")\n",
    "    print(f\"  L1: {params['l1_lambda']:.0e}\")\n",
    "    print(f\"  L2: {params['l2_lambda']:.0e}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    fold_results = []\n",
    "    \n",
    "    for fold in range(N_FOLDS):\n",
    "        print(f\"\\n    Fold {fold+1}/{N_FOLDS}...\", flush=True)\n",
    "        fold_start = time.time()\n",
    "        \n",
    "        try:\n",
    "            result = train_one_config(\n",
    "                fold=fold,\n",
    "                optimizer_name=params['optimizer'],\n",
    "                activation=params['activation'],\n",
    "                l1_lambda=params['l1_lambda'],\n",
    "                l2_lambda=params['l2_lambda'],\n",
    "                **fixed_params\n",
    "            )\n",
    "            fold_results.append(result)\n",
    "            print(f\"\\n    ‚úì Fold {fold+1}: F1={result['f1']:.4f} ({(time.time()-fold_start)/60:.1f} min)\", flush=True)\n",
    "        except Exception as e:\n",
    "            print(f\"\\n    ‚ùå Error: {e}\", flush=True)\n",
    "            fold_results.append({'f1': 0.0, 'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0})\n",
    "    \n",
    "    mean_metrics = {\n",
    "        'f1': np.mean([r['f1'] for r in fold_results]),\n",
    "        'accuracy': np.mean([r['accuracy'] for r in fold_results]),\n",
    "        'precision': np.mean([r['precision'] for r in fold_results]),\n",
    "        'recall': np.mean([r['recall'] for r in fold_results]),\n",
    "        'f1_std': np.std([r['f1'] for r in fold_results]),\n",
    "    }\n",
    "    \n",
    "    result_entry = {\n",
    "        'config_id': combo_idx,\n",
    "        'params': params,\n",
    "        'mean_metrics': mean_metrics,\n",
    "        'fold_results': fold_results,\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    }\n",
    "    all_results.append(result_entry)\n",
    "    \n",
    "    print(f\"\\n  Mean F1: {mean_metrics['f1']:.4f} ¬± {mean_metrics['f1_std']:.4f}\")\n",
    "    print(f\"  Mean Acc: {mean_metrics['accuracy']:.4f}\")\n",
    "    \n",
    "    # Auto-save\n",
    "    with open(RESULTS_DIR / 'eegnet_gridsearch_progress.json', 'w') as f:\n",
    "        json.dump(all_results, f, indent=2, default=str)\n",
    "    print(f\"  üíæ Saved\", flush=True)\n",
    "\n",
    "# Final save\n",
    "with open(RESULTS_DIR / 'eegnet_gridsearch_final.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'all_results': all_results,\n",
    "        'param_grid': param_grid,\n",
    "        'fixed_params': fixed_params,\n",
    "        'total_time_hours': (time.time() - start_time) / 3600,\n",
    "    }, f, indent=2, default=str)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" GRIDSEARCH COMPLETE \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"Total time: {(time.time()-start_time)/3600:.2f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä CELL 11: Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sorted_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mall_results\u001b[49m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m EEGNET GRIDSEARCH RESULTS \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mcenter(\u001b[38;5;241m80\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_results' is not defined"
     ]
    }
   ],
   "source": [
    "sorted_results = sorted(all_results, key=lambda x: x['mean_metrics']['f1'], reverse=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" EEGNET GRIDSEARCH RESULTS \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüèÜ TOP 10 CONFIGURATIONS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Rank':<6} {'Optimizer':>10} {'Activation':>12} {'L1':>8} {'L2':>8} {'F1':>10} {'Acc':>8}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for i, result in enumerate(sorted_results[:10], 1):\n",
    "    p = result['params']\n",
    "    m = result['mean_metrics']\n",
    "    print(f\"{i:<6} {p['optimizer']:>10} {p['activation']:>12} {p['l1_lambda']:>8.0e} \"\n",
    "          f\"{p['l2_lambda']:>8.0e} {m['f1']:>10.4f} {m['accuracy']:>8.4f}\")\n",
    "\n",
    "best = sorted_results[0]\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" BEST EEGNET CONFIGURATION \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"  Optimizer:  {best['params']['optimizer']}\")\n",
    "print(f\"  Activation: {best['params']['activation']}\")\n",
    "print(f\"  L1:         {best['params']['l1_lambda']:.0e}\")\n",
    "print(f\"  L2:         {best['params']['l2_lambda']:.0e}\")\n",
    "print(f\"\\n  F1:       {best['mean_metrics']['f1']:.4f} ¬± {best['mean_metrics']['f1_std']:.4f}\")\n",
    "print(f\"  Accuracy: {best['mean_metrics']['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" FINAL COMPARISON \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"  EEGNet (baseline):     F1 = 0.3281,  Acc = 0.3154\")\n",
    "print(f\"  EEGNet (tuned):        F1 = {best['mean_metrics']['f1']:.4f}, Acc = {best['mean_metrics']['accuracy']:.4f}\")\n",
    "print(f\"  KAN (tuned):           F1 = ???,     Acc = ???\")\n",
    "print(f\"  ResNet-101 (tuned):    F1 = 0.5585,  Acc = 0.5921\")\n",
    "\n",
    "if best['mean_metrics']['f1'] > 0.3281:\n",
    "    improvement = ((best['mean_metrics']['f1'] - 0.3281) / 0.3281) * 100\n",
    "    print(f\"\\n  ‚úÖ EEGNet improved by {improvement:.1f}% with GridSearch!\")\n",
    "else:\n",
    "    print(\"\\n  ‚ö†Ô∏è  EEGNet did not improve\")\n",
    "\n",
    "print(\"\\nüíæ Results saved to:\")\n",
    "print(f\"   {RESULTS_DIR}/eegnet_gridsearch_final.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loading file...\n",
      "üìÅ C:\\Users\\numpppy\\Downloads\\hms-harmful-brain-activity-classification\\eegnet_gridsearch_results\\eegnet_gridsearch_final.json\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Successfully loaded 0 configurations!\n",
      "================================================================================\n",
      "\n",
      "üèÜ TOP 5 CONFIGURATIONS:\n",
      "================================================================================\n",
      "Rank    Optimizer   Activation       L1       L2         F1      Acc\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 45\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<6\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>12\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1_lambda\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>8.0e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     40\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2_lambda\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>8.0e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>10.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     42\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>8.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Best configuration details\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43msorted_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m üéØ BEST CONFIGURATION \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mcenter(\u001b[38;5;241m80\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Path spesifik ke file\n",
    "file_path = r\"C:\\Users\\numpppy\\Downloads\\hms-harmful-brain-activity-classification\\eegnet_gridsearch_results\\eegnet_gridsearch_final.json\"\n",
    "\n",
    "print(\"üîç Loading file...\")\n",
    "print(f\"üìÅ {file_path}\\n\")\n",
    "\n",
    "# Load data\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract results\n",
    "all_results = data.get('sorted_results', data.get('results', []))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"‚úÖ Successfully loaded {len(all_results)} configurations!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Quick preview - Top 5\n",
    "print(\"\\nüèÜ TOP 5 CONFIGURATIONS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Rank':<6} {'Optimizer':>10} {'Activation':>12} {'L1':>8} {'L2':>8} {'F1':>10} {'Acc':>8}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "sorted_results = sorted(\n",
    "    all_results, \n",
    "    key=lambda x: x.get('mean_metrics', {}).get('f1', 0), \n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "for i, result in enumerate(sorted_results[:5], 1):\n",
    "    p = result.get('params', {})\n",
    "    m = result.get('mean_metrics', {})\n",
    "    print(f\"{i:<6} {p.get('optimizer', 'N/A'):>10} \"\n",
    "          f\"{p.get('activation', 'N/A'):>12} \"\n",
    "          f\"{p.get('l1_lambda', 0):>8.0e} \"\n",
    "          f\"{p.get('l2_lambda', 0):>8.0e} \"\n",
    "          f\"{m.get('f1', 0):>10.4f} \"\n",
    "          f\"{m.get('accuracy', 0):>8.4f}\")\n",
    "\n",
    "# Best configuration details\n",
    "best = sorted_results[0]\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" üéØ BEST CONFIGURATION \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"  Optimizer:  {best['params'].get('optimizer', 'N/A')}\")\n",
    "print(f\"  Activation: {best['params'].get('activation', 'N/A')}\")\n",
    "print(f\"  L1 Lambda:  {best['params'].get('l1_lambda', 0):.0e}\")\n",
    "print(f\"  L2 Lambda:  {best['params'].get('l2_lambda', 0):.0e}\")\n",
    "\n",
    "m = best.get('mean_metrics', {})\n",
    "print(f\"\\n  üìä Performance:\")\n",
    "print(f\"     F1:        {m.get('f1', 0):.4f} ¬± {m.get('f1_std', 0):.4f}\")\n",
    "print(f\"     Accuracy:  {m.get('accuracy', 0):.4f} ¬± {m.get('accuracy_std', 0):.4f}\")\n",
    "print(f\"     Precision: {m.get('precision', 0):.4f} ¬± {m.get('precision_std', 0):.4f}\")\n",
    "print(f\"     Recall:    {m.get('recall', 0):.4f} ¬± {m.get('recall_std', 0):.4f}\")\n",
    "\n",
    "# Comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" üìà MODEL COMPARISON \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Model':<25} {'F1':>10} {'Accuracy':>10}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'EEGNet (baseline)':<25} {0.3281:>10.4f} {0.3154:>10.4f}\")\n",
    "print(f\"{'EEGNet (tuned)':<25} {m.get('f1', 0):>10.4f} {m.get('accuracy', 0):>10.4f}\")\n",
    "print(f\"{'ResNet-101 (tuned)':<25} {0.5585:>10.4f} {0.5921:>10.4f}\")\n",
    "\n",
    "# Improvement analysis\n",
    "baseline_f1 = 0.3281\n",
    "tuned_f1 = m.get('f1', 0)\n",
    "\n",
    "if tuned_f1 > baseline_f1:\n",
    "    improvement = ((tuned_f1 - baseline_f1) / baseline_f1) * 100\n",
    "    print(f\"\\n  ‚úÖ EEGNet improved by {improvement:.2f}% with GridSearch!\")\n",
    "else:\n",
    "    decline = ((baseline_f1 - tuned_f1) / baseline_f1) * 100\n",
    "    print(f\"\\n  ‚ùå EEGNet declined by {decline:.2f}%\")\n",
    "\n",
    "# Gap to best model\n",
    "resnet_f1 = 0.5585\n",
    "gap = resnet_f1 - tuned_f1\n",
    "gap_pct = (gap / resnet_f1) * 100\n",
    "print(f\"  üìâ Gap to ResNet-101: {gap:.4f} ({gap_pct:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Convert to DataFrame for deeper analysis\n",
    "print(\"\\nüìä Creating detailed analysis...\")\n",
    "\n",
    "records = []\n",
    "for r in all_results:\n",
    "    record = {**r.get('params', {}), **r.get('mean_metrics', {})}\n",
    "    records.append(record)\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "print(\"\\nüìà HYPERPARAMETER IMPACT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Optimizer impact\n",
    "if 'optimizer' in df.columns:\n",
    "    print(\"\\nüîß OPTIMIZER:\")\n",
    "    print(\"-\"*80)\n",
    "    opt_stats = df.groupby('optimizer')['f1'].agg(['mean', 'std', 'max', 'count'])\n",
    "    opt_stats = opt_stats.sort_values('mean', ascending=False)\n",
    "    print(opt_stats)\n",
    "\n",
    "# Activation impact\n",
    "if 'activation' in df.columns:\n",
    "    print(\"\\n‚ö° ACTIVATION FUNCTION:\")\n",
    "    print(\"-\"*80)\n",
    "    act_stats = df.groupby('activation')['f1'].agg(['mean', 'std', 'max', 'count'])\n",
    "    act_stats = act_stats.sort_values('mean', ascending=False)\n",
    "    print(act_stats)\n",
    "\n",
    "# L1/L2 impact\n",
    "if 'l1_lambda' in df.columns and 'l2_lambda' in df.columns:\n",
    "    print(\"\\nüéõÔ∏è REGULARIZATION:\")\n",
    "    print(\"-\"*80)\n",
    "    print(\"L1 Lambda:\")\n",
    "    l1_stats = df.groupby('l1_lambda')['f1'].agg(['mean', 'std', 'max'])\n",
    "    print(l1_stats.sort_values('mean', ascending=False))\n",
    "    print(\"\\nL2 Lambda:\")\n",
    "    l2_stats = df.groupby('l2_lambda')['f1'].agg(['mean', 'std', 'max'])\n",
    "    print(l2_stats.sort_values('mean', ascending=False))\n",
    "\n",
    "# Statistics\n",
    "print(\"\\nüìä OVERALL STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total configurations tested: {len(df)}\")\n",
    "print(f\"\\nF1 Score Distribution:\")\n",
    "print(f\"  Best:   {df['f1'].max():.4f}\")\n",
    "print(f\"  Worst:  {df['f1'].min():.4f}\")\n",
    "print(f\"  Mean:   {df['f1'].mean():.4f}\")\n",
    "print(f\"  Median: {df['f1'].median():.4f}\")\n",
    "print(f\"  Std:    {df['f1'].std():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Analysis complete!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loading file...\n",
      "üìÅ C:\\Users\\numpppy\\Downloads\\hms-harmful-brain-activity-classification\\eegnet_gridsearch_results\\eegnet_gridsearch_final.json\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Successfully loaded 18 configurations!\n",
      "================================================================================\n",
      "\n",
      "üèÜ TOP 10 CONFIGURATIONS:\n",
      "================================================================================\n",
      "Rank   ID     Optimizer   Activation       L1       L2         F1      Acc\n",
      "--------------------------------------------------------------------------------\n",
      "1      3           adam         relu    0e+00    1e-03     0.3892   0.3731\n",
      "2      10         adamw    leakyrelu    0e+00    0e+00     0.3887   0.3684\n",
      "3      5           adam    leakyrelu    0e+00    1e-04     0.3864   0.3657\n",
      "4      6           adam    leakyrelu    0e+00    1e-03     0.3864   0.3692\n",
      "5      9          adamw         relu    0e+00    1e-03     0.3837   0.3613\n",
      "6      12         adamw    leakyrelu    0e+00    1e-03     0.3834   0.3631\n",
      "7      4           adam    leakyrelu    0e+00    0e+00     0.3813   0.3632\n",
      "8      1           adam         relu    0e+00    0e+00     0.3811   0.3644\n",
      "9      7          adamw         relu    0e+00    0e+00     0.3802   0.3577\n",
      "10     2           adam         relu    0e+00    1e-04     0.3775   0.3582\n",
      "\n",
      "================================================================================\n",
      "============================= üéØ BEST CONFIGURATION =============================\n",
      "================================================================================\n",
      "  Config ID:  3\n",
      "  Optimizer:  adam\n",
      "  Activation: relu\n",
      "  L1 Lambda:  0e+00\n",
      "  L2 Lambda:  1e-03\n",
      "\n",
      "  üìä Performance:\n",
      "     F1:        0.3892 ¬± 0.0060\n",
      "     Accuracy:  0.3731 ¬± 0.0000\n",
      "     Precision: 0.3186 ¬± 0.0000\n",
      "     Recall:    0.5343 ¬± 0.0000\n",
      "\n",
      "================================================================================\n",
      "========================= üîß GRID SEARCH CONFIGURATION ==========================\n",
      "================================================================================\n",
      "  Total configs tested: 18\n",
      "  Total time: 55.52 hours\n",
      "\n",
      "  Parameter Grid:\n",
      "    optimizer: ['adam', 'adamw', 'adagrad']\n",
      "    activation: ['relu', 'leakyrelu']\n",
      "    l1_lambda: [0]\n",
      "    l2_lambda: [0, 0.0001, 0.001]\n",
      "\n",
      "  Fixed Parameters:\n",
      "    lr: 0.0003\n",
      "    batch_size: 16\n",
      "    epochs: 30\n",
      "    patience: 10\n",
      "\n",
      "================================================================================\n",
      "============================== üìà MODEL COMPARISON ==============================\n",
      "================================================================================\n",
      "Model                             F1   Accuracy\n",
      "--------------------------------------------------------------------------------\n",
      "EEGNet (baseline)             0.3281     0.3154\n",
      "EEGNet (tuned)                0.3892     0.3731\n",
      "ResNet-101 (tuned)            0.5585     0.5921\n",
      "\n",
      "  ‚úÖ EEGNet improved by 18.62% with GridSearch!\n",
      "  üìâ Gap to ResNet-101: 0.1693 (30.3%)\n",
      "\n",
      "================================================================================\n",
      "======================= üìä HYPERPARAMETER IMPACT ANALYSIS =======================\n",
      "================================================================================\n",
      "\n",
      "üîß OPTIMIZER PERFORMANCE:\n",
      "--------------------------------------------------------------------------------\n",
      "               mean       std       max       min  count\n",
      "optimizer                                               \n",
      "adam       0.383633  0.004381  0.389181  0.377480      6\n",
      "adamw      0.381061  0.005406  0.388655  0.373367      6\n",
      "adagrad    0.262102  0.009552  0.269967  0.245708      6\n",
      "\n",
      "‚ö° ACTIVATION FUNCTION PERFORMANCE:\n",
      "--------------------------------------------------------------------------------\n",
      "                mean       std       max       min  count\n",
      "activation                                               \n",
      "leakyrelu   0.342760  0.061280  0.388655  0.245708      9\n",
      "relu        0.341771  0.059694  0.389181  0.255954      9\n",
      "\n",
      "üéõÔ∏è L2 REGULARIZATION IMPACT:\n",
      "--------------------------------------------------------------------------------\n",
      "               mean       std       max       min  count\n",
      "l2_lambda                                               \n",
      "0.0010     0.346109  0.061334  0.389181  0.264054      6\n",
      "0.0001     0.341872  0.057029  0.386422  0.267239      6\n",
      "0.0000     0.338815  0.068297  0.388655  0.245708      6\n",
      "\n",
      "üéØ BEST COMBINATIONS:\n",
      "--------------------------------------------------------------------------------\n",
      "                          mean       max\n",
      "optimizer activation                    \n",
      "adam      leakyrelu   0.384683  0.386422\n",
      "          relu        0.382584  0.389181\n",
      "adamw     leakyrelu   0.381809  0.388655\n",
      "          relu        0.380313  0.383682\n",
      "adagrad   relu        0.262415  0.267239\n",
      "          leakyrelu   0.261788  0.269967\n",
      "\n",
      "üìà OVERALL F1 SCORE STATISTICS:\n",
      "================================================================================\n",
      "  Best:    0.3892 (Config 3)\n",
      "  Worst:   0.2457 (Config 16)\n",
      "  Mean:    0.3423\n",
      "  Median:  0.3789\n",
      "  Std Dev: 0.0587\n",
      "  Range:   0.1435\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Analysis complete!\n",
      "================================================================================\n",
      "\n",
      "‚ö†Ô∏è  BOTTOM 3 CONFIGURATIONS (for reference):\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   ID     Optimizer   Activation       L2         F1      Acc\n",
      "--------------------------------------------------------------------------------\n",
      "16     15       adagrad         relu    1e-03     0.2641   0.2560\n",
      "17     13       adagrad         relu    0e+00     0.2560   0.2524\n",
      "18     16       adagrad    leakyrelu    0e+00     0.2457   0.2427\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Load file\n",
    "file_path = r\"C:\\Users\\numpppy\\Downloads\\hms-harmful-brain-activity-classification\\eegnet_gridsearch_results\\eegnet_gridsearch_final.json\"\n",
    "\n",
    "print(\"üîç Loading file...\")\n",
    "print(f\"üìÅ {file_path}\\n\")\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract results (KEY YANG BENAR: 'all_results')\n",
    "all_results = data['all_results']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"‚úÖ Successfully loaded {len(all_results)} configurations!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sort by F1 score\n",
    "sorted_results = sorted(\n",
    "    all_results, \n",
    "    key=lambda x: x.get('mean_metrics', {}).get('f1', 0), \n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Display TOP 10\n",
    "print(\"\\nüèÜ TOP 10 CONFIGURATIONS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Rank':<6} {'ID':<5} {'Optimizer':>10} {'Activation':>12} {'L1':>8} {'L2':>8} {'F1':>10} {'Acc':>8}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for i, result in enumerate(sorted_results[:10], 1):\n",
    "    p = result.get('params', {})\n",
    "    m = result.get('mean_metrics', {})\n",
    "    config_id = result.get('config_id', 'N/A')\n",
    "    \n",
    "    print(f\"{i:<6} {config_id:<5} {p.get('optimizer', 'N/A'):>10} \"\n",
    "          f\"{p.get('activation', 'N/A'):>12} \"\n",
    "          f\"{p.get('l1_lambda', 0):>8.0e} \"\n",
    "          f\"{p.get('l2_lambda', 0):>8.0e} \"\n",
    "          f\"{m.get('f1', 0):>10.4f} \"\n",
    "          f\"{m.get('accuracy', 0):>8.4f}\")\n",
    "\n",
    "# Best configuration details\n",
    "best = sorted_results[0]\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" üéØ BEST CONFIGURATION \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"  Config ID:  {best.get('config_id', 'N/A')}\")\n",
    "print(f\"  Optimizer:  {best['params'].get('optimizer', 'N/A')}\")\n",
    "print(f\"  Activation: {best['params'].get('activation', 'N/A')}\")\n",
    "print(f\"  L1 Lambda:  {best['params'].get('l1_lambda', 0):.0e}\")\n",
    "print(f\"  L2 Lambda:  {best['params'].get('l2_lambda', 0):.0e}\")\n",
    "\n",
    "m = best.get('mean_metrics', {})\n",
    "print(f\"\\n  üìä Performance:\")\n",
    "print(f\"     F1:        {m.get('f1', 0):.4f} ¬± {m.get('f1_std', 0):.4f}\")\n",
    "print(f\"     Accuracy:  {m.get('accuracy', 0):.4f} ¬± {m.get('accuracy_std', 0):.4f}\")\n",
    "print(f\"     Precision: {m.get('precision', 0):.4f} ¬± {m.get('precision_std', 0):.4f}\")\n",
    "print(f\"     Recall:    {m.get('recall', 0):.4f} ¬± {m.get('recall_std', 0):.4f}\")\n",
    "if 'loss' in m:\n",
    "    print(f\"     Loss:      {m.get('loss', 0):.4f} ¬± {m.get('loss_std', 0):.4f}\")\n",
    "\n",
    "# Grid Search Info\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" üîß GRID SEARCH CONFIGURATION \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"  Total configs tested: {len(all_results)}\")\n",
    "print(f\"  Total time: {data.get('total_time_hours', 'N/A'):.2f} hours\" if 'total_time_hours' in data else \"\")\n",
    "print(f\"\\n  Parameter Grid:\")\n",
    "for param, values in data.get('param_grid', {}).items():\n",
    "    print(f\"    {param}: {values}\")\n",
    "print(f\"\\n  Fixed Parameters:\")\n",
    "for param, value in data.get('fixed_params', {}).items():\n",
    "    print(f\"    {param}: {value}\")\n",
    "\n",
    "# Comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" üìà MODEL COMPARISON \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Model':<25} {'F1':>10} {'Accuracy':>10}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'EEGNet (baseline)':<25} {0.3281:>10.4f} {0.3154:>10.4f}\")\n",
    "print(f\"{'EEGNet (tuned)':<25} {m.get('f1', 0):>10.4f} {m.get('accuracy', 0):>10.4f}\")\n",
    "print(f\"{'ResNet-101 (tuned)':<25} {0.5585:>10.4f} {0.5921:>10.4f}\")\n",
    "\n",
    "# Improvement analysis\n",
    "baseline_f1 = 0.3281\n",
    "tuned_f1 = m.get('f1', 0)\n",
    "\n",
    "print()\n",
    "if tuned_f1 > baseline_f1:\n",
    "    improvement = ((tuned_f1 - baseline_f1) / baseline_f1) * 100\n",
    "    print(f\"  ‚úÖ EEGNet improved by {improvement:.2f}% with GridSearch!\")\n",
    "elif tuned_f1 == baseline_f1:\n",
    "    print(f\"  ‚ö†Ô∏è  EEGNet performance unchanged\")\n",
    "else:\n",
    "    decline = ((baseline_f1 - tuned_f1) / baseline_f1) * 100\n",
    "    print(f\"  ‚ö†Ô∏è  EEGNet declined by {decline:.2f}%\")\n",
    "\n",
    "# Gap to best model\n",
    "resnet_f1 = 0.5585\n",
    "gap = resnet_f1 - tuned_f1\n",
    "gap_pct = (gap / resnet_f1) * 100\n",
    "print(f\"  üìâ Gap to ResNet-101: {gap:.4f} ({gap_pct:.1f}%)\")\n",
    "\n",
    "# Convert to DataFrame for detailed analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" üìä HYPERPARAMETER IMPACT ANALYSIS \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "records = []\n",
    "for r in all_results:\n",
    "    record = {\n",
    "        'config_id': r.get('config_id'),\n",
    "        **r.get('params', {}), \n",
    "        **r.get('mean_metrics', {})\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Optimizer impact\n",
    "print(\"\\nüîß OPTIMIZER PERFORMANCE:\")\n",
    "print(\"-\"*80)\n",
    "opt_stats = df.groupby('optimizer')['f1'].agg(['mean', 'std', 'max', 'min', 'count'])\n",
    "opt_stats = opt_stats.sort_values('mean', ascending=False)\n",
    "print(opt_stats)\n",
    "\n",
    "# Activation impact\n",
    "print(\"\\n‚ö° ACTIVATION FUNCTION PERFORMANCE:\")\n",
    "print(\"-\"*80)\n",
    "act_stats = df.groupby('activation')['f1'].agg(['mean', 'std', 'max', 'min', 'count'])\n",
    "act_stats = act_stats.sort_values('mean', ascending=False)\n",
    "print(act_stats)\n",
    "\n",
    "# L2 Regularization impact (L1 is all 0)\n",
    "print(\"\\nüéõÔ∏è L2 REGULARIZATION IMPACT:\")\n",
    "print(\"-\"*80)\n",
    "l2_stats = df.groupby('l2_lambda')['f1'].agg(['mean', 'std', 'max', 'min', 'count'])\n",
    "l2_stats = l2_stats.sort_values('mean', ascending=False)\n",
    "print(l2_stats)\n",
    "\n",
    "# Combined best combinations\n",
    "print(\"\\nüéØ BEST COMBINATIONS:\")\n",
    "print(\"-\"*80)\n",
    "print(df.groupby(['optimizer', 'activation'])['f1'].agg(['mean', 'max']).sort_values('mean', ascending=False))\n",
    "\n",
    "# Overall statistics\n",
    "print(\"\\nüìà OVERALL F1 SCORE STATISTICS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"  Best:    {df['f1'].max():.4f} (Config {df.loc[df['f1'].idxmax(), 'config_id']})\")\n",
    "print(f\"  Worst:   {df['f1'].min():.4f} (Config {df.loc[df['f1'].idxmin(), 'config_id']})\")\n",
    "print(f\"  Mean:    {df['f1'].mean():.4f}\")\n",
    "print(f\"  Median:  {df['f1'].median():.4f}\")\n",
    "print(f\"  Std Dev: {df['f1'].std():.4f}\")\n",
    "print(f\"  Range:   {df['f1'].max() - df['f1'].min():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Analysis complete!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show worst performers for comparison\n",
    "print(\"\\n‚ö†Ô∏è  BOTTOM 3 CONFIGURATIONS (for reference):\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'Rank':<6} {'ID':<5} {'Optimizer':>10} {'Activation':>12} {'L2':>8} {'F1':>10} {'Acc':>8}\")\n",
    "print(\"-\"*80)\n",
    "for i, result in enumerate(sorted_results[-3:], 1):\n",
    "    p = result.get('params', {})\n",
    "    m = result.get('mean_metrics', {})\n",
    "    config_id = result.get('config_id', 'N/A')\n",
    "    \n",
    "    print(f\"{len(sorted_results)-3+i:<6} {config_id:<5} {p.get('optimizer', 'N/A'):>10} \"\n",
    "          f\"{p.get('activation', 'N/A'):>12} \"\n",
    "          f\"{p.get('l2_lambda', 0):>8.0e} \"\n",
    "          f\"{m.get('f1', 0):>10.4f} \"\n",
    "          f\"{m.get('accuracy', 0):>8.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jkl]",
   "language": "python",
   "name": "conda-env-jkl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
