{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ ResNet-101 Comprehensive GridSearch\n",
    "\n",
    "**Parameters to Explore:**\n",
    "1. ‚úÖ **Optimizer**: Adam, AdamW, SGD\n",
    "2. ‚úÖ **Activation Function**: ReLU, LeakyReLU, ELU\n",
    "3. ‚úÖ **L1 Regularization**: [0, 1e-5, 1e-4]\n",
    "4. ‚úÖ **L2 Regularization (weight_decay)**: [0, 1e-4, 1e-3]\n",
    "5. ‚úÖ **Early Stopping**: patience=10\n",
    "6. ‚úÖ **LR Scheduler**: CosineAnnealingLR\n",
    "7. ‚úÖ **Auto-save**: Results saved after each config\n",
    "\n",
    "**Fixed (Same as KAN):**\n",
    "- Loss: SoftFocalLoss (gamma=3.0)\n",
    "- Data: Hybrid loading (oversample + weighted)\n",
    "- LR: 3e-4\n",
    "- Batch size: 16\n",
    "- Input: 224x224\n",
    "- Pretrained: ImageNet weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ CELL 1: Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "===================== ResNet-101 Comprehensive GridSearch ======================\n",
      "                    Optimizer + Activation + Regularization                     \n",
      "================================================================================\n",
      "\n",
      "Started: 2026-01-07 00:25:52\n",
      "‚úÖ Random seed: 42\n",
      "‚úÖ Device: cuda:0\n",
      "   GPU: NVIDIA GeForce RTX 5060 Ti\n",
      "   Memory: 17.10 GB\n",
      "\n",
      "‚úÖ Paths OK\n",
      "   Data: data_package\n",
      "   Spectrograms: spec_hr_out\n",
      "   Results will be saved to: gridsearch_results\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, \n",
    "    confusion_matrix, accuracy_score\n",
    ")\n",
    "import torchvision.models as models\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" ResNet-101 Comprehensive GridSearch \".center(80, \"=\"))\n",
    "print(\" Optimizer + Activation + Regularization \".center(80))\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nStarted: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# ===== REPRODUCIBILITY =====\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "print(\"‚úÖ Random seed: 42\")\n",
    "\n",
    "# ===== DEVICE =====\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ===== PATHS =====\n",
    "DATA_PKG = Path(\"data_package\")\n",
    "SPEC_DIR = Path(\"spec_hr_out\")\n",
    "RESULTS_DIR = Path(\"gridsearch_results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "assert DATA_PKG.exists(), \"‚ùå data_package/ not found\"\n",
    "assert SPEC_DIR.exists(), \"‚ùå spec_hr_out/ not found\"\n",
    "print(f\"\\n‚úÖ Paths OK\")\n",
    "print(f\"   Data: {DATA_PKG}\")\n",
    "print(f\"   Spectrograms: {SPEC_DIR}\")\n",
    "print(f\"   Results will be saved to: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä CELL 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "================================= LOADING DATA =================================\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Data loaded:\n",
      "   Metadata: (17089, 3)\n",
      "   Labels: (17089, 6)\n",
      "   Classes: ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n",
      "\n",
      "üìä CLASS DISTRIBUTION:\n",
      "--------------------------------------------------------------------------------\n",
      "  seizure   :  2716 ( 15.9%)\n",
      "  lpd       :  2583 ( 15.1%)\n",
      "  gpd       :  1814 ( 10.6%)\n",
      "  lrda      :   936 (  5.5%)\n",
      "  grda      :  1835 ( 10.7%)\n",
      "  other     :  7205 ( 42.2%)\n",
      "  TOTAL     : 17089\n",
      "\n",
      "üìÇ Creating stratified folds...\n",
      "‚úÖ Created 3-fold CV\n",
      "   Fold 0: train=11392, val=5697\n",
      "   Fold 1: train=11393, val=5696\n",
      "   Fold 2: train=11393, val=5696\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" LOADING DATA \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "meta_use = pd.read_csv(DATA_PKG / \"meta_use.csv\")\n",
    "lbl = np.load(DATA_PKG / \"labels.npz\", allow_pickle=True)\n",
    "y_soft = lbl[\"y_soft\"]\n",
    "w_conf = lbl[\"w_conf\"]\n",
    "classes = [str(c) for c in lbl[\"classes\"]]\n",
    "y_hard = y_soft.argmax(axis=1)\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded:\")\n",
    "print(f\"   Metadata: {meta_use.shape}\")\n",
    "print(f\"   Labels: {y_soft.shape}\")\n",
    "print(f\"   Classes: {classes}\")\n",
    "\n",
    "# Class distribution\n",
    "print(\"\\nüìä CLASS DISTRIBUTION:\")\n",
    "print(\"-\"*80)\n",
    "for i, cls in enumerate(classes):\n",
    "    count = (y_hard == i).sum()\n",
    "    pct = 100 * count / len(y_hard)\n",
    "    print(f\"  {cls:10s}: {count:5d} ({pct:5.1f}%)\")\n",
    "print(f\"  {'TOTAL':10s}: {len(y_hard):5d}\")\n",
    "\n",
    "# Create 3-fold CV\n",
    "print(\"\\nüìÇ Creating stratified folds...\")\n",
    "N_FOLDS = 3\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "folds = list(skf.split(meta_use, y_hard))\n",
    "print(f\"‚úÖ Created {N_FOLDS}-fold CV\")\n",
    "for i, (tr_idx, va_idx) in enumerate(folds):\n",
    "    print(f\"   Fold {i}: train={len(tr_idx)}, val={len(va_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ CELL 3: Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "================================ DATASET CLASS =================================\n",
      "================================================================================\n",
      "‚úÖ Dataset class ready\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" DATASET CLASS \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "class SpecDataset(Dataset):\n",
    "    \"\"\"EEG Spectrogram Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, df, root_dir, y_soft, w_conf, F_target=81, T_target=600):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root = Path(root_dir)\n",
    "        self.y_soft = y_soft\n",
    "        self.w_conf = w_conf\n",
    "        self.F_target = F_target\n",
    "        self.T_target = T_target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _center_crop_pad(self, x):\n",
    "        C, F, T = x.shape\n",
    "        # Frequency\n",
    "        if F >= self.F_target:\n",
    "            f0 = (F - self.F_target) // 2\n",
    "            x = x[:, f0:f0+self.F_target, :]\n",
    "        else:\n",
    "            pad = self.F_target - F\n",
    "            x = np.pad(x, ((0,0),(pad//2, pad-pad//2),(0,0)), mode=\"constant\")\n",
    "        # Time\n",
    "        if T >= self.T_target:\n",
    "            t0 = (T - self.T_target) // 2\n",
    "            x = x[:, :, t0:t0+self.T_target]\n",
    "        else:\n",
    "            pad = self.T_target - T\n",
    "            x = np.pad(x, ((0,0),(0,0),(pad//2, pad-pad//2)), mode=\"constant\")\n",
    "        return x.copy()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        eid = int(row.eeg_id)\n",
    "        \n",
    "        npz = np.load(self.root / f\"{eid}_hr.npz\")\n",
    "        x = npz[\"x\"]\n",
    "        \n",
    "        x = self._center_crop_pad(x)\n",
    "        x = torch.from_numpy(x).float()\n",
    "        \n",
    "        # Resize to 224x224\n",
    "        x = F.interpolate(x.unsqueeze(0), size=(224, 224),\n",
    "                          mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "        \n",
    "        y = torch.from_numpy(self.y_soft[self.df.index[idx]]).float()\n",
    "        w = torch.tensor(self.w_conf[self.df.index[idx]], dtype=torch.float32)\n",
    "        \n",
    "        return x, y, w\n",
    "\n",
    "print(\"‚úÖ Dataset class ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è CELL 4: ResNet-101 with Configurable Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel4Ch(nn.Module):\n",
    "    \"\"\"Base class for adapting models to 4-channel input\"\"\"\n",
    "    \n",
    "    def adapt_first_conv(self, old_conv):\n",
    "        new_conv = nn.Conv2d(\n",
    "            in_channels=4,\n",
    "            out_channels=old_conv.out_channels,\n",
    "            kernel_size=old_conv.kernel_size,\n",
    "            stride=old_conv.stride,\n",
    "            padding=old_conv.padding,\n",
    "            bias=False if old_conv.bias is None else True\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            new_conv.weight[:, :3] = old_conv.weight\n",
    "            new_conv.weight[:, 3:] = old_conv.weight.mean(dim=1, keepdim=True) * 0.33\n",
    "            if old_conv.bias is not None:\n",
    "                new_conv.bias = old_conv.bias\n",
    "        return new_conv\n",
    "\n",
    "\n",
    "class ResNet101_4Ch_Configurable(BaseModel4Ch):\n",
    "    \"\"\"ResNet-101 with configurable activation function\"\"\"\n",
    "    \n",
    "    def __init__(self, n_classes=6, activation='relu', pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load pretrained model\n",
    "        if pretrained:\n",
    "            self.model = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V1)\n",
    "        else:\n",
    "            self.model = models.resnet101(weights=None)\n",
    "        \n",
    "        # Adapt first conv\n",
    "        self.model.conv1 = self.adapt_first_conv(self.model.conv1)\n",
    "        \n",
    "        # Replace classifier\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, n_classes)\n",
    "        \n",
    "        # Replace activation functions if not ReLU\n",
    "        if activation == 'leakyrelu':\n",
    "            self._replace_activations()\n",
    "        \n",
    "        self.activation_type = activation\n",
    "    \n",
    "    def _replace_activations(self):\n",
    "        \"\"\"Replace all ReLU with LeakyReLU\"\"\"\n",
    "        for name, module in self.model.named_modules():\n",
    "            if isinstance(module, nn.ReLU):\n",
    "                parent_name = '.'.join(name.split('.')[:-1])\n",
    "                child_name = name.split('.')[-1]\n",
    "                \n",
    "                if parent_name:\n",
    "                    parent = dict(self.model.named_modules())[parent_name]\n",
    "                    setattr(parent, child_name, nn.LeakyReLU(0.01, True))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ CELL 5: SoftFocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "=============================== SOFT FOCAL LOSS ================================\n",
      "================================================================================\n",
      "‚úÖ SoftFocalLoss defined (gamma=3.0)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" SOFT FOCAL LOSS \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "class SoftFocalLoss(nn.Module):\n",
    "    \"\"\"Soft Focal Loss - same as KAN\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=None, gamma=3.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, logits, soft_targets, sample_weights=None):\n",
    "        hard_targets = soft_targets.argmax(dim=1)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        p_t = probs.gather(1, hard_targets.unsqueeze(1)).squeeze(1)\n",
    "        ce_loss = -(soft_targets * F.log_softmax(logits, dim=1)).sum(dim=1)\n",
    "        focal_weight = ((1 - p_t) ** self.gamma)\n",
    "        loss = focal_weight * ce_loss\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha[hard_targets]\n",
    "            loss = alpha_t * loss\n",
    "        \n",
    "        if sample_weights is not None:\n",
    "            loss = loss * sample_weights\n",
    "        \n",
    "        return loss.mean()\n",
    "\n",
    "print(\"‚úÖ SoftFocalLoss defined (gamma=3.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ CELL 6: Hybrid Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "============================= HYBRID DATA LOADING ==============================\n",
      "================================================================================\n",
      "‚úÖ Hybrid loader function ready\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" HYBRID DATA LOADING \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "def create_hybrid_loader(fold=0, target_ratio=0.4, weight_power=3.0, batch_size=16, verbose=False):\n",
    "    tr_idx, va_idx = folds[fold]\n",
    "    df_tr = meta_use.iloc[tr_idx]\n",
    "    y_soft_tr, w_conf_tr = y_soft[tr_idx], w_conf[tr_idx]\n",
    "    \n",
    "    y_hard = y_soft_tr.argmax(axis=1)\n",
    "    counts = np.bincount(y_hard, minlength=6)\n",
    "    \n",
    "    target = int(counts.max() * target_ratio)\n",
    "    \n",
    "    # Oversample\n",
    "    indices_add = []\n",
    "    for i in range(6):\n",
    "        mask = y_hard == i\n",
    "        if mask.sum() < target:\n",
    "            idx = np.where(mask)[0]\n",
    "            n_add = target - mask.sum()\n",
    "            indices_add.extend(np.random.choice(idx, n_add, replace=True))\n",
    "    \n",
    "    all_idx = np.concatenate([np.arange(len(y_hard)), indices_add])\n",
    "    np.random.shuffle(all_idx)\n",
    "    \n",
    "    df_tr_over = df_tr.iloc[all_idx].reset_index(drop=True)\n",
    "    y_soft_over, w_conf_over = y_soft_tr[all_idx], w_conf_tr[all_idx]\n",
    "    \n",
    "    y_hard_over = y_soft_over.argmax(axis=1)\n",
    "    counts_over = np.bincount(y_hard_over, minlength=6)\n",
    "    \n",
    "    weights = (len(y_hard_over) / (counts_over + 1)) ** weight_power\n",
    "    weights = torch.FloatTensor(weights / weights.sum() * 6)\n",
    "    \n",
    "    sample_weights = weights[y_hard_over].numpy()\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    ds_tr = SpecDataset(df_tr_over, SPEC_DIR, y_soft_over, w_conf_over)\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=batch_size, sampler=sampler, num_workers=0)\n",
    "    \n",
    "    ds_va = SpecDataset(meta_use.iloc[va_idx], SPEC_DIR, y_soft[va_idx], w_conf[va_idx])\n",
    "    dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    return dl_tr, dl_va, weights\n",
    "\n",
    "print(\"‚úÖ Hybrid loader function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà CELL 7: Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "============================= EVALUATION FUNCTION ==============================\n",
      "================================================================================\n",
      "‚úÖ Evaluation function ready\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" EVALUATION FUNCTION \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_full(model, loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    \n",
    "    for x, y, w in loader:\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        preds.append(logits.argmax(1).cpu().numpy())\n",
    "        targets.append(y.argmax(1).cpu().numpy())\n",
    "    \n",
    "    y_pred = np.concatenate(preds)\n",
    "    y_true = np.concatenate(targets)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Evaluation function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è CELL 8: Training Function with L1/L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training function ready\n",
      "   Optimizers: Adam, AdamW, Adagrad\n",
      "   L1/L2 regularization supported\n",
      "   Early stopping: patience=10\n"
     ]
    }
   ],
   "source": [
    "def train_one_config(fold, optimizer_name, activation, l1_lambda, l2_lambda, \n",
    "                     lr=3e-4, batch_size=16, epochs=30, patience=10):\n",
    "    \"\"\"\n",
    "    Train with specific configuration\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    \n",
    "    # [1/6] Data\n",
    "    print(f\"      [1/6] Data loaders...\", end=\" \", flush=True)\n",
    "    sys.stdout.flush()\n",
    "    t0 = time.time()\n",
    "    \n",
    "    dl_tr, dl_va, class_weights = create_hybrid_loader(\n",
    "        fold=fold, target_ratio=0.4, weight_power=3.0, batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úì ({time.time()-t0:.1f}s)\", flush=True)\n",
    "    \n",
    "    # [2/6] Model\n",
    "    print(f\"      [2/6] Model ({activation})...\", end=\" \", flush=True)\n",
    "    sys.stdout.flush()\n",
    "    t0 = time.time()\n",
    "    \n",
    "    model = ResNet101_4Ch_Configurable(\n",
    "        n_classes=6, \n",
    "        activation=activation, \n",
    "        pretrained=True\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"‚úì ({time.time()-t0:.1f}s)\", flush=True)\n",
    "    \n",
    "    # [3/6] Optimizer\n",
    "    print(f\"      [3/6] Optimizer ({optimizer_name}, L2={l2_lambda:.0e})...\", end=\" \", flush=True)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_lambda)\n",
    "    elif optimizer_name == 'adamw':\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=l2_lambda)\n",
    "    elif optimizer_name == 'adagrad':\n",
    "        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=l2_lambda)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
    "    \n",
    "    print(f\"‚úì\", flush=True)\n",
    "    \n",
    "    # [4/6] Loss & Scheduler\n",
    "    print(f\"      [4/6] Loss & Scheduler...\", end=\" \", flush=True)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    criterion = SoftFocalLoss(alpha=class_weights.to(device), gamma=3.0)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    print(f\"‚úì\", flush=True)\n",
    "    \n",
    "    # [5/6] CUDA warmup\n",
    "    print(f\"      [5/6] CUDA warmup...\", end=\" \", flush=True)\n",
    "    sys.stdout.flush()\n",
    "    t0 = time.time()\n",
    "    \n",
    "    xb, yb, wb = next(iter(dl_tr))\n",
    "    xb = xb.to(device)\n",
    "    with torch.no_grad():\n",
    "        _ = model(xb)\n",
    "    del xb, yb, wb\n",
    "    \n",
    "    print(f\"‚úì ({time.time()-t0:.1f}s)\", flush=True)\n",
    "    \n",
    "    # [6/6] Training\n",
    "    print(f\"      [6/6] Training (patience={patience}, L1={l1_lambda:.0e})...\", flush=True)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    best_f1, best_state, no_improve = 0.0, None, 0\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss, n = 0.0, 0\n",
    "        \n",
    "        for x, y, w in dl_tr:\n",
    "            x, y, w = x.to(device), y.to(device), w.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y, w)\n",
    "            \n",
    "            # L1 Regularization\n",
    "            if l1_lambda > 0:\n",
    "                l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "                loss = loss + l1_lambda * l1_norm\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * x.size(0)\n",
    "            n += x.size(0)\n",
    "        \n",
    "        train_loss /= n\n",
    "        \n",
    "        # Validation\n",
    "        val_results = evaluate_full(model, dl_va)\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_results['f1'] > best_f1:\n",
    "            best_f1 = val_results['f1']\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"        Early stop at epoch {epoch}\", flush=True)\n",
    "                break\n",
    "        \n",
    "        # Progress\n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            print(f\"        Epoch {epoch:2d}: F1={val_results['f1']:.4f}, Loss={train_loss:.4f}\", flush=True)\n",
    "        \n",
    "        # Cleanup\n",
    "        if epoch % 5 == 0:\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Load best\n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    final_results = evaluate_full(model, dl_va)\n",
    "    \n",
    "    # Cleanup\n",
    "    del model, optimizer, scheduler, dl_tr, dl_va\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "print(\"‚úÖ Training function ready\")\n",
    "print(\"   Optimizers: Adam, AdamW, Adagrad\")\n",
    "print(\"   L1/L2 regularization supported\")\n",
    "print(\"   Early stopping: patience=10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç CELL 9: GridSearch Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "=========================== GRIDSEARCH CONFIGURATION ===========================\n",
      "================================================================================\n",
      "\n",
      "üìã HYPERPARAMETER GRID:\n",
      "--------------------------------------------------------------------------------\n",
      "  Optimizer:   ['adam', 'adamw', 'adagrad']\n",
      "  Activation:  ['relu', 'leakyrelu']\n",
      "  L1 lambda:   [0]\n",
      "  L2 lambda:   [0, 0.0001, 0.001]\n",
      "\n",
      "üìä GRIDSEARCH STATISTICS:\n",
      "--------------------------------------------------------------------------------\n",
      "  Total combinations: 18\n",
      "  Folds per config:   3\n",
      "  Total trainings:    54\n",
      "  Est. time per run:  ~20 min\n",
      "  Est. total time:    ~18.0 hours\n",
      "\n",
      "üîß FIXED PARAMETERS:\n",
      "--------------------------------------------------------------------------------\n",
      "  Learning rate: 0.0003\n",
      "  Batch size:    16\n",
      "  Max epochs:    30\n",
      "  Patience:      10\n",
      "\n",
      "üìù ALL COMBINATIONS TO TEST:\n",
      "--------------------------------------------------------------------------------\n",
      "   1. adam    + relu       + L1=0e+00 + L2=0e+00\n",
      "   2. adam    + relu       + L1=0e+00 + L2=1e-04\n",
      "   3. adam    + relu       + L1=0e+00 + L2=1e-03\n",
      "   4. adam    + leakyrelu  + L1=0e+00 + L2=0e+00\n",
      "   5. adam    + leakyrelu  + L1=0e+00 + L2=1e-04\n",
      "   6. adam    + leakyrelu  + L1=0e+00 + L2=1e-03\n",
      "   7. adamw   + relu       + L1=0e+00 + L2=0e+00\n",
      "   8. adamw   + relu       + L1=0e+00 + L2=1e-04\n",
      "   9. adamw   + relu       + L1=0e+00 + L2=1e-03\n",
      "  10. adamw   + leakyrelu  + L1=0e+00 + L2=0e+00\n",
      "  11. adamw   + leakyrelu  + L1=0e+00 + L2=1e-04\n",
      "  12. adamw   + leakyrelu  + L1=0e+00 + L2=1e-03\n",
      "  13. adagrad + relu       + L1=0e+00 + L2=0e+00\n",
      "  14. adagrad + relu       + L1=0e+00 + L2=1e-04\n",
      "  15. adagrad + relu       + L1=0e+00 + L2=1e-03\n",
      "  16. adagrad + leakyrelu  + L1=0e+00 + L2=0e+00\n",
      "  17. adagrad + leakyrelu  + L1=0e+00 + L2=1e-04\n",
      "  18. adagrad + leakyrelu  + L1=0e+00 + L2=1e-03\n",
      "\n",
      "üéØ COMPARISON FOCUS:\n",
      "--------------------------------------------------------------------------------\n",
      "  ‚úÖ 4 Optimizers: Adam vs AdamW vs Adagrad\n",
      "  ‚úÖ 2 Activations: ReLU vs LeakyReLU\n",
      "  ‚úÖ 3 L2 values: None vs Light (1e-4) vs Strong (1e-3)\n",
      "\n",
      "‚è±Ô∏è  TIMELINE:\n",
      "--------------------------------------------------------------------------------\n",
      "  Start:  2026-01-07 00:26\n",
      "  Finish: 2026-01-08 00:26 (approx)\n",
      "\n",
      "üíæ AUTO-SAVE ENABLED:\n",
      "--------------------------------------------------------------------------------\n",
      "  Results directory: gridsearch_results/\n",
      "  - gridsearch_progress.json (updated after each config)\n",
      "  - gridsearch_summary.txt (human-readable)\n",
      "  - gridsearch_final.json (complete results at end)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" GRIDSEARCH CONFIGURATION \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# HYPERPARAMETER GRID - WITH LEAKYRELU\n",
    "# ============================================================================\n",
    "\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'adamw', 'adagrad'],  # 4 optimizers\n",
    "    'activation': ['relu', 'leakyrelu'],               # 2 activations ‚úÖ\n",
    "    'l1_lambda': [0],                                   # No L1\n",
    "    'l2_lambda': [0, 1e-4, 1e-3],                      # 3 L2 values\n",
    "}\n",
    "\n",
    "# Fixed parameters\n",
    "fixed_params = {\n",
    "    'lr': 3e-4,\n",
    "    'batch_size': 16,\n",
    "    'epochs': 30,\n",
    "    'patience': 10,\n",
    "}\n",
    "\n",
    "# Generate combinations\n",
    "keys = list(param_grid.keys())\n",
    "values = list(param_grid.values())\n",
    "combinations = list(product(*values))\n",
    "\n",
    "print(\"\\nüìã HYPERPARAMETER GRID:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Optimizer:   {param_grid['optimizer']}\")\n",
    "print(f\"  Activation:  {param_grid['activation']}\")\n",
    "print(f\"  L1 lambda:   {param_grid['l1_lambda']}\")\n",
    "print(f\"  L2 lambda:   {param_grid['l2_lambda']}\")\n",
    "\n",
    "print(\"\\nüìä GRIDSEARCH STATISTICS:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Total combinations: {len(combinations)}\")\n",
    "print(f\"  Folds per config:   {N_FOLDS}\")\n",
    "print(f\"  Total trainings:    {len(combinations) * N_FOLDS}\")\n",
    "print(f\"  Est. time per run:  ~20 min\")\n",
    "print(f\"  Est. total time:    ~{len(combinations) * N_FOLDS * 20 / 60:.1f} hours\")\n",
    "\n",
    "print(\"\\nüîß FIXED PARAMETERS:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Learning rate: {fixed_params['lr']}\")\n",
    "print(f\"  Batch size:    {fixed_params['batch_size']}\")\n",
    "print(f\"  Max epochs:    {fixed_params['epochs']}\")\n",
    "print(f\"  Patience:      {fixed_params['patience']}\")\n",
    "\n",
    "print(\"\\nüìù ALL COMBINATIONS TO TEST:\")\n",
    "print(\"-\"*80)\n",
    "for i, combo in enumerate(combinations, 1):\n",
    "    params = dict(zip(keys, combo))\n",
    "    print(f\"  {i:2d}. {params['optimizer']:7s} + {params['activation']:10s} + \"\n",
    "          f\"L1={params['l1_lambda']:.0e} + L2={params['l2_lambda']:.0e}\")\n",
    "\n",
    "print(\"\\nüéØ COMPARISON FOCUS:\")\n",
    "print(\"-\"*80)\n",
    "print(\"  ‚úÖ 4 Optimizers: Adam vs AdamW vs Adagrad\")\n",
    "print(\"  ‚úÖ 2 Activations: ReLU vs LeakyReLU\")\n",
    "print(\"  ‚úÖ 3 L2 values: None vs Light (1e-4) vs Strong (1e-3)\")\n",
    "\n",
    "print(\"\\n‚è±Ô∏è  TIMELINE:\")\n",
    "print(\"-\"*80)\n",
    "current_time = datetime.now()\n",
    "finish_time = current_time + pd.Timedelta(hours=24)\n",
    "print(f\"  Start:  {current_time.strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(f\"  Finish: {finish_time.strftime('%Y-%m-%d %H:%M')} (approx)\")\n",
    "\n",
    "print(\"\\nüíæ AUTO-SAVE ENABLED:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Results directory: {RESULTS_DIR}/\")\n",
    "print(f\"  - gridsearch_progress.json (updated after each config)\")\n",
    "print(f\"  - gridsearch_summary.txt (human-readable)\")\n",
    "print(f\"  - gridsearch_final.json (complete results at end)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ CELL 10: Run GridSearch with Auto-Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "===================== RUNNING GRIDSEARCH (WITH AUTO-SAVE) ======================\n",
      "================================================================================\n",
      "\n",
      "Started: 2026-01-07 00:26:03\n",
      "Total runs: 54\n",
      "\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 1/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: relu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (1.1s)\n",
      "      [3/6] Optimizer (adam, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.4s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3587, Loss=0.7288\n",
      "        Epoch  5: F1=0.3684, Loss=0.1682\n",
      "        Epoch 10: F1=0.3800, Loss=0.0999\n",
      "        Epoch 15: F1=0.4137, Loss=0.0836\n",
      "        Epoch 20: F1=0.4658, Loss=0.0739\n",
      "        Epoch 25: F1=0.5104, Loss=0.0737\n",
      "        Epoch 30: F1=0.5189, Loss=0.0702\n",
      "\n",
      "    ‚úì Fold 1: F1=0.5189 (93.5 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adam, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3441, Loss=0.7413\n",
      "        Epoch  5: F1=0.3542, Loss=0.1749\n",
      "        Epoch 10: F1=0.3838, Loss=0.0996\n",
      "        Epoch 15: F1=0.4679, Loss=0.0794\n",
      "        Epoch 20: F1=0.5046, Loss=0.0718\n",
      "        Epoch 25: F1=0.5235, Loss=0.0677\n",
      "        Epoch 30: F1=0.5324, Loss=0.0766\n",
      "\n",
      "    ‚úì Fold 2: F1=0.5349 (93.4 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adam, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3831, Loss=0.7234\n",
      "        Epoch  5: F1=0.3850, Loss=0.1736\n",
      "        Epoch 10: F1=0.3903, Loss=0.1033\n",
      "        Epoch 15: F1=0.4534, Loss=0.0867\n",
      "        Epoch 20: F1=0.5122, Loss=0.0794\n",
      "        Epoch 25: F1=0.5360, Loss=0.0778\n",
      "        Epoch 30: F1=0.5372, Loss=0.0747\n",
      "\n",
      "    ‚úì Fold 3: F1=0.5422 (96.7 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.5320 ¬± 0.0097\n",
      "  Mean Acc: 0.5836\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 2/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: relu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.8s)\n",
      "      [3/6] Optimizer (adam, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3523, Loss=0.7362\n",
      "        Epoch  5: F1=0.3549, Loss=0.2132\n",
      "        Epoch 10: F1=0.3620, Loss=0.1154\n",
      "        Epoch 15: F1=0.3754, Loss=0.0905\n",
      "        Epoch 20: F1=0.4240, Loss=0.0738\n",
      "        Epoch 25: F1=0.4877, Loss=0.0781\n",
      "        Epoch 30: F1=0.4990, Loss=0.0751\n",
      "\n",
      "    ‚úì Fold 1: F1=0.5032 (94.3 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adam, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3701, Loss=0.7300\n",
      "        Epoch  5: F1=0.3594, Loss=0.2133\n",
      "        Epoch 10: F1=0.3593, Loss=0.1212\n",
      "        Early stop at epoch 11\n",
      "\n",
      "    ‚úì Fold 2: F1=0.3701 (34.8 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adam, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3285, Loss=0.7482\n",
      "        Epoch  5: F1=0.3633, Loss=0.2256\n",
      "        Epoch 10: F1=0.3640, Loss=0.1216\n",
      "        Early stop at epoch 13\n",
      "\n",
      "    ‚úì Fold 3: F1=0.3860 (41.0 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.4198 ¬± 0.0594\n",
      "  Mean Acc: 0.4211\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 3/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: relu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adam, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3015, Loss=0.8148\n",
      "        Epoch  5: F1=0.3591, Loss=0.4227\n",
      "        Epoch 10: F1=0.3393, Loss=0.2614\n",
      "        Early stop at epoch 15\n",
      "\n",
      "    ‚úì Fold 1: F1=0.3591 (47.2 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adam, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3301, Loss=0.7824\n",
      "        Epoch  5: F1=0.2740, Loss=0.4290\n",
      "        Epoch 10: F1=0.3044, Loss=0.2682\n",
      "        Early stop at epoch 14\n",
      "\n",
      "    ‚úì Fold 2: F1=0.3611 (44.1 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adam, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3384, Loss=0.8167\n",
      "        Epoch  5: F1=0.3426, Loss=0.4712\n",
      "        Epoch 10: F1=0.3492, Loss=0.2901\n",
      "        Epoch 15: F1=0.3604, Loss=0.2035\n",
      "        Early stop at epoch 17\n",
      "\n",
      "    ‚úì Fold 3: F1=0.3748 (54.3 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.3650 ¬± 0.0070\n",
      "  Mean Acc: 0.3542\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 4/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: leakyrelu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (1.0s)\n",
      "      [3/6] Optimizer (adam, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3344, Loss=0.7673\n",
      "        Epoch  5: F1=0.3283, Loss=0.1801\n",
      "        Epoch 10: F1=0.4044, Loss=0.0998\n",
      "        Epoch 15: F1=0.4242, Loss=0.0904\n",
      "        Epoch 20: F1=0.5119, Loss=0.0751\n",
      "        Epoch 25: F1=0.5158, Loss=0.0777\n",
      "        Epoch 30: F1=0.5242, Loss=0.0703\n",
      "\n",
      "    ‚úì Fold 1: F1=0.5283 (94.6 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adam, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3411, Loss=0.7209\n",
      "        Epoch  5: F1=0.3680, Loss=0.1767\n",
      "        Epoch 10: F1=0.3865, Loss=0.0961\n",
      "        Epoch 15: F1=0.4483, Loss=0.0784\n",
      "        Epoch 20: F1=0.4920, Loss=0.0766\n",
      "        Epoch 25: F1=0.5211, Loss=0.0686\n",
      "        Epoch 30: F1=0.5220, Loss=0.0754\n",
      "\n",
      "    ‚úì Fold 2: F1=0.5220 (94.1 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adam, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3606, Loss=0.7406\n",
      "        Epoch  5: F1=0.3464, Loss=0.1866\n",
      "        Epoch 10: F1=0.3933, Loss=0.0970\n",
      "        Epoch 15: F1=0.4323, Loss=0.0847\n",
      "        Epoch 20: F1=0.5042, Loss=0.0781\n",
      "        Epoch 25: F1=0.5288, Loss=0.0798\n",
      "        Epoch 30: F1=0.5435, Loss=0.0759\n",
      "\n",
      "    ‚úì Fold 3: F1=0.5440 (93.9 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.5315 ¬± 0.0092\n",
      "  Mean Acc: 0.5821\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 5/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: leakyrelu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.8s)\n",
      "      [3/6] Optimizer (adam, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3517, Loss=0.7451\n",
      "        Epoch  5: F1=0.3582, Loss=0.2248\n",
      "        Epoch 10: F1=0.3655, Loss=0.1273\n",
      "        Epoch 15: F1=0.3756, Loss=0.0906\n",
      "        Epoch 20: F1=0.4153, Loss=0.0788\n",
      "        Epoch 25: F1=0.4643, Loss=0.0765\n",
      "        Epoch 30: F1=0.4952, Loss=0.0737\n",
      "\n",
      "    ‚úì Fold 1: F1=0.4952 (94.6 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adam, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3191, Loss=0.7429\n",
      "        Epoch  5: F1=0.2940, Loss=0.2232\n",
      "        Epoch 10: F1=0.3242, Loss=0.1183\n",
      "        Epoch 15: F1=0.3753, Loss=0.0899\n",
      "        Epoch 20: F1=0.4194, Loss=0.0774\n",
      "        Epoch 25: F1=0.4659, Loss=0.0768\n",
      "        Epoch 30: F1=0.4974, Loss=0.0756\n",
      "\n",
      "    ‚úì Fold 2: F1=0.4988 (95.4 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adam, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3707, Loss=0.7683\n",
      "        Epoch  5: F1=0.3397, Loss=0.2269\n",
      "        Epoch 10: F1=0.3753, Loss=0.1265\n",
      "        Epoch 15: F1=0.3796, Loss=0.0954\n",
      "        Epoch 20: F1=0.3928, Loss=0.0819\n",
      "        Epoch 25: F1=0.4805, Loss=0.0872\n",
      "        Epoch 30: F1=0.5063, Loss=0.0777\n",
      "\n",
      "    ‚úì Fold 3: F1=0.5074 (94.1 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.5005 ¬± 0.0051\n",
      "  Mean Acc: 0.5328\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 6/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adam\n",
      "  Activation: leakyrelu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (1.0s)\n",
      "      [3/6] Optimizer (adam, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3218, Loss=0.8087\n",
      "        Epoch  5: F1=0.3539, Loss=0.4362\n",
      "        Epoch 10: F1=0.3373, Loss=0.2637\n",
      "        Early stop at epoch 13\n",
      "\n",
      "    ‚úì Fold 1: F1=0.3674 (41.1 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.8s)\n",
      "      [3/6] Optimizer (adam, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3009, Loss=0.7898\n",
      "        Epoch  5: F1=0.2981, Loss=0.3966\n",
      "        Epoch 10: F1=0.3296, Loss=0.2592\n",
      "        Early stop at epoch 13\n",
      "\n",
      "    ‚úì Fold 2: F1=0.3628 (40.9 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adam, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3355, Loss=0.8164\n",
      "        Epoch  5: F1=0.3344, Loss=0.4174\n",
      "        Epoch 10: F1=0.3737, Loss=0.2646\n",
      "        Early stop at epoch 13\n",
      "\n",
      "    ‚úì Fold 3: F1=0.3752 (41.1 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.3685 ¬± 0.0051\n",
      "  Mean Acc: 0.3458\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 7/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: relu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.8s)\n",
      "      [3/6] Optimizer (adamw, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3298, Loss=0.7054\n",
      "        Epoch  5: F1=0.3650, Loss=0.1741\n",
      "        Epoch 10: F1=0.3934, Loss=0.1005\n",
      "        Epoch 15: F1=0.4522, Loss=0.0838\n",
      "        Epoch 20: F1=0.5198, Loss=0.0749\n",
      "        Epoch 25: F1=0.5102, Loss=0.0732\n",
      "        Epoch 30: F1=0.5289, Loss=0.0797\n",
      "\n",
      "    ‚úì Fold 1: F1=0.5309 (93.4 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adamw, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3110, Loss=0.7407\n",
      "        Epoch  5: F1=0.3749, Loss=0.1838\n",
      "        Epoch 10: F1=0.3672, Loss=0.1015\n",
      "        Epoch 15: F1=0.4329, Loss=0.0848\n",
      "        Epoch 20: F1=0.4798, Loss=0.0723\n",
      "        Epoch 25: F1=0.5185, Loss=0.0769\n",
      "        Epoch 30: F1=0.5272, Loss=0.0711\n",
      "\n",
      "    ‚úì Fold 2: F1=0.5318 (93.8 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (1.0s)\n",
      "      [3/6] Optimizer (adamw, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3378, Loss=0.7383\n",
      "        Epoch  5: F1=0.3529, Loss=0.1789\n",
      "        Epoch 10: F1=0.3804, Loss=0.1096\n",
      "        Epoch 15: F1=0.4306, Loss=0.0810\n",
      "        Epoch 20: F1=0.5069, Loss=0.0847\n",
      "        Epoch 25: F1=0.5189, Loss=0.0772\n",
      "        Epoch 30: F1=0.5243, Loss=0.0725\n",
      "\n",
      "    ‚úì Fold 3: F1=0.5258 (93.5 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.5295 ¬± 0.0026\n",
      "  Mean Acc: 0.5773\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 8/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: relu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adamw, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3537, Loss=0.7169\n",
      "        Epoch  5: F1=0.3724, Loss=0.1693\n",
      "        Epoch 10: F1=0.3647, Loss=0.0974\n",
      "        Epoch 15: F1=0.4629, Loss=0.0806\n",
      "        Epoch 20: F1=0.5019, Loss=0.0726\n",
      "        Epoch 25: F1=0.5067, Loss=0.0725\n",
      "        Epoch 30: F1=0.5093, Loss=0.0732\n",
      "\n",
      "    ‚úì Fold 1: F1=0.5129 (93.8 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.8s)\n",
      "      [3/6] Optimizer (adamw, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3530, Loss=0.7306\n",
      "        Epoch  5: F1=0.3755, Loss=0.1692\n",
      "        Epoch 10: F1=0.3820, Loss=0.0982\n",
      "        Epoch 15: F1=0.4440, Loss=0.0810\n",
      "        Epoch 20: F1=0.4840, Loss=0.0725\n",
      "        Epoch 25: F1=0.5104, Loss=0.0752\n",
      "        Epoch 30: F1=0.5135, Loss=0.0754\n",
      "\n",
      "    ‚úì Fold 2: F1=0.5165 (96.2 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (1.0s)\n",
      "      [3/6] Optimizer (adamw, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3105, Loss=0.7483\n",
      "        Epoch  5: F1=0.3649, Loss=0.1796\n",
      "        Epoch 10: F1=0.3931, Loss=0.1111\n",
      "        Epoch 15: F1=0.4404, Loss=0.0768\n",
      "        Epoch 20: F1=0.4916, Loss=0.0755\n",
      "        Epoch 25: F1=0.5319, Loss=0.0729\n",
      "        Epoch 30: F1=0.5355, Loss=0.0773\n",
      "\n",
      "    ‚úì Fold 3: F1=0.5405 (93.9 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.5233 ¬± 0.0122\n",
      "  Mean Acc: 0.5718\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 9/18 ==================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: relu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adamw, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3659, Loss=0.7341\n",
      "        Epoch  5: F1=0.3545, Loss=0.1731\n",
      "        Epoch 10: F1=0.3813, Loss=0.0940\n",
      "        Epoch 15: F1=0.4349, Loss=0.0843\n",
      "        Epoch 20: F1=0.4849, Loss=0.0729\n",
      "        Epoch 25: F1=0.5128, Loss=0.0769\n",
      "        Epoch 30: F1=0.5316, Loss=0.0733\n",
      "\n",
      "    ‚úì Fold 1: F1=0.5316 (93.9 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adamw, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3398, Loss=0.7114\n",
      "        Epoch  5: F1=0.3706, Loss=0.1796\n",
      "        Epoch 10: F1=0.4196, Loss=0.1042\n",
      "        Epoch 15: F1=0.4590, Loss=0.0817\n",
      "        Epoch 20: F1=0.4961, Loss=0.0725\n",
      "        Epoch 25: F1=0.5264, Loss=0.0801\n",
      "        Epoch 30: F1=0.5293, Loss=0.0785\n",
      "\n",
      "    ‚úì Fold 2: F1=0.5293 (93.9 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adamw, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3732, Loss=0.7277\n",
      "        Epoch  5: F1=0.3762, Loss=0.1815\n",
      "        Epoch 10: F1=0.4161, Loss=0.1062\n",
      "        Epoch 15: F1=0.4406, Loss=0.0832\n",
      "        Epoch 20: F1=0.5103, Loss=0.0790\n",
      "        Epoch 25: F1=0.5434, Loss=0.0755\n",
      "        Epoch 30: F1=0.5458, Loss=0.0752\n",
      "\n",
      "    ‚úì Fold 3: F1=0.5458 (94.0 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.5356 ¬± 0.0073\n",
      "  Mean Acc: 0.5864\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 10/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: leakyrelu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.8s)\n",
      "      [3/6] Optimizer (adamw, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3688, Loss=0.7205\n",
      "        Epoch  5: F1=0.3679, Loss=0.1849\n",
      "        Epoch 10: F1=0.3763, Loss=0.1041\n",
      "        Epoch 15: F1=0.4012, Loss=0.0811\n",
      "        Epoch 20: F1=0.5026, Loss=0.0815\n",
      "        Epoch 25: F1=0.5267, Loss=0.0785\n",
      "        Epoch 30: F1=0.5205, Loss=0.0735\n",
      "\n",
      "    ‚úì Fold 1: F1=0.5267 (93.5 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.8s)\n",
      "      [3/6] Optimizer (adamw, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2992, Loss=0.7213\n",
      "        Epoch  5: F1=0.3718, Loss=0.1721\n",
      "        Epoch 10: F1=0.3621, Loss=0.0947\n",
      "        Epoch 15: F1=0.4140, Loss=0.0750\n",
      "        Epoch 20: F1=0.4690, Loss=0.0762\n",
      "        Epoch 25: F1=0.5132, Loss=0.0714\n",
      "        Epoch 30: F1=0.5177, Loss=0.0697\n",
      "\n",
      "    ‚úì Fold 2: F1=0.5195 (93.5 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adamw, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3541, Loss=0.7360\n",
      "        Epoch  5: F1=0.3806, Loss=0.1852\n",
      "        Epoch 10: F1=0.3865, Loss=0.1041\n",
      "        Epoch 15: F1=0.4080, Loss=0.0892\n",
      "        Epoch 20: F1=0.4949, Loss=0.0771\n",
      "        Epoch 25: F1=0.5285, Loss=0.0766\n",
      "        Epoch 30: F1=0.5254, Loss=0.0766\n",
      "\n",
      "    ‚úì Fold 3: F1=0.5285 (93.7 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.5249 ¬± 0.0039\n",
      "  Mean Acc: 0.5689\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 11/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: leakyrelu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.8s)\n",
      "      [3/6] Optimizer (adamw, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3392, Loss=0.7132\n",
      "        Epoch  5: F1=0.3395, Loss=0.1702\n",
      "        Epoch 10: F1=0.3599, Loss=0.0953\n",
      "        Epoch 15: F1=0.4632, Loss=0.0771\n",
      "        Epoch 20: F1=0.4877, Loss=0.0762\n",
      "        Epoch 25: F1=0.5122, Loss=0.0711\n",
      "        Epoch 30: F1=0.5142, Loss=0.0679\n",
      "\n",
      "    ‚úì Fold 1: F1=0.5142 (93.9 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adamw, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3631, Loss=0.7493\n",
      "        Epoch  5: F1=0.3676, Loss=0.1788\n",
      "        Epoch 10: F1=0.3827, Loss=0.0996\n",
      "        Epoch 15: F1=0.4042, Loss=0.0774\n",
      "        Epoch 20: F1=0.4807, Loss=0.0732\n",
      "        Epoch 25: F1=0.5206, Loss=0.0703\n",
      "        Epoch 30: F1=0.5145, Loss=0.0721\n",
      "\n",
      "    ‚úì Fold 2: F1=0.5206 (94.0 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (1.0s)\n",
      "      [3/6] Optimizer (adamw, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3876, Loss=0.7227\n",
      "        Epoch  5: F1=0.3811, Loss=0.1782\n",
      "        Epoch 10: F1=0.4251, Loss=0.0951\n",
      "        Epoch 15: F1=0.4332, Loss=0.0821\n",
      "        Epoch 20: F1=0.4933, Loss=0.0779\n",
      "        Epoch 25: F1=0.5250, Loss=0.0794\n",
      "        Epoch 30: F1=0.5276, Loss=0.0705\n",
      "\n",
      "    ‚úì Fold 3: F1=0.5295 (94.6 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.5214 ¬± 0.0063\n",
      "  Mean Acc: 0.5643\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 12/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adamw\n",
      "  Activation: leakyrelu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (1.0s)\n",
      "      [3/6] Optimizer (adamw, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3151, Loss=0.7380\n",
      "        Epoch  5: F1=0.3703, Loss=0.1800\n",
      "        Epoch 10: F1=0.3745, Loss=0.1018\n",
      "        Epoch 15: F1=0.4385, Loss=0.0824\n",
      "        Epoch 20: F1=0.4944, Loss=0.0788\n",
      "        Epoch 25: F1=0.5197, Loss=0.0766\n",
      "        Epoch 30: F1=0.5222, Loss=0.0760\n",
      "\n",
      "    ‚úì Fold 1: F1=0.5231 (94.1 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (1.0s)\n",
      "      [3/6] Optimizer (adamw, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3328, Loss=0.7270\n",
      "        Epoch  5: F1=0.3549, Loss=0.1795\n",
      "        Epoch 10: F1=0.3752, Loss=0.1028\n",
      "        Epoch 15: F1=0.4111, Loss=0.0760\n",
      "        Epoch 20: F1=0.5007, Loss=0.0736\n",
      "        Epoch 25: F1=0.5124, Loss=0.0743\n",
      "        Epoch 30: F1=0.5206, Loss=0.0756\n",
      "\n",
      "    ‚úì Fold 2: F1=0.5206 (94.0 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.9s)\n",
      "      [3/6] Optimizer (adamw, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.2949, Loss=0.7275\n",
      "        Epoch  5: F1=0.3879, Loss=0.1733\n",
      "        Epoch 10: F1=0.4154, Loss=0.0951\n",
      "        Epoch 15: F1=0.4143, Loss=0.0828\n",
      "        Epoch 20: F1=0.4898, Loss=0.0736\n",
      "        Epoch 25: F1=0.5241, Loss=0.0695\n",
      "        Epoch 30: F1=0.5223, Loss=0.0772\n",
      "\n",
      "    ‚úì Fold 3: F1=0.5241 (81.8 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.5226 ¬± 0.0015\n",
      "  Mean Acc: 0.5688\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 13/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: relu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.4072, Loss=0.4503\n",
      "        Epoch  5: F1=0.4291, Loss=0.0977\n",
      "        Epoch 10: F1=0.5126, Loss=0.0828\n",
      "        Epoch 15: F1=0.5338, Loss=0.0763\n",
      "        Epoch 20: F1=0.5431, Loss=0.0769\n",
      "        Epoch 25: F1=0.5531, Loss=0.0763\n",
      "        Epoch 30: F1=0.5487, Loss=0.0777\n",
      "\n",
      "    ‚úì Fold 1: F1=0.5538 (61.0 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3949, Loss=0.4466\n",
      "        Epoch  5: F1=0.4286, Loss=0.0992\n",
      "        Epoch 10: F1=0.5069, Loss=0.0787\n",
      "        Epoch 15: F1=0.5163, Loss=0.0788\n",
      "        Epoch 20: F1=0.5245, Loss=0.0786\n",
      "        Epoch 25: F1=0.5367, Loss=0.0755\n",
      "        Epoch 30: F1=0.5414, Loss=0.0756\n",
      "\n",
      "    ‚úì Fold 2: F1=0.5460 (61.5 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3984, Loss=0.4495\n",
      "        Epoch  5: F1=0.4307, Loss=0.0918\n",
      "        Epoch 10: F1=0.4931, Loss=0.0880\n",
      "        Epoch 15: F1=0.5215, Loss=0.0826\n",
      "        Epoch 20: F1=0.5334, Loss=0.0729\n",
      "        Epoch 25: F1=0.5475, Loss=0.0768\n",
      "        Epoch 30: F1=0.5417, Loss=0.0766\n",
      "\n",
      "    ‚úì Fold 3: F1=0.5475 (62.5 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.5491 ¬± 0.0034\n",
      "  Mean Acc: 0.5724\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 14/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: relu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.4044, Loss=0.4478\n",
      "        Epoch  5: F1=0.4294, Loss=0.0938\n",
      "        Epoch 10: F1=0.5035, Loss=0.0797\n",
      "        Epoch 15: F1=0.5246, Loss=0.0755\n",
      "        Epoch 20: F1=0.5392, Loss=0.0836\n",
      "        Epoch 25: F1=0.5305, Loss=0.0746\n",
      "        Epoch 30: F1=0.5413, Loss=0.0785\n",
      "\n",
      "    ‚úì Fold 1: F1=0.5446 (62.0 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3991, Loss=0.4362\n",
      "        Epoch  5: F1=0.4299, Loss=0.0912\n",
      "        Epoch 10: F1=0.5027, Loss=0.0755\n",
      "        Epoch 15: F1=0.5251, Loss=0.0746\n",
      "        Epoch 20: F1=0.5395, Loss=0.0708\n",
      "        Epoch 25: F1=0.5446, Loss=0.0742\n",
      "        Epoch 30: F1=0.5498, Loss=0.0752\n",
      "\n",
      "    ‚úì Fold 2: F1=0.5498 (61.7 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.4131, Loss=0.4440\n",
      "        Epoch  5: F1=0.4199, Loss=0.0988\n",
      "        Epoch 10: F1=0.5085, Loss=0.0849\n",
      "        Epoch 15: F1=0.5265, Loss=0.0826\n",
      "        Epoch 20: F1=0.5479, Loss=0.0776\n",
      "        Epoch 25: F1=0.5455, Loss=0.0777\n",
      "        Epoch 30: F1=0.5502, Loss=0.0761\n",
      "\n",
      "    ‚úì Fold 3: F1=0.5553 (61.8 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.5499 ¬± 0.0044\n",
      "  Mean Acc: 0.5805\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 15/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: relu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.4013, Loss=0.4282\n",
      "        Epoch  5: F1=0.4400, Loss=0.0942\n",
      "        Epoch 10: F1=0.5156, Loss=0.0754\n",
      "        Epoch 15: F1=0.5330, Loss=0.0731\n",
      "        Epoch 20: F1=0.5496, Loss=0.0768\n",
      "        Epoch 25: F1=0.5555, Loss=0.0756\n",
      "        Epoch 30: F1=0.5616, Loss=0.0762\n",
      "\n",
      "    ‚úì Fold 1: F1=0.5616 (61.6 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.0s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3927, Loss=0.4402\n",
      "        Epoch  5: F1=0.4254, Loss=0.0999\n",
      "        Epoch 10: F1=0.5096, Loss=0.0778\n",
      "        Epoch 15: F1=0.5415, Loss=0.0753\n",
      "        Epoch 20: F1=0.5488, Loss=0.0802\n",
      "        Epoch 25: F1=0.5506, Loss=0.0767\n",
      "        Epoch 30: F1=0.5533, Loss=0.0700\n",
      "\n",
      "    ‚úì Fold 2: F1=0.5533 (61.9 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (relu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.0s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3981, Loss=0.4518\n",
      "        Epoch  5: F1=0.4463, Loss=0.0982\n",
      "        Epoch 10: F1=0.4990, Loss=0.0825\n",
      "        Epoch 15: F1=0.5155, Loss=0.0855\n",
      "        Epoch 20: F1=0.5524, Loss=0.0801\n",
      "        Epoch 25: F1=0.5497, Loss=0.0815\n",
      "        Epoch 30: F1=0.5606, Loss=0.0808\n",
      "\n",
      "    ‚úì Fold 3: F1=0.5606 (61.8 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.5585 ¬± 0.0037\n",
      "  Mean Acc: 0.5921\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 16/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: leakyrelu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 0e+00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.4015, Loss=0.4454\n",
      "        Epoch  5: F1=0.4216, Loss=0.0967\n",
      "        Epoch 10: F1=0.4938, Loss=0.0758\n",
      "        Epoch 15: F1=0.5242, Loss=0.0773\n",
      "        Epoch 20: F1=0.5481, Loss=0.0763\n",
      "        Epoch 25: F1=0.5412, Loss=0.0781\n",
      "        Epoch 30: F1=0.5513, Loss=0.0768\n",
      "\n",
      "    ‚úì Fold 1: F1=0.5513 (61.1 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3849, Loss=0.4419\n",
      "        Epoch  5: F1=0.4199, Loss=0.0949\n",
      "        Epoch 10: F1=0.4844, Loss=0.0773\n",
      "        Epoch 15: F1=0.5079, Loss=0.0818\n",
      "        Epoch 20: F1=0.5140, Loss=0.0774\n",
      "        Epoch 25: F1=0.5304, Loss=0.0698\n",
      "        Epoch 30: F1=0.5275, Loss=0.0736\n",
      "\n",
      "    ‚úì Fold 2: F1=0.5382 (61.1 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=0e+00)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.4167, Loss=0.4561\n",
      "        Epoch  5: F1=0.4405, Loss=0.1013\n",
      "        Epoch 10: F1=0.5080, Loss=0.0797\n",
      "        Epoch 15: F1=0.5298, Loss=0.0803\n",
      "        Epoch 20: F1=0.5465, Loss=0.0808\n",
      "        Epoch 25: F1=0.5407, Loss=0.0801\n",
      "        Epoch 30: F1=0.5516, Loss=0.0785\n",
      "\n",
      "    ‚úì Fold 3: F1=0.5568 (61.4 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.5488 ¬± 0.0078\n",
      "  Mean Acc: 0.5743\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 17/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: leakyrelu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 1e-04\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.0s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3957, Loss=0.4327\n",
      "        Epoch  5: F1=0.4146, Loss=0.0940\n",
      "        Epoch 10: F1=0.4947, Loss=0.0771\n",
      "        Epoch 15: F1=0.5257, Loss=0.0747\n",
      "        Epoch 20: F1=0.5397, Loss=0.0768\n",
      "        Epoch 25: F1=0.5442, Loss=0.0792\n",
      "        Epoch 30: F1=0.5446, Loss=0.0755\n",
      "\n",
      "    ‚úì Fold 1: F1=0.5502 (61.7 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.4057, Loss=0.4395\n",
      "        Epoch  5: F1=0.4321, Loss=0.0978\n",
      "        Epoch 10: F1=0.4977, Loss=0.0831\n",
      "        Epoch 15: F1=0.5271, Loss=0.0776\n",
      "        Epoch 20: F1=0.5357, Loss=0.0795\n",
      "        Epoch 25: F1=0.5386, Loss=0.0756\n",
      "        Epoch 30: F1=0.5430, Loss=0.0761\n",
      "\n",
      "    ‚úì Fold 2: F1=0.5469 (62.0 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=1e-04)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.1s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.4026, Loss=0.4569\n",
      "        Epoch  5: F1=0.4358, Loss=0.0975\n",
      "        Epoch 10: F1=0.5109, Loss=0.0828\n",
      "        Epoch 15: F1=0.5383, Loss=0.0776\n",
      "        Epoch 20: F1=0.5453, Loss=0.0761\n",
      "        Epoch 25: F1=0.5397, Loss=0.0714\n",
      "        Epoch 30: F1=0.5460, Loss=0.0737\n",
      "\n",
      "    ‚úì Fold 3: F1=0.5481 (61.9 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.5484 ¬± 0.0014\n",
      "  Mean Acc: 0.5748\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "================================= CONFIG 18/18 =================================\n",
      "================================================================================\n",
      "  Optimizer: adagrad\n",
      "  Activation: leakyrelu\n",
      "  L1 lambda: 0e+00\n",
      "  L2 lambda: 1e-03\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    Fold 1/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.0s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3869, Loss=0.4392\n",
      "        Epoch  5: F1=0.4545, Loss=0.0972\n",
      "        Epoch 10: F1=0.5251, Loss=0.0811\n",
      "        Epoch 15: F1=0.5359, Loss=0.0732\n",
      "        Epoch 20: F1=0.5512, Loss=0.0779\n",
      "        Epoch 25: F1=0.5465, Loss=0.0742\n",
      "        Epoch 30: F1=0.5520, Loss=0.0687\n",
      "\n",
      "    ‚úì Fold 1: F1=0.5580 (61.7 min)\n",
      "\n",
      "    Fold 2/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.0s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3890, Loss=0.4390\n",
      "        Epoch  5: F1=0.4414, Loss=0.0958\n",
      "        Epoch 10: F1=0.5265, Loss=0.0809\n",
      "        Epoch 15: F1=0.5385, Loss=0.0776\n",
      "        Epoch 20: F1=0.5551, Loss=0.0754\n",
      "        Epoch 25: F1=0.5568, Loss=0.0693\n",
      "        Epoch 30: F1=0.5599, Loss=0.0694\n",
      "\n",
      "    ‚úì Fold 2: F1=0.5599 (62.0 min)\n",
      "\n",
      "    Fold 3/3...\n",
      "      [1/6] Data loaders... ‚úì (0.0s)\n",
      "      [2/6] Model (leakyrelu)... ‚úì (0.5s)\n",
      "      [3/6] Optimizer (adagrad, L2=1e-03)... ‚úì\n",
      "      [4/6] Loss & Scheduler... ‚úì\n",
      "      [5/6] CUDA warmup... ‚úì (0.0s)\n",
      "      [6/6] Training (patience=10, L1=0e+00)...\n",
      "        Epoch  1: F1=0.3968, Loss=0.4516\n",
      "        Epoch  5: F1=0.4533, Loss=0.0948\n",
      "        Epoch 10: F1=0.5245, Loss=0.0846\n",
      "        Epoch 15: F1=0.5368, Loss=0.0803\n",
      "        Epoch 20: F1=0.5422, Loss=0.0774\n",
      "        Epoch 25: F1=0.5521, Loss=0.0719\n",
      "        Epoch 30: F1=0.5403, Loss=0.0776\n",
      "\n",
      "    ‚úì Fold 3: F1=0.5559 (62.0 min)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  Mean F1: 0.5580 ¬± 0.0017\n",
      "  Mean Acc: 0.5979\n",
      "\n",
      "  üíæ Progress saved to gridsearch_results/\n",
      "\n",
      "================================================================================\n",
      "============================= GRIDSEARCH COMPLETE ==============================\n",
      "================================================================================\n",
      "\n",
      "Finished: 2026-01-09 20:25:16\n",
      "Total time: 67.99 hours\n",
      "\n",
      "üíæ Final results saved to gridsearch_results/gridsearch_final.json\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" RUNNING GRIDSEARCH (WITH AUTO-SAVE) \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Results storage\n",
    "all_results = []\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"\\nStarted: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total runs: {len(combinations) * N_FOLDS}\\n\")\n",
    "\n",
    "# Main GridSearch loop\n",
    "for combo_idx, combo in enumerate(combinations, 1):\n",
    "    params = dict(zip(keys, combo))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\" CONFIG {combo_idx}/{len(combinations)} \".center(80, \"=\"))\n",
    "    print(\"=\"*80)\n",
    "    print(f\"  Optimizer: {params['optimizer']}\")\n",
    "    print(f\"  Activation: {params['activation']}\")\n",
    "    print(f\"  L1 lambda: {params['l1_lambda']:.0e}\")\n",
    "    print(f\"  L2 lambda: {params['l2_lambda']:.0e}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    fold_results = []\n",
    "    \n",
    "    # Train on each fold\n",
    "    for fold in range(N_FOLDS):\n",
    "        print(f\"\\n    Fold {fold+1}/{N_FOLDS}...\", flush=True)\n",
    "        \n",
    "        fold_start = time.time()\n",
    "        \n",
    "        try:\n",
    "            result = train_one_config(\n",
    "                fold=fold,\n",
    "                optimizer_name=params['optimizer'],\n",
    "                activation=params['activation'],\n",
    "                l1_lambda=params['l1_lambda'],\n",
    "                l2_lambda=params['l2_lambda'],\n",
    "                **fixed_params\n",
    "            )\n",
    "            \n",
    "            fold_results.append(result)\n",
    "            \n",
    "            fold_time = time.time() - fold_start\n",
    "            print(f\"\\n    ‚úì Fold {fold+1}: F1={result['f1']:.4f} ({fold_time/60:.1f} min)\", flush=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n    ‚ùå Fold {fold+1} Error: {e}\", flush=True)\n",
    "            fold_results.append({'f1': 0.0, 'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0})\n",
    "    \n",
    "    # Compute mean metrics\n",
    "    mean_metrics = {\n",
    "        'f1': np.mean([r['f1'] for r in fold_results]),\n",
    "        'accuracy': np.mean([r['accuracy'] for r in fold_results]),\n",
    "        'precision': np.mean([r['precision'] for r in fold_results]),\n",
    "        'recall': np.mean([r['recall'] for r in fold_results]),\n",
    "        'f1_std': np.std([r['f1'] for r in fold_results]),\n",
    "    }\n",
    "    \n",
    "    # Store results\n",
    "    result_entry = {\n",
    "        'config_id': combo_idx,\n",
    "        'params': params,\n",
    "        'mean_metrics': mean_metrics,\n",
    "        'fold_results': fold_results,\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    }\n",
    "    all_results.append(result_entry)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n  \" + \"-\"*76)\n",
    "    print(f\"  Mean F1: {mean_metrics['f1']:.4f} ¬± {mean_metrics['f1_std']:.4f}\")\n",
    "    print(f\"  Mean Acc: {mean_metrics['accuracy']:.4f}\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # AUTO-SAVE AFTER EACH CONFIG\n",
    "    # ============================================================================\n",
    "    \n",
    "    # Save progress JSON\n",
    "    with open(RESULTS_DIR / 'gridsearch_progress.json', 'w') as f:\n",
    "        json.dump(all_results, f, indent=2, default=str)\n",
    "    \n",
    "    # Save readable summary\n",
    "    with open(RESULTS_DIR / 'gridsearch_summary.txt', 'w') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\" ResNet-101 GridSearch Progress \".center(80, \"=\") + \"\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        f.write(f\"Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Completed: {combo_idx}/{len(combinations)} configs\\n\")\n",
    "        f.write(f\"Progress: {100*combo_idx/len(combinations):.1f}%\\n\\n\")\n",
    "        \n",
    "        # Top configs so far\n",
    "        sorted_results = sorted(all_results, key=lambda x: x['mean_metrics']['f1'], reverse=True)\n",
    "        f.write(\"TOP 5 CONFIGS SO FAR:\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        for i, res in enumerate(sorted_results[:5], 1):\n",
    "            p = res['params']\n",
    "            m = res['mean_metrics']\n",
    "            f.write(f\"{i}. F1={m['f1']:.4f} | Opt={p['optimizer']}, Act={p['activation']}, \"\n",
    "                   f\"L1={p['l1_lambda']:.0e}, L2={p['l2_lambda']:.0e}\\n\")\n",
    "    \n",
    "    print(f\"\\n  üíæ Progress saved to {RESULTS_DIR}/\", flush=True)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SAVE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" GRIDSEARCH COMPLETE \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nFinished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total time: {total_time/3600:.2f} hours\")\n",
    "\n",
    "# Save final results\n",
    "with open(RESULTS_DIR / 'gridsearch_final.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'all_results': all_results,\n",
    "        'param_grid': param_grid,\n",
    "        'fixed_params': fixed_params,\n",
    "        'n_folds': N_FOLDS,\n",
    "        'total_time_hours': total_time/3600,\n",
    "        'completed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    }, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nüíæ Final results saved to {RESULTS_DIR}/gridsearch_final.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä CELL 11: Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "=============================== RESULTS ANALYSIS ===============================\n",
      "================================================================================\n",
      "\n",
      "üèÜ TOP 10 CONFIGURATIONS:\n",
      "================================================================================\n",
      "Rank    Optimizer   Activation       L1       L2         F1      Acc\n",
      "--------------------------------------------------------------------------------\n",
      "1         adagrad         relu    0e+00    1e-03     0.5585   0.5921\n",
      "2         adagrad    leakyrelu    0e+00    1e-03     0.5580   0.5979\n",
      "3         adagrad         relu    0e+00    1e-04     0.5499   0.5805\n",
      "4         adagrad         relu    0e+00    0e+00     0.5491   0.5724\n",
      "5         adagrad    leakyrelu    0e+00    0e+00     0.5488   0.5743\n",
      "6         adagrad    leakyrelu    0e+00    1e-04     0.5484   0.5748\n",
      "7           adamw         relu    0e+00    1e-03     0.5356   0.5864\n",
      "8            adam         relu    0e+00    0e+00     0.5320   0.5836\n",
      "9            adam    leakyrelu    0e+00    0e+00     0.5315   0.5821\n",
      "10          adamw         relu    0e+00    0e+00     0.5295   0.5773\n",
      "\n",
      "================================================================================\n",
      "============================== BEST CONFIGURATION ==============================\n",
      "================================================================================\n",
      "\n",
      "üìã Best Hyperparameters:\n",
      "  Optimizer:    adagrad\n",
      "  Activation:   relu\n",
      "  L1 lambda:    0e+00\n",
      "  L2 lambda:    1e-03\n",
      "\n",
      "üìä Best Performance:\n",
      "  F1 Score:   0.5585 ¬± 0.0037\n",
      "  Accuracy:   0.5921\n",
      "  Precision:  0.5443\n",
      "  Recall:     0.5919\n",
      "\n",
      "üìà COMPARISON WITH BASELINES:\n",
      "--------------------------------------------------------------------------------\n",
      "  KAN:       F1 = 0.4073\n",
      "  EEGNet:    F1 = 0.3281\n",
      "  ResNet-101 (Best): F1 = 0.5585\n",
      "\n",
      "  üéâ ResNet-101 BEATS KAN by 37.1%!\n",
      "\n",
      "================================================================================\n",
      "============================== ALL RESULTS SAVED ===============================\n",
      "================================================================================\n",
      "\n",
      "üìÅ Results directory: gridsearch_results/\n",
      "   - gridsearch_final.json (complete results)\n",
      "   - gridsearch_summary.txt (readable summary)\n",
      "   - gridsearch_progress.json (backup)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" RESULTS ANALYSIS \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sort by F1\n",
    "sorted_results = sorted(all_results, key=lambda x: x['mean_metrics']['f1'], reverse=True)\n",
    "\n",
    "print(\"\\nüèÜ TOP 10 CONFIGURATIONS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Rank':<6} {'Optimizer':>10} {'Activation':>12} {'L1':>8} {'L2':>8} {'F1':>10} {'Acc':>8}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for i, result in enumerate(sorted_results[:10], 1):\n",
    "    p = result['params']\n",
    "    m = result['mean_metrics']\n",
    "    print(f\"{i:<6} {p['optimizer']:>10} {p['activation']:>12} {p['l1_lambda']:>8.0e} \"\n",
    "          f\"{p['l2_lambda']:>8.0e} {m['f1']:>10.4f} {m['accuracy']:>8.4f}\")\n",
    "\n",
    "# Best config\n",
    "best_result = sorted_results[0]\n",
    "best_params = best_result['params']\n",
    "best_metrics = best_result['mean_metrics']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" BEST CONFIGURATION \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüìã Best Hyperparameters:\")\n",
    "print(f\"  Optimizer:    {best_params['optimizer']}\")\n",
    "print(f\"  Activation:   {best_params['activation']}\")\n",
    "print(f\"  L1 lambda:    {best_params['l1_lambda']:.0e}\")\n",
    "print(f\"  L2 lambda:    {best_params['l2_lambda']:.0e}\")\n",
    "\n",
    "print(\"\\nüìä Best Performance:\")\n",
    "print(f\"  F1 Score:   {best_metrics['f1']:.4f} ¬± {best_metrics['f1_std']:.4f}\")\n",
    "print(f\"  Accuracy:   {best_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision:  {best_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall:     {best_metrics['recall']:.4f}\")\n",
    "\n",
    "# Comparison\n",
    "print(\"\\nüìà COMPARISON WITH BASELINES:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  KAN:       F1 = 0.4073\")\n",
    "print(f\"  EEGNet:    F1 = 0.3281\")\n",
    "print(f\"  ResNet-101 (Best): F1 = {best_metrics['f1']:.4f}\")\n",
    "\n",
    "if best_metrics['f1'] > 0.4073:\n",
    "    improvement = ((best_metrics['f1'] - 0.4073) / 0.4073) * 100\n",
    "    print(f\"\\n  üéâ ResNet-101 BEATS KAN by {improvement:.1f}%!\")\n",
    "else:\n",
    "    gap = ((0.4073 - best_metrics['f1']) / 0.4073) * 100\n",
    "    print(f\"\\n  ‚ö†Ô∏è  ResNet-101 is {gap:.1f}% below KAN\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" ALL RESULTS SAVED \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìÅ Results directory: {RESULTS_DIR}/\")\n",
    "print(f\"   - gridsearch_final.json (complete results)\")\n",
    "print(f\"   - gridsearch_summary.txt (readable summary)\")\n",
    "print(f\"   - gridsearch_progress.json (backup)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ CELL 12: Load Previous Results (If Runtime Died)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# USE THIS CELL TO LOAD RESULTS IF RUNTIME DIED\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Loading saved results...\\n\")\n",
    "\n",
    "# Try to load final results first\n",
    "final_path = RESULTS_DIR / 'gridsearch_final.json'\n",
    "progress_path = RESULTS_DIR / 'gridsearch_progress.json'\n",
    "\n",
    "if final_path.exists():\n",
    "    with open(final_path, 'r') as f:\n",
    "        saved_data = json.load(f)\n",
    "    all_results = saved_data['all_results']\n",
    "    print(f\"‚úÖ Loaded FINAL results: {len(all_results)} configs\")\n",
    "    \n",
    "elif progress_path.exists():\n",
    "    with open(progress_path, 'r') as f:\n",
    "        all_results = json.load(f)\n",
    "    print(f\"‚úÖ Loaded PROGRESS results: {len(all_results)} configs\")\n",
    "    print(f\"   (GridSearch was interrupted, this is partial results)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No saved results found in gridsearch_results/\")\n",
    "    print(\"   Make sure you ran Cell 10 (GridSearch) first!\")\n",
    "    all_results = []\n",
    "\n",
    "if all_results:\n",
    "    # Show top 5\n",
    "    sorted_results = sorted(all_results, key=lambda x: x['mean_metrics']['f1'], reverse=True)\n",
    "    \n",
    "    print(\"\\nüèÜ TOP 5 CONFIGURATIONS:\")\n",
    "    print(\"-\"*80)\n",
    "    for i, result in enumerate(sorted_results[:5], 1):\n",
    "        p = result['params']\n",
    "        m = result['mean_metrics']\n",
    "        print(f\"{i}. F1={m['f1']:.4f} | Opt={p['optimizer']}, Act={p['activation']}, \"\n",
    "              f\"L1={p['l1_lambda']:.0e}, L2={p['l2_lambda']:.0e}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Results loaded! You can now run Cell 11 for full analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "=============================== RESULTS ANALYSIS ===============================\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Sort by F1\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m sorted_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mall_results\u001b[49m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müèÜ TOP 10 CONFIGURATIONS:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_results' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" RESULTS ANALYSIS \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sort by F1\n",
    "sorted_results = sorted(all_results, key=lambda x: x['mean_metrics']['f1'], reverse=True)\n",
    "\n",
    "print(\"\\nüèÜ TOP 10 CONFIGURATIONS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Rank':<6} {'Optimizer':>10} {'Grid':>6} {'Spline':>8} {'L1':>8} {'L2':>8} {'F1':>10} {'Acc':>8}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for i, result in enumerate(sorted_results[:10], 1):\n",
    "    p = result['params']\n",
    "    m = result['mean_metrics']\n",
    "    print(f\"{i:<6} {p['optimizer']:>10} {p['grid_size']:>6} {p['spline_order']:>8} \"\n",
    "          f\"{p['l1_lambda']:>8.0e} {p['l2_lambda']:>8.0e} \"\n",
    "          f\"{m['f1']:>10.4f} {m['accuracy']:>8.4f}\")\n",
    "\n",
    "# Best config\n",
    "best_result = sorted_results[0]\n",
    "best_params = best_result['params']\n",
    "best_metrics = best_result['mean_metrics']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" BEST CONFIGURATION \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìã Best Hyperparameters:\")\n",
    "print(f\"  Optimizer:    {best_params['optimizer']}\")\n",
    "print(f\"  Grid size:    {best_params['grid_size']}\")\n",
    "print(f\"  Spline order: {best_params['spline_order']}\")\n",
    "print(f\"  L1 lambda:    {best_params['l1_lambda']:.0e}\")\n",
    "print(f\"  L2 lambda:    {best_params['l2_lambda']:.0e}\")\n",
    "\n",
    "print(\"\\nüìä Best Performance:\")\n",
    "print(f\"  F1 Score:   {best_metrics['f1']:.4f} ¬± {best_metrics['f1_std']:.4f}\")\n",
    "print(f\"  Accuracy:   {best_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision:  {best_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall:     {best_metrics['recall']:.4f}\")\n",
    "\n",
    "# Comparison\n",
    "print(\"\\nüìà COMPARISON WITH BASELINES:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  EEGNet:    F1 = 0.3281\")\n",
    "print(f\"  KAN (Best):       F1 = {best_metrics['f1']:.4f}\")\n",
    "print(f\"  ResNet-101: F1 = 0.5585\")\n",
    "\n",
    "if best_metrics['f1'] > 0.5585:\n",
    "    improvement = ((best_metrics['f1'] - 0.5585) / 0.5585) * 100\n",
    "    print(f\"\\n  üéâ KAN BEATS ResNet-101 by {improvement:.1f}%!\")\n",
    "elif best_metrics['f1'] > 0.3281:\n",
    "    improvement_eegnet = ((best_metrics['f1'] - 0.3281) / 0.3281) * 100\n",
    "    gap_resnet = ((0.5585 - best_metrics['f1']) / 0.5585) * 100\n",
    "    print(f\"\\n  ‚úÖ KAN beats EEGNet by {improvement_eegnet:.1f}%\")\n",
    "    print(f\"  üìâ KAN is {gap_resnet:.1f}% below ResNet-101\")\n",
    "else:\n",
    "    gap = ((0.3281 - best_metrics['f1']) / 0.3281) * 100\n",
    "    print(f\"\\n  ‚ö†Ô∏è  KAN is {gap:.1f}% below EEGNet baseline\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" ALL RESULTS SAVED \".center(80, \"=\"))\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìÅ Results directory: {RESULTS_DIR}/\")\n",
    "print(f\"   - kan_gridsearch_final.json (complete results)\")\n",
    "print(f\"   - kan_gridsearch_summary.txt (readable summary)\")\n",
    "print(f\"   - kan_gridsearch_progress.json (backup)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jkl]",
   "language": "python",
   "name": "conda-env-jkl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
